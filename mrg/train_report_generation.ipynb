{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1\r\n"
     ]
    }
   ],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Timer #, EarlyStopping\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3\r\n"
     ]
    }
   ],
   "source": [
    "!echo ${CUDA_VISIBLE_DEVICES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:1')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size=128, shuffle=False):\n",
    "    def collate_fn(batch_tuples):\n",
    "        images = []\n",
    "        batch_seq_out = []\n",
    "        for image, seq_out in batch_tuples:\n",
    "            images.append(image)\n",
    "            batch_seq_out.append(seq_out)\n",
    "\n",
    "        images = torch.stack(images)\n",
    "        batch_seq_out = pad_sequence(batch_seq_out, batch_first=True)\n",
    "        return images, batch_seq_out\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size, collate_fn=collate_fn,\n",
    "                            shuffle=shuffle)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_step_fn(model, optimizer=None, training=True, device=DEVICE):\n",
    "    \"\"\"Creates a step function for an Engine.\"\"\"\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    def step_fn(engine, data_batch):\n",
    "        # Images\n",
    "        images = data_batch[0].to(device)\n",
    "        # shape: batch_size, 3, height, width\n",
    "\n",
    "        # Reports, as word ids\n",
    "        reports = data_batch[1].to(device).long() # shape: batch_size, max_sentence_len\n",
    "        _, max_sentence_len = reports.size()\n",
    "        \n",
    "        # Enable training\n",
    "        model.train(training)\n",
    "        torch.set_grad_enabled(training) # enable recording gradients\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        if training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Pass thru the model\n",
    "        output_tuple = model(images, max_sentence_len, reports)\n",
    "\n",
    "        generated_words = output_tuple[0]\n",
    "        _, _, vocab_size = generated_words.size()\n",
    "        # shape: batch_size, n_sentences, vocab_size\n",
    "\n",
    "        # Compute classification loss\n",
    "        loss = loss_fn(generated_words.view(-1, vocab_size), reports.view(-1))\n",
    "        \n",
    "        batch_loss = loss.item()\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return batch_loss, generated_words, reports\n",
    "\n",
    "    return step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run utils/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from ignite.metrics import RunningAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run metrics/report_generation/word_accuracy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _transform_word_accuracy(outputs):\n",
    "    _, generated_scores, seq = outputs\n",
    "    _, words_predicted = generated_scores.max(dim=2)\n",
    "    return words_predicted, seq\n",
    "\n",
    "def attach_metrics_report_generation(engine):\n",
    "    loss = RunningAverage(output_transform=lambda x: x[0])\n",
    "    loss.attach(engine, 'loss')\n",
    "    \n",
    "    word_acc = WordAccuracy(output_transform=_transform_word_accuracy)\n",
    "    word_acc.attach(engine, 'word_acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/runs.py\n",
    "%run tensorboard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(run_name, model, train_dataloader, val_dataloader, n_epochs=1, lr=0.0001,\n",
    "                debug=True):\n",
    "    # Prepare run\n",
    "    run_state = RunState(run_name, classification=False, debug=debug)\n",
    "    initial_epoch = run_state.current_epoch()\n",
    "    if initial_epoch > 0:\n",
    "        print('Found previous run on epoch: ', initial_epoch)\n",
    "\n",
    "    # TB writer\n",
    "    tb_writer = TBWriter(run_name, classification=False, debug=debug)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Create validator engine\n",
    "    validator = Engine(get_step_fn(model, training=False))\n",
    "    attach_metrics_report_generation(validator)\n",
    "    \n",
    "    # Create trainer engine\n",
    "    trainer = Engine(get_step_fn(model, optimizer=optimizer, training=True))\n",
    "    attach_metrics_report_generation(trainer)\n",
    "    \n",
    "    # Create Timer to measure wall time between epochs\n",
    "    timer = Timer(average=True)\n",
    "    timer.attach(trainer, start=Events.EPOCH_STARTED, step=Events.EPOCH_COMPLETED)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def tb_write_metrics(trainer):\n",
    "        # State\n",
    "        epoch = trainer.state.epoch + initial_epoch\n",
    "        max_epochs = trainer.state.max_epochs + initial_epoch\n",
    "        run_state.save_state(epoch)\n",
    "        \n",
    "        # Run on evaluation\n",
    "        validator.run(val_dataloader, 1)\n",
    "\n",
    "        # Common time\n",
    "        wall_time = time.time()\n",
    "\n",
    "        # Metrics\n",
    "        train_metrics = trainer.state.metrics\n",
    "        val_metrics = validator.state.metrics\n",
    "        \n",
    "        # Log to TB\n",
    "        tb_writer.write_metrics(train_metrics, 'train', epoch, wall_time)\n",
    "        tb_writer.write_metrics(val_metrics, 'val', epoch, wall_time)\n",
    "        tb_writer.write_histogram(model, epoch, wall_time)\n",
    "        \n",
    "        # Print metrics\n",
    "        train_loss = train_metrics.get('loss', -1)\n",
    "        val_loss = val_metrics.get('loss', -1)\n",
    "        loss_str = f'loss {train_loss:.4f}, {val_loss:.4f}'\n",
    "        \n",
    "        train_acc = train_metrics.get('word_acc', -1)\n",
    "        val_acc = val_metrics.get('word_acc', -1)\n",
    "        acc_str = f'acc {train_acc:.4f}, {val_acc:.4f}'\n",
    "        \n",
    "        duration_str = duration_to_str(timer._elapsed())\n",
    "        print(f'Finished epoch {epoch}/{max_epochs}, {loss_str}, {acc_str} (took {duration_str})')\n",
    "\n",
    "    # Train!\n",
    "    print('-' * 50)\n",
    "    print('Training...')\n",
    "    trainer.run(train_dataloader, n_epochs)\n",
    "\n",
    "    # Capture time\n",
    "    secs_per_epoch = timer.value()\n",
    "    duration_per_epoch = duration_to_str(secs_per_epoch)\n",
    "    print('Average time per epoch: ', duration_per_epoch)\n",
    "    print('-'*50)\n",
    "    \n",
    "    # Close stuff\n",
    "    tb_writer.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./datasets/iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5927, 3062), (751, 382))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = IUXRayDataset(dataset_type='train')\n",
    "val_dataset = IUXRayDataset(dataset_type='val', vocab=train_dataset.get_vocab())\n",
    "train_dataset.size(), val_dataset.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5927, 3062)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = 15\n",
    "\n",
    "train_dataloader = create_dataloader(train_dataset, batch_size=BS)\n",
    "val_dataloader = create_dataloader(val_dataset, batch_size=BS)\n",
    "train_dataloader.dataset.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.handlers import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./datasets/cxr14.py\n",
    "%run ./models/classification/__init__.py\n",
    "%run ./models/report_generation/decoder_lstm.py\n",
    "%run ./models/report_generation/cnn_to_seq.py\n",
    "%run ./models/checkpoint.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create load_classification_model() function\n",
    "\n",
    "run_name = '0627_151524_cxr14_resnet_lr1e-06'\n",
    "debug_run = True\n",
    "\n",
    "pretrained_cnn = init_empty_model('resnet',\n",
    "                                  CXR14_DISEASES,\n",
    "                                  multilabel=True,\n",
    "                                 ).to(DEVICE)\n",
    "\n",
    "dummy_optimizer = optim.Adam(pretrained_cnn.parameters(), lr=0.0001)\n",
    "\n",
    "compiled_model = CompiledModel(pretrained_cnn, dummy_optimizer)\n",
    "filepath = get_latest_filepath(run_name, classification=True, debug=debug_run)\n",
    "checkpoint = torch.load(filepath)\n",
    "Checkpoint.load_objects(compiled_model.to_save_checkpoint(), checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = pretrained_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = LSTMDecoder(len(train_dataset.word_to_idx), 100, 100,\n",
    "                      teacher_forcing=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN2Seq(cnn, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Training...\n",
      "Finished epoch 1/10, loss 6.3861, 5.0906, acc 0.1129, 0.1393 (took 0h 1m 31s)\n",
      "Finished epoch 2/10, loss 4.4598, 4.4035, acc 0.1440, 0.1393 (took 0h 1m 32s)\n",
      "Finished epoch 3/10, loss 4.2623, 4.3845, acc 0.1457, 0.1037 (took 0h 1m 32s)\n",
      "Finished epoch 4/10, loss 4.0759, 4.3604, acc 0.1989, 0.0923 (took 0h 1m 32s)\n",
      "Finished epoch 5/10, loss 3.8773, 4.3706, acc 0.2625, 0.1014 (took 0h 1m 31s)\n",
      "Finished epoch 6/10, loss 3.6922, 4.3984, acc 0.3170, 0.0986 (took 0h 1m 32s)\n",
      "Finished epoch 7/10, loss 3.5309, 4.5021, acc 0.3433, 0.0907 (took 0h 1m 32s)\n",
      "Finished epoch 8/10, loss 3.3881, 4.5830, acc 0.3590, 0.0907 (took 0h 1m 32s)\n",
      "Finished epoch 9/10, loss 3.2619, 4.5946, acc 0.3722, 0.1074 (took 0h 1m 32s)\n",
      "Finished epoch 10/10, loss 3.1505, 4.6772, acc 0.3903, 0.1074 (took 0h 1m 32s)\n",
      "Average time per epoch:  0h 1m 32s\n",
      "--------------------------------------------------\n",
      "CPU times: user 40min 12s, sys: 7min 48s, total: 48min 1s\n",
      "Wall time: 15min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_model('tf-new', model, train_dataloader, val_dataloader, n_epochs=10, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word = {v: k for k, v in train_dataset.get_vocab().items()}\n",
    "# idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_text(idxs):\n",
    "    return ' '.join([idx_to_word[int(g.item())] for g in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 512, 512]), torch.Size([79]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, report = train_dataset[-1]\n",
    "image.size(), report.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([79])\n",
      "tensor([76,  4,  7,  8, 12, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'status the and mediastinum normal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = image.unsqueeze(0).to(DEVICE)\n",
    "generated, = model(images, report.size()[0])\n",
    "_, generated = generated.max(dim=2)\n",
    "generated = generated.squeeze(0).cpu()\n",
    "print(generated.size())\n",
    "print(generated)\n",
    "\n",
    "idx_to_text(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heart size and pulmonary vascularity appear within normal limits . retrocardiac soft tissue density is present . there appears to be air within this which could suggest that this represents a hiatal hernia . vascular calcification is noted . calcified granuloma is seen . there has been interval development of bandlike opacity in the left lung base . this may represent atelectasis . no pneumothorax or pleural effusion is seen . osteopenia is present in the spine . END'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_text(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'the size is normal'\n",
    "found = []\n",
    "\n",
    "for report in train_dataset.reports:\n",
    "    report = idx_to_text(report['tokens_idxs'])\n",
    "    if re.search(r'\\A[a-zA-Z]+ size is normal', report):\n",
    "        found.append(report)\n",
    "\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "255px",
    "width": "188px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
