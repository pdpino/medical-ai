{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/__init__.py\n",
    "config_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medai.datasets import iu_xray, mimic_cxr\n",
    "IU_DIR = iu_xray.DATASET_DIR\n",
    "MIMIC_DIR = mimic_cxr.DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../datasets/vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IU_VOCAB = load_vocab(os.path.join(IU_DIR, 'reports'), 'v4-1')\n",
    "MIMIC_VOCAB = load_vocab(os.path.join(MIMIC_DIR, 'reports'), 'v4-2')\n",
    "len(IU_VOCAB), len(MIMIC_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir, VOCAB = IU_DIR, IU_VOCAB\n",
    "# dataset_dir, VOCAB = MIMIC_DIR, MIMIC_VOCAB\n",
    "\n",
    "fpath = os.path.join(dataset_dir, 'reports', 'sentences_with_chexpert_labels.csv')\n",
    "SENTENCES_DF = pd.read_csv(fpath)\n",
    "SENTENCES_DF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(dataset_dir, 'reports', 'reports_with_chexpert_labels.csv')\n",
    "REPORTS_DF = pd.read_csv(fpath)\n",
    "REPORTS_DF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose sentences/reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = list(REPORTS_DF['Reports'])\n",
    "sentences = list(SENTENCES_DF['sentence'])\n",
    "len(sentences), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsentences = list(set(\n",
    "    sub.strip()\n",
    "    for sentence in sentences\n",
    "    for sub in sentence.split(',')\n",
    "))\n",
    "len(subsentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sentences\n",
    "# text = subsentences\n",
    "# text = reports\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../models/report_generation/word_embedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work for now:\n",
    "# (1) negative values in the embeddings (not allowed in LDA or NMF)\n",
    "# (2) features do not represent words directly --> should search closest word to feature?\n",
    "# or something like that? does it make sense?\n",
    "class RadGloveVectorizer:\n",
    "    def __init__(self, vocabulary=None, stop_words=None, **kwargs):\n",
    "        self.radglove = RadGlove()\n",
    "        \n",
    "        assert vocabulary is not None\n",
    "        self.vocab = vocabulary\n",
    "        self.stop_words = set(stop_words) or set()\n",
    "        \n",
    "    def fit(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, texts):\n",
    "        return self.transform(texts)\n",
    "        \n",
    "    def transform(self, texts):\n",
    "        # texts: list of texts\n",
    "\n",
    "        vectors = []\n",
    "        for text in texts:\n",
    "            report_vector = np.zeros(self.radglove.dim)\n",
    "            n_words = 0\n",
    "\n",
    "            for word in text.split(): # assume is tokenized\n",
    "                if word in self.stop_words:\n",
    "                    continue\n",
    "                if word not in self.vocab:\n",
    "                    continue\n",
    "\n",
    "                vector = self.radglove[word].numpy() # really inefficient!!\n",
    "                report_vector += vector\n",
    "                n_words += 1\n",
    "                \n",
    "            if n_words > 0:\n",
    "                report_vector /= n_words\n",
    "        \n",
    "            vectors.append(report_vector)\n",
    "            \n",
    "        vectors = np.array(vectors) # shape: n_texts, n_dim=100\n",
    "        \n",
    "        return vectors\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return list(range(self.radglove.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = [\n",
    "    'there', 'the', 'is', 'are', 'in', 'on', '.', 'of', 'to', 'a',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda text: text.split() # text is already tokenized!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'vocabulary': VOCAB, 'tokenizer': tokenizer, 'stop_words': STOP_WORDS}\n",
    "# vectorizer = RadGloveVectorizer(**kwargs)\n",
    "vectorizer = TfidfVectorizer(**kwargs)\n",
    "# vectorizer = CountVectorizer(vocabulary=IU_VOCAB, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectors = vectorizer.fit_transform(text)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = vectorizer.get_feature_names()\n",
    "len(FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lda = LDA(n_components=10)\n",
    "lda.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics(lda, 'LDA', yscale=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nmf = NMF(n_components=10, beta_loss='kullback-leibler', solver='mu')\n",
    "nmf.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics(nmf, 'NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topics(model, name, n_top_words=20, n_cols=5, yscale=8):\n",
    "    n_rows = math.ceil(len(model.components_) / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*yscale), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        # topic shape: n_words (features)\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1] # shape: n_top_words\n",
    "\n",
    "        top_features = [FEATURE_NAMES[i] for i in top_features_ind] # names of \n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights)\n",
    "        ax.set_title(f\"T{topic_idx + 1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(name, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
