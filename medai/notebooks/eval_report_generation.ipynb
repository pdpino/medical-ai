{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/__init__.py\n",
    "config_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device('cpu')\n",
    "DEVICE = torch.device('cuda')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate models in subsets\n",
    "\n",
    "TODO: move this to script???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n train_report_generation.py\n",
    "%run datasets/__init__.py\n",
    "%run models/checkpoint/__init__.py\n",
    "%run training/report_generation/flat.py\n",
    "%run training/report_generation/hierarchical.py\n",
    "%run models/report_generation/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eval_in_subset(run_name, compiled_model, debug=True, max_n_words=None, max_n_sentences=None,\n",
    "                   device='cuda'):\n",
    "    # Create datasets\n",
    "    vocab = compiled_model.metadata['vocab']\n",
    "    train_dataset = IUXRayDataset('train', vocab=vocab)\n",
    "    val_dataset = IUXRayDataset('val', vocab=vocab)\n",
    "    test_dataset = IUXRayDataset('test', vocab=vocab)\n",
    "    \n",
    "    # Prepare subsets\n",
    "    subset_kwargs = {\n",
    "        'max_n_words': max_n_words,\n",
    "        'max_n_sentences': max_n_sentences,\n",
    "    }\n",
    "    \n",
    "    train_subset = create_report_dataset_subset(train_dataset, **subset_kwargs)\n",
    "    val_subset = create_report_dataset_subset(val_dataset, **subset_kwargs)\n",
    "    test_subset = create_report_dataset_subset(test_dataset, **subset_kwargs)\n",
    "    \n",
    "    # Decide hierachical\n",
    "    decoder_name = compiled_model.metadata['decoder_kwargs']['decoder_name']\n",
    "    hierarchical = is_decoder_hierarchical(decoder_name)\n",
    "    if hierarchical:\n",
    "        create_dataloader = create_hierarchical_dataloader\n",
    "    else:\n",
    "        create_dataloader = create_flat_dataloader\n",
    "\n",
    "    # Create dataloaders\n",
    "    BS = 50\n",
    "    train_dataloader = create_dataloader(train_subset, batch_size=BS)\n",
    "    val_dataloader = create_dataloader(val_subset, batch_size=BS)\n",
    "    test_dataloader = create_dataloader(test_subset, batch_size=BS)\n",
    "    \n",
    "    # Create a suffix\n",
    "    if max_n_words:\n",
    "        suffix = f'max-words-{max_n_words}'\n",
    "    elif max_n_sentences:\n",
    "        suffix = f'max-sentences-{max_n_sentences}'\n",
    "        \n",
    "    evaluate_and_save(run_name,\n",
    "                      compiled_model.model,\n",
    "                      train_dataloader,\n",
    "                      val_dataloader,\n",
    "                      test_dataloader,\n",
    "                      hierarchical=hierarchical,\n",
    "                      debug=debug,\n",
    "                      device=device,\n",
    "                      suffix=suffix,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_n_words = [\n",
    "    20 , # --> 15%\n",
    "    25 , # --> 26%\n",
    "    27 , # --> 33%\n",
    "    33 , # --> 50%\n",
    "#     39 , # --> 66%\n",
    "#     41 , # --> 70%\n",
    "    44 , # --> 75%\n",
    "#     47 , # --> 80%\n",
    "#     58 , # --> 90%\n",
    "    # None, # --> 100%\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_n_sentences = [\n",
    "#     1, # 1.2324835387472564\n",
    "#     2, # 4.761100793516799\n",
    "    3, # 25.730204288367382\n",
    "    4, # 55.10720918453487\n",
    "    5, # 76.66722944453824\n",
    "    6, # 89.39726489954415\n",
    "#     7, # 95.03629917271653\n",
    "#     8, # 97.6194496032416\n",
    "#     9, # 98.86881647813608\n",
    "#     10, # 99.42596657099443\n",
    "#     11, # 99.71298328549722\n",
    "#     12, # 99.89869998311667\n",
    "#     13, # 99.96623332770555\n",
    "#     17, # 99.98311666385278\n",
    "#     18, # 100\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_names = [\n",
    "#     '0717_041434_lstm_lr0.0001_densenet-121',\n",
    "    '0716_211601_lstm-att_lr0.0001_densenet-121', # faltan 33 y 34\n",
    "#     '0717_015057_h-lstm_lr0.0001_densenet-121',\n",
    "#     '0716_234501_h-lstm-att_lr0.0001_densenet-121',\n",
    "]\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for run_name in run_names:\n",
    "    compiled_model = load_compiled_model_report_generation(run_name,\n",
    "                                                           debug=debug,\n",
    "                                                           multiple_gpu=True,\n",
    "                                                           device=DEVICE)\n",
    "    for n_words in tqdm(eval_n_words):\n",
    "        eval_in_subset(run_name,\n",
    "                       compiled_model,\n",
    "                       max_n_words=n_words,\n",
    "                       max_n_sentences=None,\n",
    "                       debug=debug,\n",
    "                       device=DEVICE,\n",
    "                      )\n",
    "    for n_sentences in tqdm(eval_n_sentences):\n",
    "        eval_in_subset(run_name,\n",
    "                       compiled_model,\n",
    "                       max_n_words=None,\n",
    "                       max_n_sentences=n_sentences,\n",
    "                       debug=debug,\n",
    "                       device=DEVICE,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug chexpert-labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/files.py\n",
    "%run ../metrics/__init__.py\n",
    "%run ../metrics/report_generation/chexpert.py\n",
    "# %run -n ../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = RunId('0428_133057', True, 'rg')\n",
    "run_id.full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_rg_outputs(run_id, free=False)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_with_labels = _load_all_gt_labels('mimic-cxr')\n",
    "gt_with_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gt_with_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_with_labels.drop('filename', axis=1, inplace=True)\n",
    "gt_with_labels = gt_with_labels.groupby('Reports').first()\n",
    "print(len(gt_with_labels))\n",
    "gt_with_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_from_gt = gt_with_labels.merge(df[['generated']], left_on='Reports', right_on='generated', how='inner')\n",
    "print(len(annotated_from_gt))\n",
    "annotated_from_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = df.loc[~df['generated'].isin(set(annotated_from_gt['generated']))]\n",
    "print(len(missing_df))\n",
    "missing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_missing_reports = missing_df['generated'].unique()\n",
    "print(len(unique_missing_reports))\n",
    "unique_missing_reports.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = pd.DataFrame(unique_missing_reports, columns=['gen-unique'])\n",
    "print(len(df_unique))\n",
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = _apply_labeler_to_column_in_batches(\n",
    "    df_unique, 'gen-unique', n_batches=3, fill_empty=0, fill_uncertain=1,\n",
    "    caller_id='eval-notebook',\n",
    ")\n",
    "gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_2 = _concat_df_matrix(df_unique, gen, 'gen')\n",
    "print(len(df_unique_2))\n",
    "df_unique_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_unique_2, how='inner', left_on='generated', right_on='gen-unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = apply_labeler_to_df(df,\n",
    "                         batches=3,\n",
    "                         caller_id='eval-notebook',\n",
    "                         dataset_name='mimic-cxr',\n",
    "                        )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug `batches` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_batches = apply_labeler_to_df(df,\n",
    "                         batches=3,\n",
    "                         caller_id='eval-notebook',\n",
    "                         dataset_name='mimic-cxr',\n",
    "                        )\n",
    "df_batches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole = apply_labeler_to_df(df,\n",
    "                         batches=1,\n",
    "                         caller_id='eval-notebook',\n",
    "                         dataset_name='mimic-cxr',\n",
    "                        )\n",
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in df_whole.columns if c.endswith('-gt') or c.endswith('-gen')]\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_batches = df_batches[cols].to_numpy()\n",
    "arr_whole = df_whole[cols].to_numpy()\n",
    "arr_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert arr_batches.shape == arr_whole.shape\n",
    "assert (arr_batches == arr_whole).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
