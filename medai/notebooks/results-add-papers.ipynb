{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save paper results\n",
    "\n",
    "Save baseline/paper results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/common/constants.py\n",
    "%run ../utils/__init__.py\n",
    "%run ../utils/files.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_metrics(folder, filename, results_dict):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(results_dict, f, indent=2)\n",
    "    print(f'Saved dict to {filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mirqi_metrics(folder, results):\n",
    "    _save_metrics(folder, 'mirqi-metrics-free.json', results)\n",
    "\n",
    "def save_chexpert_metrics(folder, results):\n",
    "    _save_metrics(folder, 'chexpert-metrics-free.json', results)\n",
    "\n",
    "def save_runtime_metrics(folder, results):\n",
    "    _save_metrics(folder, 'metrics-free.json', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_folder(dataset, paper, save_mode=False):\n",
    "    assert dataset in ('iu-x-ray', 'mimic-cxr')\n",
    "    run_name = f'{dataset}_paper_{paper}'\n",
    "    folder = get_results_folder(RunId(run_name, False, 'rg'), save_mode=save_mode)\n",
    "    return folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(metrics, prefixes, no_finding=False,\n",
    "                 diseases=CHEXPERT_DISEASES, verbose=False):\n",
    "    if isinstance(prefixes, str):\n",
    "        prefixes = (prefixes,)\n",
    "\n",
    "    macro_avgs = {}\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        keys = [\n",
    "            f'{prefix}-{disease}'\n",
    "            for disease in diseases\n",
    "            if no_finding or disease.lower() != 'no finding'\n",
    "        ]\n",
    "        macro_avg = np.mean([metrics[k] for k in keys])\n",
    "\n",
    "        key = prefix if no_finding else f'{prefix}-woNF'\n",
    "        macro_avgs[key] = macro_avg\n",
    "            \n",
    "        if verbose:\n",
    "            metrics_sliced = { k: metrics[k] for k in keys }\n",
    "            s = pprint.pformat(metrics_sliced)\n",
    "            print(f'Prefix={prefix}, avg={macro_avg}, slice: {len(keys)}, {s}')\n",
    "            \n",
    "    return macro_avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Paper MIRQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('iu-x-ray', 'zhang-et-al-mirqi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.441, 0.291, 0.203, 0.147\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.304,\n",
    "        'rougeL': 0.367,\n",
    "    }\n",
    "}\n",
    "mirqi_results = {\n",
    "    'test': {\n",
    "        'MIRQI-r': 0.483,\n",
    "        'MIRQI-p': 0.490,\n",
    "        'MIRQI-f': 0.478,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_mirqi_metrics(folder, mirqi_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lovelace et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'lovelace-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their transformer w/fine-tuning ablation\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.415, 0.272, 0.193, 0.146\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.316, # not sure if Cider-D or Cider\n",
    "        'rougeL': 0.318,\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'f1': 22.8,\n",
    "    'prec': 33.3,\n",
    "    'recall': 21.7,\n",
    "\n",
    "    'f1-Atelectasis': 32.2,\n",
    "    'f1-Cardiomegaly': 43.3,\n",
    "    'f1-Consolidation': 7.3,\n",
    "    'f1-Edema': 29.8,\n",
    "    'f1-Enlarged Cardiomediastinum': 5.9,\n",
    "    'f1-Fracture': 0,\n",
    "    'f1-Lung Lesion': 1.4,\n",
    "    'f1-Lung Opacity': 17.1,\n",
    "    'f1-No Finding': 54.1,\n",
    "    'f1-Pleural Effusion': 48.0,\n",
    "    'f1-Pleural Other': 0.9,\n",
    "    'f1-Pneumonia': 3.9,\n",
    "    'f1-Pneumothorax': 9.8,\n",
    "    'f1-Support Devices': 66.0,\n",
    "\n",
    "    'prec-Atelectasis': 43.0,\n",
    "    'prec-Cardiomegaly': 46.9,\n",
    "    'prec-Consolidation': 15.7,\n",
    "    'prec-Edema': 37.6,\n",
    "    'prec-Enlarged Cardiomediastinum': 12.3,\n",
    "    'prec-Fracture': 0,\n",
    "    'prec-Lung Lesion': 23.8,\n",
    "    'prec-Lung Opacity': 64.0,\n",
    "    'prec-No Finding': 39.0,\n",
    "    'prec-Pleural Effusion': 71.2,\n",
    "    'prec-Pleural Other': 16.1,\n",
    "    'prec-Pneumonia': 7,\n",
    "    'prec-Pneumothorax': 12.9,\n",
    "    'prec-Support Devices': 77.0,\n",
    "\n",
    "    'recall-Atelectasis': 25.8,\n",
    "    'recall-Cardiomegaly': 40.2,\n",
    "    'recall-Consolidation': 4.8,\n",
    "    'recall-Edema': 24.6,\n",
    "    'recall-Enlarged Cardiomediastinum': 3.9,\n",
    "    'recall-Fracture': 0,\n",
    "    'recall-Lung Lesion': 0.7,\n",
    "    'recall-Lung Opacity': 9.9,\n",
    "    'recall-No Finding': 88.2,\n",
    "    'recall-Pleural Effusion': 36.2,\n",
    "    'recall-Pleural Other': 0.5,\n",
    "    'recall-Pneumonia': 2.7,\n",
    "    'recall-Pneumothorax': 7.8,\n",
    "    'recall-Support Devices': 57.8,\n",
    "}\n",
    "woNF = calculate_avg_woNF(_values, ['f1', 'recall', 'prec'])\n",
    "_values.update(woNF)\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        k: value / 100\n",
    "        for k, value in _values.items()\n",
    "    },\n",
    "}\n",
    "woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boag et al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'boag-et-al-1nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their 1-NN model\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.305, 0.171, 0.098, 0.057\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.755, # not sure if Cider-D or Cider\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.818,\n",
    "    'prec': 0.253,\n",
    "    'f1': 0.258,\n",
    "\n",
    "    'f1-Support Devices': 0.527,\n",
    "    'f1-Lung Opacity': 0.417,\n",
    "    'f1-Cardiomegaly': 0.445,\n",
    "    'f1-Atelectasis': 0.375,\n",
    "    'f1-No Finding': 0.455,\n",
    "    'f1-Pleural Effusion': 0.532,\n",
    "    'f1-Edema': 0.286,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.142,\n",
    "    'f1-Pneumonia': 0.08,\n",
    "    'f1-Pneumothorax': 0.111,\n",
    "    'f1-Fracture': 0.060,\n",
    "    'f1-Lung Lesion': 0.062,\n",
    "    'f1-Consolidation': 0.085,\n",
    "    'f1-Pleural Other': 0.039,\n",
    "}\n",
    "woNF = calculate_avg_woNF(_values, 'f1')\n",
    "_values.update(woNF)\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}\n",
    "woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### cnn-rnn (without beam-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'boag-et-al-cnn-rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their CNN-RNN (wo-beam)\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.004, 0.001, 0.001, 0.001\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.066, # not sure if Cider-D or Cider\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.822, \n",
    "    'prec': 0.144,\n",
    "    'f1': 0.067,\n",
    "\n",
    "    'f1-Support Devices': 0.106,\n",
    "    'f1-Lung Opacity': 0.330,\n",
    "    'f1-Cardiomegaly': 0.022,\n",
    "    'f1-Atelectasis': 0.054,\n",
    "    'f1-No Finding': 0.362,\n",
    "    'f1-Pleural Effusion': 0.001, # less than that\n",
    "    'f1-Edema': 0.009,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.001, # less than that\n",
    "    'f1-Pneumonia': 0.01,\n",
    "    'f1-Pneumothorax': 0.042,\n",
    "    'f1-Fracture': 0.001, # less than that\n",
    "    'f1-Lung Lesion': 0.005,\n",
    "    'f1-Consolidation': 0.002,\n",
    "    'f1-Pleural Other': 0.001, # less than that\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wNF = compute_mean(_values, ['f1'], no_finding=True)\n",
    "woNF = compute_mean(_values, ['f1'], no_finding=False)\n",
    "woNF, wNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_results = {'test': {**_values,**woNF}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### cnn-rnn-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'boag-et-al-cnn-rnn-beam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their CNN-RNN-beam\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.305, 0.201, 0.137, 0.092\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.850, # not sure if Cider-D or Cider\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.837, \n",
    "    'prec': 0.304,\n",
    "    'f1': 0.186,\n",
    "\n",
    "    'f1-Support Devices': 0.613,\n",
    "    'f1-Lung Opacity': 0.077,\n",
    "    'f1-Cardiomegaly': 0.390,\n",
    "    'f1-Atelectasis': 0.146,\n",
    "    'f1-No Finding': 0.407,\n",
    "    'f1-Pleural Effusion': 0.473,\n",
    "    'f1-Edema': 0.271,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.134,\n",
    "    'f1-Pneumonia': 0.03,\n",
    "    'f1-Pneumothorax': 0.043,\n",
    "    'f1-Fracture': 0.001,\n",
    "    'f1-Lung Lesion': 0.001, # less than that\n",
    "    'f1-Consolidation': 0.014,\n",
    "    'f1-Pleural Other': 0.001, # less than that\n",
    "}\n",
    "woNF = calculate_avg_woNF(_values, ['f1'], CHEXPERT_DISEASES)\n",
    "_values.update(woNF)\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}\n",
    "woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Liu et al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'liu-et-al-ccr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their CCR ablation\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.294, 0.190, 0.134, 0.094\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 0.956,\n",
    "        'rougeL': 0.284,\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.868,\n",
    "    'prec': 0.313,\n",
    "    'recall': 0.126,\n",
    "\n",
    "    'prec-No Finding': 0.491,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.202,\n",
    "    'prec-Cardiomegaly': 0.678,\n",
    "    'prec-Lung Lesion': 0,\n",
    "    'prec-Lung Opacity': 0.640,\n",
    "    'prec-Edema': 0.280,\n",
    "    'prec-Consolidation': 0.037,\n",
    "    'prec-Pneumonia': 0,\n",
    "    'prec-Atelectasis': 0.476,\n",
    "    'prec-Pneumothorax': 0.039,\n",
    "    'prec-Pleural Effusion': 0.683,\n",
    "    'prec-Pleural Other': 0,\n",
    "    'prec-Fracture': 0,\n",
    "    'prec-Support Devices': 0.849,\n",
    "}\n",
    "woNF = calculate_avg_woNF(_values, ['prec'], CHEXPERT_DISEASES, verbose=False)\n",
    "_values.update(woNF)\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}\n",
    "woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'liu-et-al-full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using their CCR ablation\n",
    "bleu1, bleu2, bleu3, bleu4 = 0.313, 0.206, 0.146, 0.103\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'ciderD': 1.046,\n",
    "        'rougeL': 0.306,\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.867,\n",
    "    'prec': 0.309,\n",
    "    'recall': 0.134,\n",
    "\n",
    "    'prec-No Finding': 0.405,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.167,\n",
    "    'prec-Cardiomegaly': 0.704,\n",
    "    'prec-Lung Lesion': 0,\n",
    "    'prec-Lung Opacity': 0.460,\n",
    "    'prec-Edema': 0,\n",
    "    'prec-Consolidation': 0,\n",
    "    'prec-Pneumonia': 0.4,\n",
    "    'prec-Atelectasis': 0.521,\n",
    "    'prec-Pneumothorax': 0.098,\n",
    "    'prec-Pleural Effusion': 0.689,\n",
    "    'prec-Pleural Other': 0,\n",
    "    'prec-Fracture': 0,\n",
    "    'prec-Support Devices': 0.880,\n",
    "}\n",
    "woNF = calculate_avg_woNF(_values, ['prec'], CHEXPERT_DISEASES, verbose=False)\n",
    "woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_values.update(woNF)\n",
    "\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Ni et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def calculate_f1(values, diseases):\n",
    "    f1s = dict()\n",
    "    for disease in diseases:\n",
    "        prec = values[f'prec-{disease}']\n",
    "        recall = values[f'recall-{disease}']\n",
    "        \n",
    "        f1 = 2 * (prec * recall) / (prec + recall)\n",
    "        f1s[f'f1-{disease}'] = f1\n",
    "    f1s['f1'] = np.mean(list(f1s.values()))\n",
    "    return f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'ni-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# MIMIC-CXR dataset but only with abnormal findings!!!\n",
    "# approx 30k samples in total\n",
    "# CVSE + mutual exclusivity ablation \n",
    "bleu4, bleu1 = 0.036, 0.192\n",
    "# meteor = 0.077\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu4': bleu4,\n",
    "        'rougeL': 0.153,\n",
    "    }\n",
    "}\n",
    "_values = {\n",
    "    'acc': 0.863,\n",
    "    'prec': 0.317,\n",
    "    'recall': 0.224,\n",
    "\n",
    "    'acc-No Finding': 0.769,\n",
    "    'acc-Enlarged Cardiomediastinum': 0.926,\n",
    "    'acc-Cardiomegaly': 0.801,\n",
    "    'acc-Lung Lesion': 0.921,\n",
    "    'acc-Lung Opacity': 0.692,\n",
    "    'acc-Edema': 0.920,\n",
    "    'acc-Consolidation': 0.876,\n",
    "    'acc-Pneumonia': 0.859,\n",
    "    'acc-Atelectasis': 0.773,\n",
    "    'acc-Pneumothorax': 0.964,\n",
    "    'acc-Pleural Effusion': 0.894,\n",
    "    'acc-Pleural Other': 0.962,\n",
    "    'acc-Fracture': 0.917,\n",
    "    'acc-Support Devices': 0.808,\n",
    "\n",
    "    'prec-No Finding': 0.346,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.063,\n",
    "    'prec-Cardiomegaly': 0.512,\n",
    "    'prec-Lung Lesion': 0.192,\n",
    "    'prec-Lung Opacity': 0.635,\n",
    "    'prec-Edema': 0.405,\n",
    "    'prec-Consolidation': 0.130,\n",
    "    'prec-Pneumonia': 0.364,\n",
    "    'prec-Atelectasis': 0.525,\n",
    "    'prec-Pneumothorax': 0.073,\n",
    "    'prec-Pleural Effusion': 0.640,\n",
    "    'prec-Pleural Other': 0.145,\n",
    "    'prec-Fracture': 0.063,\n",
    "    'prec-Support Devices': 0.348,\n",
    "\n",
    "    'recall-No Finding': 0.265,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.060,\n",
    "    'recall-Cardiomegaly': 0.606,\n",
    "    'recall-Lung Lesion': 0.121,\n",
    "    'recall-Lung Opacity': 0.237,\n",
    "    'recall-Edema': 0.206,\n",
    "    'recall-Consolidation': 0.181,\n",
    "    'recall-Pneumonia': 0.214,\n",
    "    'recall-Atelectasis': 0.320,\n",
    "    'recall-Pneumothorax': 0.051,\n",
    "    'recall-Pleural Effusion': 0.465,\n",
    "    'recall-Pleural Other': 0.036,\n",
    "    'recall-Fracture': 0.050,\n",
    "    'recall-Support Devices': 0.321,\n",
    "}\n",
    "f1 = calculate_f1(_values, CHEXPERT_DISEASES)\n",
    "_values.update(f1)\n",
    "woNF = calculate_avg_woNF(_values, ['recall', 'f1', 'prec'], CHEXPERT_DISEASES, verbose=False)\n",
    "_values.update(woNF)\n",
    "\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}\n",
    "f1, woNF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Chen et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folder = get_paper_folder('mimic-cxr', 'chen-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.353, 0.218, 0.145, 0.103\n",
    "# meteor = 0.142 # unused!\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.277,\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'f1': 0.276,\n",
    "        'prec': 0.333,\n",
    "        'recall': 0.273,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(folder, chexpert_results)\n",
    "save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RTEx paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'rtex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu4': 5.9 / 100, # Assume is bleu4\n",
    "        'rougeL': 20.5 / 100\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'prec': 0.229,\n",
    "        'recall': 0.284,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iu_folder = get_paper_folder('iu-x-ray', 'rtex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu4': 5.5 / 100,\n",
    "        'rougeL': 20.2 / 100\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'prec': 0.193,\n",
    "        'recall': 0.222,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(iu_folder, chexpert_results)\n",
    "save_runtime_metrics(iu_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Nguyen et al\n",
    "\n",
    "MV+T+I variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'nguyen-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.495, 0.360, 0.278, 0.224\n",
    "# meteor = 0.222 # unused!\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.390,\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'acc': 0.887,\n",
    "        # Macro scores:\n",
    "        # 'auc': 0.784,\n",
    "        'f1': 0.412,\n",
    "        'prec': 0.432,\n",
    "        'recall': 0.418,\n",
    "        ## Micro scores:\n",
    "        # 'micro-auc': 0.874,\n",
    "        # 'micro-f1': 0.576,\n",
    "        # 'micro-prec': 0.567,\n",
    "        # 'micro-recall': 0.585,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iu_folder = get_paper_folder('iu-x-ray', 'nguyen-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.515, 0.378, 0.293, 0.235\n",
    "# meteor = 0.219 # unused!\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.362,\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'acc': 0.937,\n",
    "        # Macro scores:\n",
    "        # 'auc': 0.702,\n",
    "        'f1': 0.152,\n",
    "        'prec': 0.142,\n",
    "        'recall': 0.173,\n",
    "        ## Micro scores:\n",
    "        # 'micro-auc': 0.877,\n",
    "        # 'micro-f1': 0.626,\n",
    "        # 'micro-prec': 0.604,\n",
    "        # 'micro-recall': 0.649,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(iu_folder, chexpert_results)\n",
    "save_runtime_metrics(iu_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Nishino et al\n",
    "\n",
    "TS-MRGen w/o modification, is the fair one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'nishino-et-al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.217, 0.118, 0.073, 0.048\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'acc': 0.873,\n",
    "        # Macro scores:\n",
    "        'f1': 0.217,\n",
    "        # 'micro-f1': 0.296,\n",
    "        # Most likely micro!! (though not specified)\n",
    "        # Unclear if macro or micro! probably micro\n",
    "        # 'micro-prec': 0.482,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Liu et al 2021: contrastive attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'liu-2021-et-al-CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.350, 0.290, 0.152, 0.109\n",
    "# meteor = 0.151\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.283,\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'f1': 0.303,\n",
    "        'prec': 0.352,\n",
    "        'recall': 0.298,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.492, 0.314, 0.222, 0.169\n",
    "# meteor = 0.193\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.381,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iu_folder = get_paper_folder('iu-x-ray', 'liu-2021-et-al-CA')\n",
    "save_runtime_metrics(iu_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variational topic inference (VTI)\n",
    "\n",
    "Najdenkoska et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'vti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.418, 0.293, 0.152, 0.109\n",
    "# meteor = 0.177\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.302,\n",
    "    }\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': {\n",
    "        'f1': 0.210,\n",
    "        'prec': 0.350,\n",
    "        'recall': 0.151,\n",
    "        # Micro:\n",
    "        # 'micro-f1': 0.403,\n",
    "        # 'micro-prec': 0.497,\n",
    "        # 'micro-recall': 0.342,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bleu1, bleu2, bleu3, bleu4 = 0.493, 0.360, 0.291, 0.154\n",
    "# meteor = 0.218\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.375,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iu_folder = get_paper_folder('iu-x-ray', 'vti')\n",
    "save_runtime_metrics(iu_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RATCHET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder = get_paper_folder('mimic-cxr', 'ratchet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# meteor = 0.101\n",
    "# spice = 0.127\n",
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu1': 0.232, # 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        # 'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]),\n",
    "        'rougeL': 0.240,\n",
    "        'ciderD': 0.493,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_f1_values = {\n",
    "    'f1-No Finding': 0.451,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.015,\n",
    "    'f1-Cardiomegaly': 0.446,\n",
    "    'f1-Lung Lesion': 0.069,\n",
    "    'f1-Lung Opacity': 0.344,\n",
    "    'f1-Edema': 0.407,\n",
    "    'f1-Consolidation': 0.041,\n",
    "    'f1-Pneumonia': 0.234,\n",
    "    'f1-Atelectasis': 0.411,\n",
    "    'f1-Pneumothorax': 0.110,\n",
    "    'f1-Pleural Effusion': 0.633,\n",
    "    'f1-Pleural Other': 0,\n",
    "    'f1-Fracture': 0,\n",
    "    'f1-Support Devices': 0.697,\n",
    "}\n",
    "\n",
    "_prec_values = {\n",
    "    'prec-No Finding': 0.344,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.096,\n",
    "    'prec-Cardiomegaly': 0.405,\n",
    "    'prec-Lung Lesion': 0.162,\n",
    "    'prec-Lung Opacity': 0.500,\n",
    "    'prec-Edema': 0.582,\n",
    "    'prec-Consolidation': 0.233,\n",
    "    'prec-Pneumonia': 0.422,\n",
    "    'prec-Atelectasis': 0.465,\n",
    "    'prec-Pneumothorax': 0.110,\n",
    "    'prec-Pleural Effusion': 0.704,\n",
    "    'prec-Pleural Other': 0,\n",
    "    'prec-Fracture': 0,\n",
    "    'prec-Support Devices': 0.628,\n",
    "}\n",
    "\n",
    "_recall_values = {\n",
    "    'recall-No Finding': 0.653,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.008,\n",
    "    'recall-Cardiomegaly': 0.496,\n",
    "    'recall-Lung Lesion': 0.044,\n",
    "    'recall-Lung Opacity': 0.262,\n",
    "    'recall-Edema': 0.312,\n",
    "    'recall-Consolidation': 0.022,\n",
    "    'recall-Pneumonia': 0.162,\n",
    "    'recall-Atelectasis': 0.368,\n",
    "    'recall-Pneumothorax': 0.110,\n",
    "    'recall-Pleural Effusion': 0.575,\n",
    "    'recall-Pleural Other': 0,\n",
    "    'recall-Fracture': 0,\n",
    "    'recall-Support Devices': 0.783,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_values = {\n",
    "    'recall': full_mean(_recall_values),\n",
    "    'recall-woNF': woNF_mean(_recall_values),\n",
    "    'prec': full_mean(_prec_values),\n",
    "    'prec-woNF': woNF_mean(_prec_values),\n",
    "    'f1': full_mean(_f1_values),\n",
    "    'f1-woNF': woNF_mean(_f1_values),\n",
    "    **_f1_values,\n",
    "    **_prec_values,\n",
    "    **_recall_values,\n",
    "}\n",
    "chexpert_results = {\n",
    "    'test': _values,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miura et al\n",
    "\n",
    "Two ablations: fc_E and fc_EN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FC_E ablation in MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder_fce = get_paper_folder('mimic-cxr', 'miura-et-al-fce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runtime_results = {\n",
    "    'test': {\n",
    "        'bleu4': 0.111,\n",
    "        'ciderD': 0.492,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_values = {\n",
    "    'prec-Atelectasis': 0.379,\n",
    "    'recall-Atelectasis': 0.805,\n",
    "    'f1-Atelectasis': 0.516,\n",
    "    'prec-Cardiomegaly': 0.343,\n",
    "    'recall-Cardiomegaly': 0.813,\n",
    "    'f1-Cardiomegaly': 0.482,\n",
    "    'prec-Consolidation': 0.196,\n",
    "    'recall-Consolidation': 0.057,\n",
    "    'f1-Consolidation': 0.089,\n",
    "    'prec-Edema': 0.56,\n",
    "    'recall-Edema': 0.699,\n",
    "    'f1-Edema': 0.622,\n",
    "    'prec-Pleural Effusion': 0.682,\n",
    "    'recall-Pleural Effusion': 0.785,\n",
    "    'f1-Pleural Effusion': 0.730,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.048,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.198,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.077,\n",
    "    'prec-Fracture': 0.107,\n",
    "    'recall-Fracture': 0.054,\n",
    "    'f1-Fracture': 0.071,\n",
    "    'prec-Lung Lesion': 0.222,\n",
    "    'recall-Lung Lesion': 0.021,\n",
    "    'f1-Lung Lesion': 0.038,\n",
    "    'prec-Lung Opacity': 0.535,\n",
    "    'recall-Lung Opacity': 0.104,\n",
    "    'f1-Lung Opacity': 0.174,\n",
    "    'prec-No Finding': 0.498,\n",
    "    'recall-No Finding': 0.417,\n",
    "    'f1-No Finding': 0.454,\n",
    "    'prec-Pleural Other': 0,\n",
    "    'recall-Pleural Other': 0,\n",
    "    'f1-Pleural Other': 0,\n",
    "    'prec-Pneumonia': 0.621,\n",
    "    'recall-Pneumonia': 0.17,\n",
    "    'f1-Pneumonia': 0.267,\n",
    "    'prec-Pneumothorax': 0.37,\n",
    "    'recall-Pneumothorax': 0.128,\n",
    "    'f1-Pneumothorax': 0.19,\n",
    "    'prec-Support Devices': 0.532,\n",
    "    'recall-Support Devices': 0.787,\n",
    "    'f1-Support Devices': 0.635,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=True)\n",
    "d2 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=False)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_results = {'test': { **_values, **d1, **d2 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder_fce, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder_fce, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FC_E ablation in IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iu_folder_fce = get_paper_folder('iu-x-ray', 'miura-et-al-fce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runtime_results = {'test': { 'bleu4': 0.12, 'ciderD': 0.996 }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_values = {\n",
    "    'prec-Atelectasis': 0.358,\n",
    "    'recall-Atelectasis': 0.477,\n",
    "    'f1-Atelectasis': 0.409,\n",
    "    'prec-Cardiomegaly': 0.573,\n",
    "    'recall-Cardiomegaly': 0.556,\n",
    "    'f1-Cardiomegaly': 0.564,\n",
    "    'prec-Consolidation': 0.152,\n",
    "    'recall-Consolidation': 0.263,\n",
    "    'f1-Consolidation': 0.192,\n",
    "    'prec-Edema': 0.309,\n",
    "    'recall-Edema': 0.507,\n",
    "    'f1-Edema': 0.384,\n",
    "    'prec-Pleural Effusion': 0.594,\n",
    "    'recall-Pleural Effusion': 0.664,\n",
    "    'f1-Pleural Effusion': 0.627,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.02,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.042,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.027,\n",
    "    'prec-Fracture': 0.0,\n",
    "    'recall-Fracture': 0.0,\n",
    "    'f1-Fracture': 0.0,\n",
    "    'prec-Lung Lesion': 0.0,\n",
    "    'recall-Lung Lesion': 0.0,\n",
    "    'f1-Lung Lesion': 0.0,\n",
    "    'prec-Lung Opacity': 0.578,\n",
    "    'recall-Lung Opacity': 0.076,\n",
    "    'f1-Lung Opacity': 0.134,\n",
    "    'prec-No Finding': 0.821,\n",
    "    'recall-No Finding': 0.915,\n",
    "    'f1-No Finding': 0.865,\n",
    "    'prec-Pleural Other': 0.0,\n",
    "    'recall-Pleural Other': 0.0,\n",
    "    'f1-Pleural Other': 0.0,\n",
    "    'prec-Pneumonia': 0.386,\n",
    "    'recall-Pneumonia': 0.248,\n",
    "    'f1-Pneumonia': 0.302,\n",
    "    'prec-Pneumothorax': 0.0,\n",
    "    'recall-Pneumothorax': 0.0,\n",
    "    'f1-Pneumothorax': 0.0,\n",
    "    'prec-Support Devices': 0.197,\n",
    "    'recall-Support Devices': 0.366,\n",
    "    'f1-Support Devices': 0.256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=True)\n",
    "d2 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=False)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_results = {'test': { **_values, **d1, **d2 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(iu_folder_fce, chexpert_results)\n",
    "save_runtime_metrics(iu_folder_fce, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FC_EN ablation in MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_folder_fcen = get_paper_folder('mimic-cxr', 'miura-et-al-fcen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "runtime_results = {'test': { 'bleu4': 0.114, 'ciderD': 0.509 }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_values = {\n",
    "    'prec-Atelectasis': 0.406,\n",
    "    'recall-Atelectasis': 0.762,\n",
    "    'f1-Atelectasis': 0.530,\n",
    "    'prec-Cardiomegaly': 0.375,\n",
    "    'recall-Cardiomegaly': 0.613,\n",
    "    'f1-Cardiomegaly': 0.466,\n",
    "    'prec-Consolidation': 0.192,\n",
    "    'recall-Consolidation': 0.032,\n",
    "    'f1-Consolidation': 0.055,\n",
    "    'prec-Edema': 0.656,\n",
    "    'recall-Edema': 0.527,\n",
    "    'f1-Edema': 0.585,\n",
    "    'prec-Pleural Effusion': 0.659,\n",
    "    'recall-Pleural Effusion': 0.820,\n",
    "    'f1-Pleural Effusion': 0.731,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.046,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.477,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.084,\n",
    "    'prec-Fracture': 0.261,\n",
    "    'recall-Fracture': 0.107,\n",
    "    'f1-Fracture': 0.152,\n",
    "    'prec-Lung Lesion': 0.444,\n",
    "    'recall-Lung Lesion': 0.041,\n",
    "    'f1-Lung Lesion': 0.075,\n",
    "    'prec-Lung Opacity': 0.549,\n",
    "    'recall-Lung Opacity': 0.266,\n",
    "    'f1-Lung Opacity': 0.358,\n",
    "    'prec-No Finding': 0.488,\n",
    "    'recall-No Finding': 0.399,\n",
    "    'f1-No Finding': 0.439,\n",
    "    'prec-Pleural Other': 0.0,\n",
    "    'recall-Pleural Other': 0.0,\n",
    "    'f1-Pleural Other': 0.0,\n",
    "    'prec-Pneumonia': 0.0,\n",
    "    'recall-Pneumonia': 0.0,\n",
    "    'f1-Pneumonia': 0.0,\n",
    "    'prec-Pneumothorax': 0.500,\n",
    "    'recall-Pneumothorax': 0.103,\n",
    "    'f1-Pneumothorax': 0.170,\n",
    "    'prec-Support Devices': 0.490,\n",
    "    'recall-Support Devices': 0.897,\n",
    "    'f1-Support Devices': 0.633,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d1 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=True)\n",
    "d2 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=False)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_results = {'test': { **_values, **d1, **d2 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder_fcen, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder_fcen, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC_EN ablation in IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu_folder_fcen = get_paper_folder('iu-x-ray', 'miura-et-al-fcen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_results = {'test': { 'bleu4': 0.131, 'ciderD': 1.034 }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_values = {\n",
    "    'prec-Atelectasis': 0.394,\n",
    "    'recall-Atelectasis': 0.454,\n",
    "    'f1-Atelectasis': 0.422,\n",
    "    'prec-Cardiomegaly': 0.600,\n",
    "    'recall-Cardiomegaly': 0.467,\n",
    "    'f1-Cardiomegaly': 0.525,\n",
    "    'prec-Consolidation': 0.143,\n",
    "    'recall-Consolidation': 0.053,\n",
    "    'f1-Consolidation': 0.077,\n",
    "    'prec-Edema': 0.414,\n",
    "    'recall-Edema': 0.320,\n",
    "    'f1-Edema': 0.361,\n",
    "    'prec-Pleural Effusion': 0.560,\n",
    "    'recall-Pleural Effusion': 0.664,\n",
    "    'f1-Pleural Effusion': 0.608,\n",
    "    'prec-Enlarged Cardiomediastinum': 0.040,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.208,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.067,\n",
    "    'prec-Fracture': 0.031,\n",
    "    'recall-Fracture': 0.023,\n",
    "    'f1-Fracture': 0.027,\n",
    "    'prec-Lung Lesion': 0.667,\n",
    "    'recall-Lung Lesion': 0.045,\n",
    "    'f1-Lung Lesion': 0.084,\n",
    "    'prec-Lung Opacity': 0.411,\n",
    "    'recall-Lung Opacity': 0.221,\n",
    "    'f1-Lung Opacity': 0.287,\n",
    "    'prec-No Finding': 0.817,\n",
    "    'recall-No Finding': 0.884,\n",
    "    'f1-No Finding': 0.849,\n",
    "    'prec-Pleural Other': 0.0,\n",
    "    'recall-Pleural Other': 0.0,\n",
    "    'f1-Pleural Other': 0.0,\n",
    "    'prec-Pneumonia': 0.0,\n",
    "    'recall-Pneumonia': 0.0,\n",
    "    'f1-Pneumonia': 0.0,\n",
    "    'prec-Pneumothorax': 1.00,\n",
    "    'recall-Pneumothorax': 0.133,\n",
    "    'f1-Pneumothorax': 0.235,\n",
    "    'prec-Support Devices': 0.131,\n",
    "    'recall-Support Devices': 0.561,\n",
    "    'f1-Support Devices': 0.213,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=True)\n",
    "d2 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=False)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_results = {'test': { **_values, **d1, **d2 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_chexpert_metrics(iu_folder_fcen, chexpert_results)\n",
    "save_runtime_metrics(iu_folder_fcen, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iu_folder_arl = get_paper_folder('iu-x-ray', 'arl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_results = {'test': {\n",
    "    'bleu4': 0.125, 'meteor': 0.171, 'rougeL': 0.262, 'ciderD': 0.366,\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_runtime_metrics(iu_folder_arl, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_folder_arl = get_paper_folder('mimic-cxr', 'arl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_results = {'test': {\n",
    "    'bleu4': 0.148, 'meteor': 0.253, 'rougeL': 0.329, 'ciderD': 0.402,\n",
    "}}\n",
    "\n",
    "_values = {\n",
    "    'prec-No Finding': 0.718,\n",
    "    'recall-No Finding': 0.741,\n",
    "    'f1-No Finding': 0.729,\n",
    "\n",
    "    'prec-Lung Opacity': 0.522,\n",
    "    'recall-Lung Opacity': 0.458,\n",
    "    'f1-Lung Opacity': 0.488,\n",
    "\n",
    "    'prec-Atelectasis': 0.426,\n",
    "    'recall-Atelectasis': 0.259,\n",
    "    'f1-Atelectasis': 0.322,\n",
    "\n",
    "    'prec-Pleural Effusion': 0.347,\n",
    "    'recall-Pleural Effusion': 0.140,\n",
    "    'f1-Pleural Effusion': 0.200,\n",
    "\n",
    "    'prec-Pneumonia': 0.356,\n",
    "    'recall-Pneumonia': 0.148,\n",
    "    'f1-Pneumonia': 0.209,\n",
    "\n",
    "    'prec-Cardiomegaly': 0.221,\n",
    "    'recall-Cardiomegaly': 0.071,\n",
    "    'f1-Cardiomegaly': 0.108,\n",
    "\n",
    "    'prec-Edema': 0.134,\n",
    "    'recall-Edema': 0.038,\n",
    "    'f1-Edema': 0.059,\n",
    "\n",
    "    'prec-Support Devices': 0.143,\n",
    "    'recall-Support Devices': 0.017,\n",
    "    'f1-Support Devices': 0.0317,\n",
    "\n",
    "    'prec-Consolidation': 0.089,\n",
    "    'recall-Consolidation': 0.0119,\n",
    "    'f1-Consolidation': 0.0209,\n",
    "\n",
    "    'prec-Lung Lesion': 0.0667,\n",
    "    'recall-Lung Lesion': 0.0062,\n",
    "    'f1-Lung Lesion': 0.0113,\n",
    "\n",
    "    'prec-Pneumothorax': 0.0323,\n",
    "    'recall-Pneumothorax': 0.0021,\n",
    "    'f1-Pneumothorax': 0.0040,\n",
    "\n",
    "    'prec-Enlarged Cardiomediastinum': 0.,\n",
    "    'recall-Enlarged Cardiomediastinum': 0.,\n",
    "    'f1-Enlarged Cardiomediastinum': 0.,\n",
    "    'prec-Fracture': 0.,\n",
    "    'recall-Fracture': 0.,\n",
    "    'f1-Fracture': 0.,\n",
    "    'prec-Pleural Other': 0.,\n",
    "    'recall-Pleural Other': 0.,\n",
    "    'f1-Pleural Other': 0.,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=True)\n",
    "d2 = compute_mean(_values, ['prec', 'recall', 'f1'], no_finding=False)\n",
    "d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_results = {'test': { **_values, **d1, **d2 } }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_chexpert_metrics(mimic_folder_arl, chexpert_results)\n",
    "save_runtime_metrics(mimic_folder_arl, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Survey IU papers\n",
    "\n",
    "Papers that only report NLP metrics in IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PAPER_RESULTS = [\n",
    "    # paper, bleu1, bleu2, bleu3, bleu4, rougeL, cider-D\n",
    "    # ('coatt', 0.517, 0.386, 0.306, 0.247, 0.447, 0.327), # findings+impression\n",
    "#     ('hrgr', 0.438, 0.298, 0.208, 0.151, 0.369, 0.343),\n",
    "#     ('kerp', 0.482, 0.325, 0.226, 0.162, 0.339, 0.280),\n",
    "#     ('tienet', 0.330, 0.194, 0.124, 0.081, 0.311, 1.334), # Reported in Liu et al.\n",
    "#     ('rtmic', 0.350, 0.234, 0.143, 0.096, None, 0.323), # Cider, not -D\n",
    "#     ('clara', 0.471, 0.324, 0.214, 0.199, None, 0.359),\n",
    "#     ('syeda-et-al', 0.560, 0.510, 0.500, 0.490, 0.580, None), # findings+impression, apparently\n",
    "#     ('vispi', 0.419, 0.280, 0.201, 0.150, 0.371, 0.553), # findings + impression\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for result in PAPER_RESULTS:\n",
    "    paper, bleu1, bleu2, bleu3, bleu4, rougeL, ciderD = result\n",
    "    folder = get_paper_folder('iu-x-ray', paper)\n",
    "    \n",
    "    d = {\n",
    "        'bleu1': bleu1, 'bleu2': bleu2, 'bleu3': bleu3, 'bleu4': bleu4,\n",
    "        'bleu': np.mean([bleu1, bleu2, bleu3, bleu4]), # will fail if any is None\n",
    "    }\n",
    "    if ciderD is not None:\n",
    "        d['ciderD'] = ciderD\n",
    "    if rougeL is not None:\n",
    "        d['rougeL'] = rougeL\n",
    "    \n",
    "    runtime_results = {'test': d}\n",
    "    \n",
    "    save_runtime_metrics(folder, runtime_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Show (attend) tell re-implementations\n",
    "\n",
    "Also more CoAtt re-implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _check_validity(d):\n",
    "    total_errors = 0\n",
    "    for model_name, reimpls in d.items():\n",
    "        errors = []\n",
    "        for reim in reimpls:\n",
    "            if not isinstance(reim, tuple):\n",
    "                errors.append(f'Not tuple: {reim}')\n",
    "                continue\n",
    "            paper_name = reim[0]\n",
    "            if len(reim) != 12:\n",
    "                errors.append(f'Len not 12: {paper_name}, len={len(reim)}')\n",
    "        if errors:\n",
    "            print(f'{model_name}:\\n\\t{pprint.pformat(errors)}')\n",
    "        total_errors += len(errors)\n",
    "        \n",
    "    print('Total errors: ', total_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "IU_RESULTS = {\n",
    "    # paper, bleu1, bleu2, bleu3, bleu4, rougeL, meteor, cider-D, chex-acc, -f1, -p, -r\n",
    "    'show-tell': [\n",
    "        # coatt values are also used in Yin et al, CDGPT2\n",
    "        ('coatt', 0.316, 0.211, 0.140, 0.095, 0.267, 0.159, 0.111, None, None, None, None),\n",
    "        ('liu-et-al', 0.265, 0.157, 0.105, 0.073, 0.306, None, 0.926, 0.915, None, None, None),\n",
    "        ('huang-et-al', 0.251, 0.137, 0.098, 0.069, 0.294, None, 0.108, None, None, None, None),\n",
    "\n",
    "        # HRGR values are also used in: KERP, Vispi, RTMIC??, CLARA, CMAS, Chen-et-al,\n",
    "        # MedWriter\n",
    "        ('hrgr', 0.216, 0.124, 0.087, 0.066, 0.306, None, 0.294, None, None, None, None),\n",
    "        \n",
    "        ('xue-et-al-18', 0.273, 0.144, 0.116, 0.082, 0.226, 0.125, None, None, None, None, None),\n",
    "        ('singh-et-al', 0.289, 0.173, 0.119, 0.088, 0.265, 0.137, 0.270, None, None, None, None),\n",
    "        ('harzig-et-al-19a', 0.333, 0.205, 0.136, 0.094, 0.272, 0.145, 0.306, None, None, None, None),\n",
    "        ('a3fn', 0.311, 0.218, 0.137, 0.092, 0.262, None, 0.124, None, None, None, None),\n",
    "        ('rtex', None, None, None, 0.069, 0.236, None, None, None, None, 0.118, 0.088),\n",
    "        \n",
    "        # CA also used by: CMCL\n",
    "        ('liu-2021-et-al-CA', 0.352, 0.227, 0.154, 0.109, 0.313, 0.133, None, None, None, None, None),\n",
    "    ],\n",
    "    'show-attend-tell': [\n",
    "        # coatt values are also used in: Yuan et al, Yin et al, S-M (citation wrong) ??\n",
    "        ('coatt', 0.399, 0.251, 0.168, 0.118, 0.323, 0.167, 0.302, None, None, None, None),\n",
    "        ('liu-et-al', 0.328, 0.195, 0.123, 0.080, 0.313, None, 1.276, 0.908, None, None, None),\n",
    "        ('huang-et-al', 0.328, 0.184, 0.109, 0.083, 0.319, None, 0.154, None, None, None, None),\n",
    "        ('a3fn', 0.351, 0.237, 0.161, 0.120, 0.314, None, 0.278, None, None, None, None),\n",
    "        ('zhang-et-al-mirqi', 0.433, 0.281, 0.193, 0.138, 0.361, None, 0.320, None, None, None, None),\n",
    "        \n",
    "        ('liu-2021-et-al-CA', 0.371, 0.233, 0.159, 0.118, 0.320, 0.147, None, None, None, None, None),\n",
    "    ],\n",
    "    'coatt': [\n",
    "        # CA also used in: CMCL\n",
    "        ('liu-2021-et-al-CA', 0.463, 0.293, 0.207, 0.155, 0.365, 0.178, None, None, None, None, None),\n",
    "        \n",
    "# ('original-coatt', 0.517, 0.386, 0.306, 0.247, 0.447, 0.327), # findings+impression\n",
    "#     ('coatt_re-impl-hrgr', 0.455, 0.288, 0.205, 0.154, 0.369, 0.277),\n",
    "#     ('coatt_re-impl-huang-et-al', 0.429, 0.295, 0.201, 0.148, 0.340, 0.278),\n",
    "#     ('coatt_re-impl-a3fn', 0.421, 0.324, 0.225, 0.174, 0.341, 0.331),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MIMIC_RESULTS = {\n",
    "    # paper, bleu1, bleu2, bleu3, bleu4, rougeL, meteor, cider-D, chex-acc, -f1, -p, -r\n",
    "    'show-tell': [\n",
    "        # Liu et al very similar to boag et al (also both use mimic-alpha version)\n",
    "        ('liu-et-al', 0.307, 0.201, 0.137, 0.093, 0.300, None, 0.886, 0.837, None, 0.304, 0.173),\n",
    "        \n",
    "        # Boag also used by: nishino et al\n",
    "        ('boag-et-al', 0.305, 0.201, 0.137, 0.092, None, None, 0.850, 0.837, 0.186, 0.304, None),\n",
    "\n",
    "        # TODO: ratchet has chexpert details (by abn) in the supplementary\n",
    "        ('ratchet', 0.208, None, None, None, 0.217, 0.108, 0.419, None, 0.186, 0.293, 0.232),\n",
    "        \n",
    "        # Chen-et-al also used by: AlignTransformer,\n",
    "        ('chen-et-al', 0.299, 0.184, 0.121, 0.084, 0.263, 0.124, None, None, None, None, None),\n",
    "        \n",
    "        ('rtex', None, None, None, 0.078, 0.257, None, None, None, None, 0.08, 0.118),\n",
    "        \n",
    "        # CA also used by: CMCL\n",
    "        ('liu-2021-et-al-CA', 0.290, 0.182, 0.119, 0.081, 0.249, 0.112, None, None, None, None, None),\n",
    "        \n",
    "        ('medwriter', 0.247, 0.165, 0.124, 0.098, 0.314, None, 0.245, None, None, None, None),\n",
    "    ],\n",
    "    'show-attend-tell': [\n",
    "        ('liu-et-al', 0.318, 0.205, 0.137, 0.093, 0.288, None, 0.967, 0.849, None, 0.312, 0.232),\n",
    "        ('lovelace-et-al', 0.370, 0.240, 0.170, 0.128, 0.310, 0.141, 0.278, None, None, None, None),\n",
    "        ('liu-2021-et-al-CA', 0.318, 0.186, 0.122, 0.085, 0.267, 0.119, None, None, None, None, None),\n",
    "    ],\n",
    "    'coatt': [\n",
    "        # CA also used in: CMCL\n",
    "        ('liu-2021-et-al-CA', 0.329, 0.206, 0.133, 0.095, 0.273, 0.129, None, None, None, None, None),\n",
    "\n",
    "        ('medwriter', 0.410, 0.267, 0.189, 0.144, 0.274, None, 0.234, None, None, None, None),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_check_validity(MIMIC_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_SHORTEN_NAMES = {} # {'show-tell': 'ST', 'show-attend-tell': 'SAT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "NLP_METRICS = ['bleu1', 'bleu2', 'bleu3', 'bleu4', 'rougeL', 'meteor', 'ciderD']\n",
    "CHEX_METRICS = ['acc', 'f1', 'prec', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_results(res, dataset_name):\n",
    "    for model_name, reimpls in res.items():\n",
    "        model_name = _SHORTEN_NAMES.get(model_name, model_name)\n",
    "        for reim in reimpls:\n",
    "            paper_name = reim[0]\n",
    "            paper = f'{model_name}_re-impl-{paper_name}'\n",
    "            folder = get_paper_folder(dataset_name, paper)\n",
    "            \n",
    "            if os.path.isdir(folder):\n",
    "                print(f'Folder already exists, skipping: {folder}')\n",
    "                continue\n",
    "            \n",
    "            # Build nlp metrics dict\n",
    "            nlp_metrics = {\n",
    "                metric_name: value\n",
    "                for value, metric_name in zip(reim[1:], NLP_METRICS)\n",
    "                if value is not None\n",
    "            }\n",
    "            bleu1, bleu2, bleu3, bleu4 = reim[1:5]\n",
    "            if bleu1 and bleu2 and bleu3 and bleu4:\n",
    "                nlp_metrics['bleu'] = np.mean([bleu1, bleu2, bleu3, bleu4])\n",
    "\n",
    "            save_runtime_metrics(folder, {'test': nlp_metrics})\n",
    "            \n",
    "            # Build Chex metrics dict\n",
    "            chex_metrics = {\n",
    "                metric_name: value\n",
    "                for value, metric_name in zip(reim[-4:], CHEX_METRICS)\n",
    "                if value is not None\n",
    "            }\n",
    "            \n",
    "            save_chexpert_metrics(folder, {'test': chex_metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_results(IU_RESULTS, 'iu-x-ray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_results(MIMIC_RESULTS, 'mimic-cxr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
