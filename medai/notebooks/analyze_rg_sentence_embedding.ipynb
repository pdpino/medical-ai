{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/__init__.py\n",
    "config_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/checkpoint/__init__.py\n",
    "%run ../utils/files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model_wrapper(run_name):\n",
    "    run_id = RunId(run_name, False, 'rg')\n",
    "    compiled_model = load_compiled_model_report_generation(run_id)\n",
    "    \n",
    "    return run_id, compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = '0426_221511' # h-lstm-att\n",
    "# run_name = '0426_143345' # h-lstm\n",
    "run_name = '0507_111646'\n",
    "run_id, compiled_model = _load_model_wrapper(run_name)\n",
    "compiled_model.model.decoder.return_topics = True\n",
    "run_id.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = compiled_model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = {\n",
    "    'dataset_name': 'iu-x-ray',\n",
    "    'max_samples': None,\n",
    "    'hierarchical': True,\n",
    "    'frontal_only': True,\n",
    "    'image_size': (256, 256),\n",
    "    'norm_by_sample': True,\n",
    "    'batch_size': 20,\n",
    "    'vocab': compiled_model.metadata['dataset_kwargs']['vocab'],\n",
    "}\n",
    "train_dataloader = prepare_data_report_generation(dataset_type='train', **dataset_kwargs)\n",
    "val_dataloader = prepare_data_report_generation(dataset_type='val', **dataset_kwargs)\n",
    "len(train_dataloader.dataset), len(val_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = train_dataloader.dataset.get_vocab()\n",
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_READER = ReportReader(VOCAB)\n",
    "REPORT_READER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['red', 'green', 'brown', 'blue', 'cyan']\n",
    "ORGANS = ['heart', 'lungs', 'thorax', 'all', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect sentence vectors\n",
    "\n",
    "Plot distributions, write embeddings to TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Distribution of number of sentences\n",
    "\n",
    "How many reports with N sentences are generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### In datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_n_sentences_values = lambda dataset: [\n",
    "    len(list(sentence_iterator(r['tokens_idxs'])))\n",
    "    for r in dataset.iter_reports_only()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_n_sentences = get_n_sentences_values(val_dataloader.dataset)\n",
    "len(val_n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_n_sentences = get_n_sentences_values(train_dataloader.dataset)\n",
    "len(train_n_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### In predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../training/report_generation/hierarchical.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_sentences_dist(dataloader):\n",
    "    n_sentences_dist = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch.images.to(DEVICE)\n",
    "        reports = batch.reports.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = compiled_model.model(images, reports, free=True,\n",
    "                                          max_words=100, max_sentences=100)\n",
    "        gen_words, gen_stops, gen_scores, gen_topics = output\n",
    "\n",
    "        # for report in _flatten_gen_reports(gen_words, gen_stops):\n",
    "            # Use torch:\n",
    "        #     tokens, counts = report.unique(return_counts=True)\n",
    "        #     dot_index, = (tokens == END_OF_SENTENCE_IDX).nonzero(as_tuple=True)\n",
    "        #     if dot_index.size() == (0,):\n",
    "        #         # No dot present\n",
    "        #         n_sentences = 1\n",
    "        #     else:\n",
    "        #         dot_index = dot_index.item()\n",
    "        #         n_sentences = counts[index]\n",
    "\n",
    "            # Use iterator to count sentences:\n",
    "            # n_sentences = len(list(sentence_iterator(report)))\n",
    "            # n_sentences_dist.append(n_sentences)\n",
    "\n",
    "\n",
    "        # Use stops only\n",
    "        # Approximation: assumes the 1s appear all first, and the 0s all after\n",
    "        n_sentences = (gen_stops < 0.5).long().sum(dim=1).tolist()\n",
    "\n",
    "        n_sentences_dist.extend(n_sentences)\n",
    "\n",
    "    if len(n_sentences_dist) != len(dataloader.dataset):\n",
    "        print('Error: array does not match dataset size')\n",
    "        print(f'arr-len={len(n_sentences_dist)} vs dataset-len={len(dataloader.dataset)}')\n",
    "    return n_sentences_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_n_sentences_gen = compute_sentences_dist(val_dataloader)\n",
    "len(val_n_sentences_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_n_sentences_gen = compute_sentences_dist(train_dataloader)\n",
    "len(train_n_sentences_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot dataset and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_n_sentences_distribution(n_sentences, split, gt=True, max_value=20):\n",
    "    if max_value is not None:\n",
    "        kwargs = {\n",
    "            'bins': max_value,\n",
    "            'range': (0, max_value),\n",
    "        }\n",
    "    else:\n",
    "        kwargs = { 'bins': 10 }\n",
    "    \n",
    "    \n",
    "    title = f'{\"GT\" if gt else \"GEN\"}-{split}'\n",
    "    plt.title(f'N sentences per report ({title})', fontsize=20)\n",
    "    plt.hist(n_sentences, align='mid', **kwargs)\n",
    "    plt.xlabel('N sentences', fontsize=15)\n",
    "    plt.ylabel('Number of reports', fontsize=15)\n",
    "    \n",
    "    if max_value is not None:\n",
    "        outliers = [\n",
    "            val\n",
    "            for val in n_sentences\n",
    "            if val > max_value\n",
    "        ]\n",
    "        n_outliers = len(outliers)\n",
    "        if n_outliers > 0:\n",
    "            min_o = min(outliers)\n",
    "            max_o = max(outliers)\n",
    "            print(f'{n_outliers} outliers found in {title}, from {min_o} to {max_o}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MAX_VALUE = 15\n",
    "\n",
    "n_rows = 2\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(n_cols*7, n_rows*5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_n_sentences_distribution(train_n_sentences, 'train', gt=True, max_value=MAX_VALUE)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_n_sentences_distribution(val_n_sentences, 'val', gt=True, max_value=MAX_VALUE)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_n_sentences_distribution(train_n_sentences_dist, 'train', gt=False, max_value=MAX_VALUE)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_n_sentences_distribution(val_n_sentences_dist, 'val', gt=False, max_value=MAX_VALUE)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector topics\n",
    "\n",
    "Plot and analyze in TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute vectors and save to file\n",
    "\n",
    "TODO: wrap this in a function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences_and_topic_vectors_(dataloader, all_sentences, all_vectors,\n",
    "                                      all_metadata,\n",
    "                                      max_amount=None):\n",
    "    n_sentences_added = 0\n",
    "    split = dataloader.dataset.dataset_type\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        images = batch.images.to(DEVICE)\n",
    "        reports = batch.reports.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = compiled_model.model(images, reports, free=True,\n",
    "                                          max_words=100, max_sentences=100)\n",
    "        gen_words, gen_stops, _, gen_topics = output\n",
    "        gen_words = gen_words.argmax(-1) # shape: bs, n_sentences, n_words\n",
    "        gen_stops = (gen_stops > 0.5).type(torch.uint8) # shape: bs, n_sentences\n",
    "\n",
    "        for report, stops, topics in zip(gen_words, gen_stops, gen_topics):\n",
    "            for i_sentence, (sentence, should_stop, topic) in enumerate(zip(report, stops, topics)):\n",
    "                if should_stop:\n",
    "                    break\n",
    "                dot_positions, = (sentence == END_OF_SENTENCE_IDX).nonzero(as_tuple=True)\n",
    "                if len(dot_positions) == 0:\n",
    "                    first_dot = len(sentence)\n",
    "                else:\n",
    "                    first_dot = dot_positions[0].item() + 1\n",
    "                sentence = sentence[:first_dot].tolist()\n",
    "                sentence = REPORT_READER.idx_to_text(sentence)\n",
    "\n",
    "                all_sentences.append(sentence)\n",
    "                all_vectors.append(topic)\n",
    "                all_metadata.append((sentence, i_sentence, split))\n",
    "                \n",
    "                n_sentences_added += 1\n",
    "\n",
    "        if max_amount is not None and \\\n",
    "            n_sentences_added >= _MAX_SENTENCES_COLLECTION:\n",
    "            print(f'Stopped at {n_sentences_added}')\n",
    "            break\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader.dataset), len(val_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SENTENCES = []\n",
    "ALL_VECTORS = []\n",
    "ALL_METADATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sentences_and_topic_vectors_(train_dataloader,\n",
    "                                  ALL_SENTENCES, ALL_VECTORS, ALL_METADATA)\n",
    "len(ALL_SENTENCES), len(ALL_VECTORS), len(ALL_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sentences_and_topic_vectors_(val_dataloader,\n",
    "                                  ALL_SENTENCES, ALL_VECTORS, ALL_METADATA)\n",
    "len(ALL_SENTENCES), len(ALL_VECTORS), len(ALL_METADATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_VECTORS = torch.stack(ALL_VECTORS, dim=0)\n",
    "ALL_VECTORS.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe\n",
    "\n",
    "With sentences and metadata (topic vectors are added later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES_DF = pd.DataFrame(ALL_METADATA, columns=['sentence', 'position', 'split'])\n",
    "print(len(SENTENCES_DF))\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(SENTENCES_DF['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add organs per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/common/sentences2organs/compute.py\n",
    "%run ../datasets/common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organs_onehot, warnings = find_organs_for_sentences(ALL_SENTENCES)\n",
    "neutral_sentences = set(warnings['all-empty'])\n",
    "len(organs_onehot), len(neutral_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'heart' not in SENTENCES_DF.columns:\n",
    "    SENTENCES_DF = pd.concat([\n",
    "        SENTENCES_DF,\n",
    "        pd.DataFrame(organs_onehot, columns=JSRT_ORGANS)], axis=1)\n",
    "    assert len(SENTENCES_DF) == len(ALL_SENTENCES)\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES_DF['organ'] = [\n",
    "    get_main_organ(one_hot, sentence, warnings)\n",
    "    for sentence, one_hot in zip(ALL_SENTENCES, organs_onehot)\n",
    "]\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(SENTENCES_DF['organ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add diseases per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_FPATH = os.path.join(WORKSPACE_DIR, 'cache', 'labeler', 'sentences_chexpert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_df = pd.read_csv(CACHE_FPATH)\n",
    "cache_df = cache_df.loc[cache_df['sentences'].isin(set(ALL_SENTENCES))]\n",
    "print(len(cache_df))\n",
    "cache_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'No Finding' not in SENTENCES_DF.columns:\n",
    "    SENTENCES_DF = SENTENCES_DF.merge(cache_df, left_on='sentence', right_on='sentences', how='left')\n",
    "    SENTENCES_DF.fillna(-3, inplace=True)\n",
    "    assert len(SENTENCES_DF) == len(ALL_SENTENCES)\n",
    "    SENTENCES_DF = SENTENCES_DF.astype({d: 'int8' for d in CHEXPERT_DISEASES})\n",
    "    del SENTENCES_DF['sentences']\n",
    "\n",
    "print(len(SENTENCES_DF))\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(SENTENCES_DF['No Finding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cache_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SENTENCES_DF), ALL_VECTORS.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f'emb{i}' for i in range(ALL_VECTORS.size(1))]\n",
    "if 'emb0' not in SENTENCES_DF.columns:\n",
    "    SENTENCES_DF = pd.concat([\n",
    "            SENTENCES_DF,\n",
    "            pd.DataFrame(ALL_VECTORS.cpu().numpy(), columns=columns)], axis=1)\n",
    "    assert len(SENTENCES_DF) == len(ALL_SENTENCES)\n",
    "    print('Concatenated')\n",
    "\n",
    "print(len(SENTENCES_DF))\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save sentences to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(get_results_folder(run_id), 'sentence_vectors.csv')\n",
    "folder = os.path.dirname(fpath)\n",
    "os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES_DF.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load pre-computed sentences and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(get_results_folder(run_id), 'sentence_vectors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SENTENCES_DF = pd.read_csv(fpath)\n",
    "print(len(SENTENCES_DF))\n",
    "SENTENCES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot basic position distribution\n",
    "\n",
    "How many sentences are generated in X position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_positions_histogram(positions, upper_group=10,\n",
    "                             titlesize=18, labelsize=15,\n",
    "                             title='Distribution of sentence positions',\n",
    "                             barcolor=None,\n",
    "                            ):\n",
    "    \"\"\"Plots an histogram of a positions array.\n",
    "    \n",
    "    Args:\n",
    "        positions -- array with numbers indicating sentences positions\n",
    "        upper_group -- positions larger or equal to this will be grouped in one bin\n",
    "    \"\"\"\n",
    "    max_position = max(positions)\n",
    "    if upper_group >= max_position:\n",
    "        bins = range(0, max_position)\n",
    "        last_one_grouped = False\n",
    "    else:\n",
    "        bins = list(range(0, upper_group + 1)) + [max_position]\n",
    "        last_one_grouped = True\n",
    "    hist, bins = np.histogram(positions, bins=bins)\n",
    "    bins = bins[:-1]\n",
    "\n",
    "    plt.title(title, fontsize=titlesize)\n",
    "    plt.xlabel('Sentence position', fontsize=labelsize)\n",
    "    plt.ylabel('N sentences', fontsize=labelsize)\n",
    "    plt.bar(bins, hist, color=barcolor)\n",
    "\n",
    "    xlabels = list(str(i) for i in range(len(bins)))\n",
    "    if last_one_grouped:\n",
    "        xlabels[-1] = f'{xlabels[-1]}+'\n",
    "    _ = plt.xticks(range(len(xlabels)), xlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = SENTENCES_DF['position']\n",
    "len(set(positions)) # , Counter(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plot_positions_histogram(positions, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot organs distribution by sentence position\n",
    "\n",
    "How many sentences about each organ are generated in position X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_positions = [0, 1, 2, 3, 4, 5, (6,200)]\n",
    "\n",
    "n_rows = len(plot_positions)\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(n_cols * 5, n_rows * 3))\n",
    "\n",
    "for i_split, split in enumerate(('train', 'val')):\n",
    "    sub_df = SENTENCES_DF.loc[SENTENCES_DF['split'] == split]\n",
    "    \n",
    "    for i_position, position in enumerate(plot_positions):\n",
    "        if isinstance(position, tuple):\n",
    "            lower, _ = position\n",
    "            actual_upper = max(sub_df['position'])\n",
    "            position = (lower, actual_upper)\n",
    "            condition = (sub_df['position'] >= lower) & (sub_df['position'] <= actual_upper)\n",
    "        else:\n",
    "            condition = sub_df['position'] == position\n",
    "        rows = sub_df.loc[condition]\n",
    "        \n",
    "        counter = Counter(rows['organ'])\n",
    "        amounts = [counter[o] for o in ORGANS]\n",
    "        # organs, amounts = zip(*sorted(.items()))\n",
    "        \n",
    "        plt_index = i_position * n_cols + i_split + 1\n",
    "        plt.subplot(n_rows, n_cols, plt_index)\n",
    "        plt.bar(ORGANS, amounts, color=COLORS)\n",
    "        plt.title(f'Organs in {split} position={position}', fontsize=16)\n",
    "        plt.ylabel('Number of sentences', fontsize=15)\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot position distribution by organ\n",
    "\n",
    "Given organ X, in what positions is X described?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = len(ORGANS)\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(n_cols * 5, n_rows * 3))\n",
    "\n",
    "for i_split, split in enumerate(('train', 'val')):\n",
    "    sub_df = SENTENCES_DF.loc[SENTENCES_DF['split'] == split]\n",
    "    \n",
    "    for i_organ, (organ, color) in enumerate(zip(ORGANS, COLORS)):\n",
    "        rows = sub_df.loc[sub_df['organ'] == organ]\n",
    "        \n",
    "        positions = rows['position']\n",
    "        \n",
    "        plt_index = i_organ * n_cols + i_split + 1\n",
    "        plt.subplot(n_rows, n_cols, plt_index)\n",
    "        title = f'Sentence positions for {organ} ({split})'\n",
    "        plot_positions_histogram(positions, 10,\n",
    "                                 title=title, barcolor=color,\n",
    "                                 labelsize=15,\n",
    "                                )\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../tensorboard/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tb(split, sample=None, dryrun=True):\n",
    "    df = SENTENCES_DF.loc[SENTENCES_DF['split'] == split]\n",
    "\n",
    "    if sample is not None:\n",
    "        df = df.sample(sample)\n",
    "    \n",
    "    emb_cols = [c for c in SENTENCES_DF.columns if 'emb' in c]\n",
    "    embeddings = df[emb_cols].to_numpy()\n",
    "    assert embeddings.shape == (len(df), 100), f'Got {embeddings.shape}'\n",
    "    \n",
    "    # Group larger position values into one bin\n",
    "    group_greater_than = 8\n",
    "    replace_with = f'{group_greater_than}+'\n",
    "    df.replace(\n",
    "        {'position': {k:replace_with for k in range(group_greater_than, 200)}},\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    header = ['position', *JSRT_ORGANS, 'organ', *CHEXPERT_DISEASES]\n",
    "    metadata = df[header].to_numpy()\n",
    "    metadata = [tuple(map(str, x)) for x in metadata]\n",
    "    \n",
    "    tag = f'sentence_embeddings_{split}_{len(embeddings)}'\n",
    "    if dryrun:\n",
    "        print(f'Would write: {len(embeddings):,} vectors, tag={tag}')\n",
    "        return\n",
    "    \n",
    "    writer = SummaryWriter(get_tb_large_log_folder(run_id))\n",
    "    \n",
    "    writer.add_embedding(\n",
    "        embeddings,\n",
    "        metadata=metadata,\n",
    "        metadata_header=header,\n",
    "        global_step=compiled_model.get_current_epoch(),\n",
    "        tag=tag,\n",
    "    )\n",
    "    print(f'Written {len(embeddings):,} vectors, tag={tag}')\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tb('train', sample=2000, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tb('val', dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
