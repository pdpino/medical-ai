{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../utils/__init__.py\n",
    "%run ../utils/files.py\n",
    "%run ../metrics/__init__.py\n",
    "%run ../models/checkpoint/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Choose task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TASK = 'seg'\n",
    "TASK = 'rg'\n",
    "# TASK = 'cls-seg'\n",
    "# TASK = ('cls', 'cls-seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "KEY_COLS = ['run_name', 'timestamp', 'dataset_type']\n",
    "if TASK == 'rg':\n",
    "    KEY_COLS.append('free')\n",
    "KEY_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _get_run_folders(tasks, target_folder):\n",
    "    if isinstance(tasks, str):\n",
    "        tasks = (tasks,)\n",
    "    results = []\n",
    "    for task in tasks:\n",
    "        target_glob = os.path.join(WORKSPACE_DIR, _get_task_folder(task), target_folder, '*')\n",
    "        results.extend(glob.glob(target_glob))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_suffix(filename):\n",
    "    match = re.search('.*metrics-(?P<suffix>\\w*)\\.json', filename)\n",
    "    if match is None:\n",
    "        suffix = ''\n",
    "    else:\n",
    "        suffix = match.group('suffix')\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "METRIC_TYPES = [\n",
    "    'chexpert',\n",
    "    'grad-cam',\n",
    "    'mirqi',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _extract_timestamp(run_name):\n",
    "    if re.search('^\\d{4}_\\d{6}', run_name):\n",
    "        return run_name[:11]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_results():\n",
    "    results_by_metric_type = {}\n",
    "\n",
    "    for run_folder in _get_run_folders(TASK, 'results'):\n",
    "        run_name = os.path.basename(run_folder)\n",
    "        \n",
    "        if run_name == 'debug':\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(run_folder):\n",
    "            filepath = os.path.join(run_folder, filename)\n",
    "            if not os.path.isfile(filepath) or not filename.endswith('json'):\n",
    "                continue\n",
    "\n",
    "            if any(\n",
    "                s in filename\n",
    "                for s in ('thresholds-', 'training-stats')\n",
    "                ):\n",
    "                continue\n",
    "                \n",
    "            metric_type = next(\n",
    "                (met for met in METRIC_TYPES if met in filename),\n",
    "                'base', # Default if no specific metric_type is found\n",
    "            )\n",
    "\n",
    "            with open(filepath, 'r') as f:\n",
    "                results_dict = json.load(f)\n",
    "   \n",
    "            results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "            results_df.reset_index(inplace=True)\n",
    "            results_df.rename(columns={'index': 'dataset_type'}, inplace=True)\n",
    "            results_df['run_name'] = run_name\n",
    "            results_df['timestamp'] = _extract_timestamp(run_name)\n",
    "            if TASK == 'rg':\n",
    "                results_df['free'] = get_suffix(filename)           \n",
    "            \n",
    "            if metric_type not in results_by_metric_type:\n",
    "                results_by_metric_type[metric_type] = results_df\n",
    "            else:\n",
    "                prev = results_by_metric_type[metric_type]\n",
    "                results_by_metric_type[metric_type] = prev.append(results_df, ignore_index=True)\n",
    "\n",
    "    df = None\n",
    "    cols_in_order = list(KEY_COLS)\n",
    "    for results in results_by_metric_type.values():\n",
    "        cols_in_order += [col for col in results.columns if col not in cols_in_order]\n",
    "        \n",
    "        if df is None:\n",
    "            df = results\n",
    "        else:\n",
    "            df = df.merge(results, on=KEY_COLS, how='outer')\n",
    "                \n",
    "    return df[cols_in_order], results_by_metric_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_training_stats():\n",
    "    re_filename = re.compile(r'training-stats.*.json')\n",
    "\n",
    "    all_training_stats = []\n",
    "\n",
    "    for run_folder in _get_run_folders(TASK, 'models'):\n",
    "        run_name = os.path.basename(run_folder)\n",
    "\n",
    "        if run_name == 'debug':\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(run_folder):\n",
    "            if not re_filename.match(filename):\n",
    "                continue\n",
    "            \n",
    "            filepath = os.path.join(run_folder, filename)\n",
    "            if not os.path.isfile(filepath):\n",
    "                continue\n",
    "\n",
    "            with open(filepath, 'r') as f:\n",
    "                training_stats_original_dict = json.load(f)\n",
    "\n",
    "            # Unwrap dicts and fix old key-values\n",
    "            training_stats = dict()\n",
    "            for key, value in training_stats_original_dict.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for k, v in value.items():\n",
    "                        training_stats[k] = v\n",
    "                elif key == 'n_epochs' or key == 'epochs':\n",
    "                    training_stats['final_epoch'] = value\n",
    "                    training_stats['current_epoch'] = value\n",
    "                else:\n",
    "                    training_stats[key] = value\n",
    "                    \n",
    "            # Add total-time column\n",
    "            secs_per_epoch = training_stats['secs_per_epoch']\n",
    "            n_epochs = training_stats['current_epoch'] - training_stats['initial_epoch']\n",
    "            total_time = secs_per_epoch * n_epochs\n",
    "            training_stats['total_time'] = duration_to_str(total_time)\n",
    "    \n",
    "            # Add pretty-time columns\n",
    "            training_stats['time_per_epoch'] = duration_to_str(secs_per_epoch)\n",
    "    \n",
    "            # Add run_name column\n",
    "            training_stats['run_name'] = run_name\n",
    "\n",
    "            all_training_stats.append(training_stats)\n",
    "        \n",
    "    df = pd.DataFrame(all_training_stats)\n",
    "    cols = ['run_name'] + [c for c in df.columns if c != 'run_name']\n",
    "    df = df[cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Filter fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _filter_df_run_name_contains(df, contains):\n",
    "    if contains:\n",
    "        filter_contains = lambda d, s: d.loc[d['run_name'].str.contains(s)]\n",
    "        if isinstance(contains, (list, tuple)):\n",
    "            for c in contains:\n",
    "                df = filter_contains(df, c)\n",
    "        elif isinstance(contains, str):\n",
    "            df = filter_contains(df, contains)\n",
    "    return df\n",
    "\n",
    "def __rename_run_name(run_name, replace_strs):\n",
    "    s = run_name\n",
    "    for target, replace_with in replace_strs:\n",
    "        s = re.sub(target, replace_with, s)\n",
    "    return s\n",
    "\n",
    "def _df_rename_runs(df, rename_runs):\n",
    "    if rename_runs and 'run_name' in df:\n",
    "        df['run_name'] = [\n",
    "            __rename_run_name(r, rename_runs)\n",
    "            for r in df['run_name']\n",
    "        ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_renamer(replace_strs):\n",
    "    def _rename_run(run_name):\n",
    "        s = run_name\n",
    "        for target, replace_with in replace_strs:\n",
    "            s = re.sub(target, replace_with, s)\n",
    "        return s\n",
    "    return _rename_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def filter_results(dataset_type=None, metrics=None,\n",
    "                   metrics_contain=None, free=None,\n",
    "                   contains=None, doesnt_contain=None,\n",
    "                   drop=None, drop_na_rows=False, drop_key_cols=False,\n",
    "                   timestamp_col=False,\n",
    "                   rename_runs=None, remove_timestamp=False,\n",
    "                  ):\n",
    "    df = RESULTS_DF\n",
    "    \n",
    "    if dataset_type:\n",
    "        if isinstance(dataset_type, str):\n",
    "            df = df[df['dataset_type'] == dataset_type]\n",
    "        elif isinstance(dataset_type, (list, tuple)):\n",
    "            dataset_type = set(dataset_type)\n",
    "            df = df[df['dataset_type'].isin(dataset_type)]\n",
    "    \n",
    "    if free is not None:\n",
    "        free_str = 'free' if free else 'notfree'\n",
    "        df = df.loc[df['free'] == free_str]\n",
    "    \n",
    "    df = _filter_df_run_name_contains(df, contains)\n",
    "    \n",
    "    if doesnt_contain:\n",
    "        filter_doesnt_contain = lambda d, s: d.loc[~d['run_name'].str.contains(s)]\n",
    "        if isinstance(doesnt_contain, (list, tuple)):\n",
    "            for c in doesnt_contain:\n",
    "                df = filter_doesnt_contain(df, c)\n",
    "        elif isinstance(doesnt_contain, str):\n",
    "            df = filter_doesnt_contain(df, doesnt_contain)\n",
    "    \n",
    "    if drop:\n",
    "        df = df.loc[~df['run_name'].str.contains(drop)]\n",
    "        \n",
    "    if metrics_contain:\n",
    "        columns = KEY_COLS + [c for c in df.columns if metrics_contain in c]\n",
    "        df = df[columns]\n",
    "    elif metrics:\n",
    "        columns = KEY_COLS + metrics\n",
    "        df = df[columns]\n",
    "    \n",
    "    if drop_na_rows:\n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    # Drop cols with all na\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    if drop_key_cols:\n",
    "        columns = [\n",
    "            c for c in df.columns\n",
    "            if c == 'run_name' or (timestamp_col and c == 'timestamp') or c not in KEY_COLS\n",
    "        ]\n",
    "        df = df[columns]\n",
    "\n",
    "    _df_rename_runs(df, rename_runs)\n",
    "\n",
    "    if remove_timestamp:\n",
    "        df = df.replace(r'^\\d{4}_\\d{6}_', '', regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def filter_training_stats(contains=None, columns=None,\n",
    "                          rename_runs=None, remove_timestamp=False,\n",
    "                         ):\n",
    "    df = TRAINING_STATS_DF\n",
    "    \n",
    "    df = _filter_df_run_name_contains(df, contains)\n",
    "            \n",
    "    _df_rename_runs(df, rename_runs)\n",
    "    \n",
    "    if remove_timestamp:\n",
    "        df = df.replace(r'^\\d{4}_\\d{6}_', '', regex=True)\n",
    "        \n",
    "    if columns is not None:\n",
    "        df = df[columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DF, debug = load_results()\n",
    "print(len(RESULTS_DF))\n",
    "# RESULTS_DF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_STATS_DF = load_training_stats()\n",
    "print(len(TRAINING_STATS_DF))\n",
    "# TRAINING_STATS_DF.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set(\n",
    "#     col.replace('-', '_').split('_')[0]\n",
    "#     for col in RESULTS_DF.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def add_macro_avg_column(target_col):\n",
    "    matching_cols = [c for c in RESULTS_DF.columns if c.startswith(target_col)]\n",
    "    assert len(matching_cols) == 3, f'Matching cols not 3: {matching_cols}'\n",
    "    averages = RESULTS_DF[matching_cols].mean(axis=1)\n",
    "    RESULTS_DF[target_col] = averages\n",
    "    print(f'Calculated col {target_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "add_macro_avg_column('n-shapes-gen')\n",
    "add_macro_avg_column('n-holes-gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEG_METRICS = []\n",
    "organs = ('heart', 'left lung', 'right lung')\n",
    "def _add_metric(metric_name, macro=True):\n",
    "    if macro: SEG_METRICS.append(metric_name)\n",
    "    SEG_METRICS.extend(f'{metric_name}-{organ}' for organ in organs)\n",
    "_add_metric('iou')\n",
    "# _add_metric('dice')\n",
    "_add_metric('n-shapes-gen')\n",
    "_add_metric('n-holes-gen')\n",
    "SEG_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "replace_strs = [\n",
    "    # (r'^\\d{4}_\\d{6}_', ''),\n",
    "    (r'jsrt_scan_', ''),\n",
    "#     ('most-similar-image', '1nn'),\n",
    "#     ('_lr[\\d\\.]+', ''),\n",
    "#     ('_size256', ''),\n",
    "#     (r'_\\d{4}_\\d{6}_.*', ''),\n",
    "#     ('dummy-', ''),\n",
    "#     ('common', 'top'),\n",
    "#     ('-v2', ''),\n",
    "#     (r'top-(\\w)\\w+-(\\d+)', r'top-\\1-\\2'),\n",
    "#     ('_densenet-121', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filter_results(\n",
    "    metrics=SEG_METRICS,\n",
    "    dataset_type='test',\n",
    "    drop='1105_180035',\n",
    "    rename_runs=replace_strs,\n",
    ").sort_values(\n",
    "    ['n-shapes-gen', 'n-holes-gen'],\n",
    "    ascending=True,\n",
    ").set_index('run_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP_METRICS = ['bleu1', 'bleu2', 'bleu3', 'bleu4', 'bleu', 'rougeL', 'ciderD']\n",
    "# CHEXPERT_METRICS = ['recall', 'prec', 'f1'] # 'acc', 'roc_auc', \n",
    "CHEXPERT_DISEASE_METRICS = [\n",
    "    c\n",
    "    for c in RESULTS_DF.columns\n",
    "    if any(\n",
    "        c.startswith(f'{ch}-')\n",
    "        for ch in ('f1', 'recall', 'prec')\n",
    "    ) and not c.endswith('-woNF')\n",
    "]\n",
    "# CHEXPERT_RUNTIME_METRICS = [col for col in RESULTS_DF.columns if col.startswith('chex')]\n",
    "# VAR_METRICS = [c for c in RESULTS_DF.columns if 'distinct' in c]\n",
    "# MIRQI_METRICS = [c for c in RESULTS_DF.columns if 'MIRQI' in c]\n",
    "MIRQI_METRICS_v1 = ['MIRQI-f', 'MIRQI-p', 'MIRQI-r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_METRICS = [\n",
    "    'bleu', 'bleu1', 'bleu2', 'bleu3', 'bleu4',\n",
    "    'rougeL', 'ciderD',\n",
    "]\n",
    "ESSENTIAL_METRICS = [\n",
    "    'bleu', 'rougeL', 'ciderD',\n",
    "    # 'chex_f1', 'chex_acc', # 'chex_recall', 'chex_prec', # Runtime-chexpert\n",
    "    # 'MIRQI-v2-f',\n",
    "    # \n",
    "    # Holistic-chexpert:\n",
    "    # 'acc',\n",
    "    'f1', 'prec', 'recall',\n",
    "\n",
    "    # woNF:\n",
    "    # 'f1-woNF', 'prec-woNF', 'recall-woNF',\n",
    "    # 'pr_auc', 'pr_auc-woNF',\n",
    "    # 'acc',\n",
    "    # *CHEXPERT_DISEASE_METRICS,\n",
    "    *MIRQI_METRICS_v1,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_runs = [\n",
    "    # (r'_precnn-\\d{4}-\\d{6}', ''),\n",
    "    ('mimic-cxr_', ''),\n",
    "    ('iu-x-ray_', ''),\n",
    "    # ('most-similar-image', '1nn'),\n",
    "    (r'_lr(-\\w+)?[\\d\\.e\\-]+', ''),\n",
    "    # (r'_lr[\\d\\.]+', ''),\n",
    "    ('_size256', ''),\n",
    "    # ('-v2', ''),\n",
    "    ('_front', ''),\n",
    "    (r'__[\\w\\-]*', ''),\n",
    "    (r'_(pre)?cnn\\-\\d{4}\\-\\d{6}', ''),\n",
    "    ('_densenet-121-v2', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IU = False\n",
    "# MICCAI experiments:\n",
    "# iu lstm 0612_035549, best-bleu: 0621_134437\n",
    "# mimic lstm best-bleu: 0621_231122\n",
    "# iu h-coatt: 0623_120544|0623_110053\n",
    "# mimic h-coatt: 0623_192208\n",
    "CONTAINS = \\\n",
    "    ('iu-x-ray', r'(paper|(0612_035549|0623_202003|dummy|tpl.*-ordbest-v2.*0611-155356).*v4-1)') \\\n",
    "    if IU else \\\n",
    "    ('mimic-cxr',\n",
    "     r'06.*dummy-m|0617_144209|0623_103308|0625_184437|0612_233628|tpl-(chex-v1|m-chex-grouped-v6)-ordbest-v2.*cnn-0612-082139|paper',\n",
    "    )\n",
    "\n",
    "res = filter_results(\n",
    "    # contains=('iu-x-ray', '_lstm-att-v2.*hs\\-512.*_front'),\n",
    "    # contains=('mimic-cxr', r'tpl-(chex-v1-ordbest|m-chex-grouped-v6)'),\n",
    "    \n",
    "    # H-coatt models\n",
    "    # contains=('iu-x-ray', 'h-coatt.*v4-1.*mti|paper_coatt'), # __og2\n",
    "    # contains=('mimic-cxr', 'h-coatt'),\n",
    "    \n",
    "    # MICCAI template experiments:\n",
    "    # contains=('iu-x-ray', 'chex-v1|chex-v2-grouped', '0611.155356', 'v4-1'), # 0611.162006\n",
    "\n",
    "    contains=CONTAINS,\n",
    "    doesnt_contain=(\n",
    "        'dummy-baseline', 'dummy-common', '_satt', '_ssent', '_COPY', 'tiny',\n",
    "        'boag-et-al-1nn', 'liu-et-al-ccr', 'tienet', 'rtmic',\n",
    "        'most-similar-image_0519-181554', 'cls-seg', 'noisy',\n",
    "        # 'constant-mimic',\n",
    "        're-impl',\n",
    "    ),\n",
    "    dataset_type='test',\n",
    "    free=True,\n",
    "    metrics=ESSENTIAL_METRICS,\n",
    "    drop_key_cols=True,\n",
    "    timestamp_col=True,\n",
    "    # drop_na_rows=True,\n",
    "    rename_runs=rename_runs,\n",
    "    remove_timestamp=True,\n",
    ")\n",
    "res = res.set_index('run_name').sort_index() # .sort_values('f1', ascending=False)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-table to latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bold(s):\n",
    "    return '\\textbf{' + s + '}'\n",
    "\n",
    "shorten_cols = get_renamer([\n",
    "    ('-woNF', '-d'),\n",
    "    ('ciderD', 'C-D'),\n",
    "    ('bleu', 'B'),\n",
    "    ('rougeL', 'R-L'),\n",
    "    ('acc', 'Acc'),\n",
    "    ('prec', 'P'),\n",
    "    ('recall', 'R'),\n",
    "    ('f1', 'F-1'),\n",
    "    ('MIRQI-f', 'M-F-1'),\n",
    "    ('MIRQI-r', 'M-R'),\n",
    "    ('MIRQI-p', 'M-P'),\n",
    "])\n",
    "def latexify_cols(col):\n",
    "    return bold(shorten_cols(col))\n",
    "\n",
    "get_official_run_name = get_renamer([\n",
    "    # All trained models\n",
    "    ('_reports-v4-1', ''),\n",
    "    (r'_(cnn-)?\\d{4}-\\d{6}', ''),\n",
    "    ('_densenet-121', ''),\n",
    "    # Dummy models\n",
    "    (r'most-similar-image', '1-nn'),\n",
    "    ('dummy-', ''),\n",
    "    ('common-', 'top-'),\n",
    "    ('constant-.*', 'Constant'),\n",
    "    ('random', 'Random'),\n",
    "    # DL models\n",
    "    ('lstm-att.*', 'CNN-LSTM-att'),\n",
    "    # Template models\n",
    "    ('tpl', 'Templ.'),\n",
    "    (r'-chex-v1-ordbest-v2.*', ' single'),\n",
    "    # (r'-chex-v1-noisy.*', ' top-char.'),\n",
    "    (r'-chex-v2-grouped-ordbest-v2', ' grouped'),\n",
    "    (r'-m-chex-grouped-v6-ordbest-v2', ' grouped'),\n",
    "    ('-ord\\w+', ''),\n",
    "    ('h-coatt.*', 'CoAtt\\reimplemented{}\\cite{jing2017automatic}'),\n",
    "    # Papers\n",
    "    ('paper_', ''),\n",
    "    ('rtex', 'RTEX \\cite{kougia2021rtex}'),\n",
    "    ('zhang-et-al-mirqi', 'Zhang et al. \\\\\\\\findingsAndImpression{}\\cite{zhang2020graph}'),\n",
    "    ('lovelace-et-al', 'Lovelace et al. \\cite{lovelace2020learning}'),\n",
    "    ('liu-et-al-full', 'Liu et al. \\cite{liu2019clinically}'),\n",
    "    ('boag-et-al-1nn', 'Boag et al. (1-nn) \\cite{boag2020baselines}'),\n",
    "    ('boag-et-al-cnn-rnn-beam', 'Boag et al. \\cite{boag2020baselines}'),\n",
    "    ('chen-et-al', 'Chen et al. \\cite{chen2020memory}'),\n",
    "    ('clara', 'CLARA \\cite{biswal2020clara}'),\n",
    "    ('coatt', 'CoAtt \\\\\\\\findingsAndImpression{}\\cite{jing2017automatic}'),\n",
    "    ('ni-et-al', 'CVSE \\cite{ni2020embeddings}'),\n",
    "    ('hrgr', 'HRGR \\cite{li2018hybrid}'),\n",
    "    ('kerp', 'KERP \\cite{li2019knowledge}'),\n",
    "    ('syeda-et-al', 'S-M et al. \\\\\\\\findingsAndImpression{}\\cite{syeda2020chest}'),\n",
    "    # ('-mirqi', ''),\n",
    "    # (r'(\\w+)-et-al', r'\\1 et al.'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bold_best_value_in_values(values):\n",
    "    formatter = lambda x: f'{x:.3f}'\n",
    "\n",
    "    values = np.nan_to_num(values, nan=-1)\n",
    "\n",
    "    # Get max_value\n",
    "    max_value = np.max(values)\n",
    "    max_value = formatter(max_value)\n",
    "\n",
    "    values_str = []\n",
    "    for value in values:\n",
    "        if value == -1:\n",
    "            value_s = '-'\n",
    "        else:\n",
    "            value_s = formatter(value)\n",
    "        if value_s == max_value:\n",
    "            value_s = bold(value_s)\n",
    "        values_str.append(value_s)\n",
    "        \n",
    "    return values_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bold_best_value_by_column(df):\n",
    "    METRICS_RANGE_100 = set() # ('bleu', 'rougeL')\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    for col in df.columns:\n",
    "        values = df[col].values\n",
    "\n",
    "        df2[col] = bold_best_value_in_values(values)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rotated_multirow_args():\n",
    "    dataset = 'IU X-ray' if IU else 'MIMIC-CXR'\n",
    "    return '{' + str(len(res)) + '}{' + dataset + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = res.drop(columns='timestamp') if 'timestamp' in res.columns else res\n",
    "table = bold_best_value_by_column(table).rename(\n",
    "    index=get_official_run_name,\n",
    "    columns=latexify_cols,\n",
    ").reset_index().rename(columns={'run_name': bold('Model')}).to_latex(\n",
    "    float_format='%.3f',\n",
    "    column_format='l' + 'c' * len(res.columns),\n",
    "    na_rep='-',\n",
    "    index=False,\n",
    "    escape=False,\n",
    "    # bold_rows=True,\n",
    ")\n",
    "table = re.sub(r' +', ' ', table, flags=re.M)\n",
    "# Add this additional column for the dataset (IU or MIMIC)\n",
    "table = re.sub(r'^ +', '& ', table, flags=re.M)\n",
    "table = re.sub(\n",
    "    r'^\\& (CLARA|Templ\\. simple|Boag)',\n",
    "    r'\\cline{2-11}\\n& \\1', table, flags=re.M,\n",
    ")\n",
    "table = re.sub(\n",
    "    r'^\\\\midrule',\n",
    "    r'\\\\midrule\\n\\\\rotatedMultirow' + _rotated_multirow_args(),\n",
    "    table, flags=re.M,\n",
    ")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chexpert by disease table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bold_best_value_by_row(df):\n",
    "    df2 = df.copy()\n",
    "    for row in df.index:\n",
    "        values = df.loc[row].values\n",
    "        \n",
    "        df2.loc[row] = bold_best_value_in_values(values)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'f1'\n",
    "metrics = [c for c in CHEXPERT_DISEASE_METRICS if base in c] + [base]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_runs_2 = [\n",
    "    ('iu-x-ray_', ''),\n",
    "    ('mimic-cxr_', ''),\n",
    "    ('_front', ''),\n",
    "    ('tpl-chex-v1-grouped-ordbest_cnn-0611-155356_densenet-121-v2', 'densenet-121 + templates'),\n",
    "    ('dummy-', ''),\n",
    "    (r'_(precnn-)?\\d{4}-\\d{6}', ''),\n",
    "    (r'_lr(-emb)?[\\d\\.]+', ''),\n",
    "    (r'__\\w+', ''),\n",
    "    ('-v2', ''),\n",
    "    ('_cnn-freeze', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_results(\n",
    "    contains=('mimic-cxr', r'0612_215504|0612_215709|0612_233628|paper_(boag|lovelace|ni)'),\n",
    "    # contains=('iu-x-ray', r'dummy|tpl|__base|paper'),\n",
    "    # contains=('iu-x-ray', r'0611_182321|0612_012900'), # 0612_012741\n",
    "    # dummy-most|dummy-random|__freeze\n",
    "    doesnt_contain=('dummy-baseline', '_satt', '_ssent', '_COPY', 'tiny'),\n",
    "    dataset_type='test',\n",
    "    free=True,\n",
    "    metrics=metrics,\n",
    "    rename_runs=rename_runs_2,\n",
    "    drop_key_cols=True,\n",
    "    # timestamp_col=True,\n",
    "    # drop_na_rows=True,\n",
    "    remove_timestamp=True,\n",
    ").set_index('run_name').sort_index().transpose().rename(index={base: f'{base}-macro'})\n",
    "df = df.rename(\n",
    "    columns=get_official_run_name,\n",
    "    index=get_renamer([\n",
    "        (r'{}-macro'.format(base), 'Macro average'),\n",
    "        (r'{}-(\\w+)'.format(base), r'\\1'),\n",
    "    ])\n",
    ")\n",
    "df = bold_best_value_by_row(df)\n",
    "df.columns.rename(f'{base.capitalize()} by disease', inplace=True)\n",
    "table = df.to_latex(\n",
    "    float_format='%.3f',\n",
    "    column_format='l' + 'c' * len(res.columns),\n",
    "    # na_rep='-',\n",
    "    # index=False,\n",
    "    escape=False,\n",
    ")\n",
    "table = re.sub(r' +', ' ', table, flags=re.M)\n",
    "table = re.sub(\n",
    "    r'^(Macro)',\n",
    "    r'\\midrule\\n\\1', table, flags=re.M,\n",
    ")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_strs = [\n",
    "    (r'_precnn-\\d{4}-\\d{6}', ''),\n",
    "    (r'_lr[\\d\\.]+', ''),\n",
    "    (r'_lr-emb[\\d\\.]+', ''),\n",
    "    ('_size256', ''),\n",
    "    ('-v2', ''),\n",
    "    ('_front', ''),\n",
    "    (r'__[\\w\\-]*', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'run_name',\n",
    "    'time_per_epoch', 'total_time',\n",
    "    'current_epoch', 'final_epoch',\n",
    "    'batch_size', 'device', 'visible',\n",
    "]\n",
    "res = filter_training_stats(\n",
    "    contains='__base',\n",
    "    columns=cols,\n",
    "    rename_runs=replace_strs,\n",
    ")\n",
    "res = res.replace(r'^\\d{4}_\\d{6}_(.*)', r'\\1', regex=True)\n",
    "res = res.set_index('run_name').rename(index=rename_runs)\n",
    "res.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Compare runtime chexpert vs holistic chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def subtract_cols(df, cols_a, cols_b, drop_na_rows=True):\n",
    "    array_a = df[cols_a].to_numpy()\n",
    "    array_b = df[cols_b].to_numpy()\n",
    "    \n",
    "    df_2 = df[KEY_COLS].copy()\n",
    "    df_2 = pd.concat([df_2, pd.DataFrame(array_a - array_b, columns=cols_a)], axis=1)\n",
    "    \n",
    "    if drop_na_rows:\n",
    "        df_2.dropna(axis=0, inplace=True, how='any')\n",
    "    \n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metric = 'f1'\n",
    "\n",
    "runtime_chexpert = [c for c in RESULTS_DF.columns if c.startswith(f'chex_{metric}')]\n",
    "holistic_chexpert = [c for c in RESULTS_DF.columns if c.startswith(metric)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = RESULTS_DF\n",
    "df = df.loc[~df['run_name'].str.contains('dummy')]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set(df['run_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = subtract_cols(df, runtime_chexpert, holistic_chexpert)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "run_name = '0112_154506_lstm-v2_lr0.001_densenet-121-v2_noes'\n",
    "debug = False\n",
    "d1 = load_rg_outputs(run_name, debug=debug, free=True)\n",
    "d2 = load_rg_outputs(run_name, debug=debug, free=False)\n",
    "len(d1), len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1 = Counter(d1['filename'])\n",
    "c2 = Counter(d2['filename'])\n",
    "len(c1), len(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for fname in c1.keys():\n",
    "    v1 = c1[fname]\n",
    "    v2 = c2[fname]\n",
    "    if v1 != v2:\n",
    "        print('Wrong: ', fname, v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set(d2['dataset_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pretty-print (latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "replace_strs = [\n",
    "    (r'^\\d{4}_\\d{6}_', ''),\n",
    "    ('most-similar-image', '1nn'),\n",
    "    ('_lr[\\d\\.]+', ''),\n",
    "    ('_size256', ''),\n",
    "    (r'_\\d{4}_\\d{6}_.*', ''),\n",
    "    ('dummy-', ''),\n",
    "    ('common', 'top'),\n",
    "    ('-v2', ''),\n",
    "    (r'top-(\\w)\\w+-(\\d+)', r'top-\\1-\\2'),\n",
    "    ('_densenet-121', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = ['bleu', 'rougeL', 'ciderD'] + CHEXPERT_METRICS + MIRQI_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = filter_results(dataset_type='test',\n",
    "                    free=True,\n",
    "                    metrics=columns,\n",
    "                    contains='(?=_lstm-att-v2.*densenet|_lstm-v2.*densenet|dummy)',\n",
    "                    drop='0915_173951|0915_174222|0916_104739',\n",
    "                    drop_na_rows=True,\n",
    "                    rename_runs=replace_strs,\n",
    "                   )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shorten_cols = lambda s: s.replace('MIRQI-v2', 'v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df.set_index('run_name').rename(\n",
    "    index=rename_runs,\n",
    "    columns=shorten_cols,\n",
    ").sort_index().to_latex(\n",
    "    columns=[shorten_cols(c) for c in columns],\n",
    "    float_format='%.3f',\n",
    "    column_format='l' + 'c' * len(columns),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains = 'covid-x'\n",
    "# contains = 'cxr14'\n",
    "# contains = 'e0'\n",
    "# contains = '0717_120222_covid-x_densenet-121_lr1e-06_os_aug-covid'\n",
    "# contains = '0717_101812_covid-x_densenet-121_lr1e-06_os-max2_aug-covid'\n",
    "# run_name = '0717_120222_covid-x_densenet-121_lr1e-06_os_aug-covid' # WINNER\n",
    "\n",
    "# contains = '0717_101812_covid-x_densenet-121_lr1e-06_os-max2_aug-covid'\n",
    "# contains = 'covid-uc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'roc_auc', 'pr_auc', # 'hamming', #\n",
    "]\n",
    "# metrics = [\n",
    "#     'acc', 'roc_auc', 'prec', 'recall', 'roc_auc_Cardiomegaly', 'roc_auc_Pneumonia',\n",
    "#     'recall_Cardiomegaly', 'recall_Pneumonia',\n",
    "#     'iobb-masks', 'iobb-masks-Cardiomegaly', 'iobb-masks-Pneumonia',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_strs = [\n",
    "    # (r'^\\d{4}_\\d{6}_', ''),\n",
    "    # (r'_precnn-\\d{4}-\\d{6}', ''),\n",
    "    (r'_lr[e\\-\\d\\.]+', ''),\n",
    "    # (r'(cxr14|chexpert|iu-x-ray)_', ''),\n",
    "    ('_size256', ''),\n",
    "    (r'_cl-wbce_seg-w', ''),\n",
    "    (r'_seg-unw', ''),\n",
    "    # (r'_aug\\d-(touch|double|single)', ''),\n",
    "    ('_shuffle', ''),\n",
    "    ('_sch-(roc|pr)[\\-_]auc-p\\d-f0.5(-c\\d)?', ''),\n",
    "    ('_best-(roc|pr)[\\-_]auc', ''),\n",
    "    ('_norm[SD]', ''),\n",
    "    ('_labels13', ''),\n",
    "    # ('_front', ''),\n",
    "    # (r'__[\\w\\-]*', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTAINS = r'cxr14.*(?:small|tiny)|0402_062551'\n",
    "CONTAINS = 'cxr14_densenet-121'\n",
    "# CONTAINS = 'chexpert_densenet-121'\n",
    "# CONTAINS = r'chexpert' # .*(?:small|tiny)\n",
    "# CONTAINS = r'iu-x-ray.*(?:tiny)|0420_175514'\n",
    "# CONTAINS = r'iu-x-ray.*(?:small)|0420_175514'\n",
    "# CONTAINS = r'iu-x-ray_densenet-121' # 0420_175514\n",
    "\n",
    "DATASET_TYPE = 'val' if 'chex' in CONTAINS else 'test'\n",
    "\n",
    "d = filter_results(\n",
    "    contains=CONTAINS,\n",
    "    doesnt_contain=['hint', 'balance', 'Cardiomeg', 'Pneumonia'],\n",
    "    dataset_type=DATASET_TYPE,\n",
    "    metrics=metrics,\n",
    "    drop_key_cols=True,\n",
    "    # rename_runs=replace_strs,\n",
    ").sort_values('pr_auc', ascending=False)\n",
    "d.set_index('run_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta = load_metadata(RunId('0406_230221', False, 'cls'))\n",
    "meta['hparams']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_strs = [\n",
    "    (r'_lr[e\\-\\d\\.]+', ''),\n",
    "    # (r'(cxr14|chexpert|iu-x-ray)_', ''),\n",
    "    (r'_pre\\d{4}-\\d{6}', ''),\n",
    "    ('_size256', ''),\n",
    "    (r'_cl-wbce_seg-w', ''),\n",
    "    (r'_seg-unw', ''),\n",
    "    (r'_aug\\d-(touch|double|single)', ''),\n",
    "    ('_shuffle', ''),\n",
    "    ('_sch-(roc|pr)[\\-_]auc-p\\d-f0.5(-c\\d)?', ''),\n",
    "    ('_best-(roc|pr)[\\-_]auc', ''),\n",
    "    ('_norm[SD]', ''),\n",
    "    ('_labels13', ''),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'run_name',\n",
    "    'time_per_epoch', 'total_time',\n",
    "    'current_epoch', 'initial_epoch', 'final_epoch',\n",
    "    'batch_size', 'visible',\n",
    "]\n",
    "res = filter_training_stats(\n",
    "    contains=r'cxr14|chexpert',\n",
    "    columns=cols,\n",
    "    rename_runs=replace_strs,\n",
    ")\n",
    "# res = res.replace(r'^\\d{4}_\\d{6}_(.*)', r'\\1', regex=True)\n",
    "res = res.set_index('run_name').rename(index=rename_runs)\n",
    "res.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report-generation: results at different report lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_words = [20, 25, 27, 33, 44, None]\n",
    "vals_sents = [3, 4, 5, 6, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = vals_words[0]\n",
    "suffix = f'max-words-{max_words}' if max_words else ''\n",
    "all_results = load_results(suffix)\n",
    "results_df_test = create_results_df(all_results, 'test')\n",
    "results_df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
