{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/__init__.py\n",
    "config_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to rename layers\n",
    "\n",
    "For simplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_layer(name):\n",
    "    name = name.replace('classifier.1', 'classifier')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rename_layers(layers):\n",
    "    new_layers = []\n",
    "    for layer in layers:\n",
    "        layer2 = rename_layer(layer)\n",
    "        if layer2 not in layers:\n",
    "            new_layers.append((layer, layer2))\n",
    "        if layer2 != layer:\n",
    "            print(f'{layer:<42} {layer2 if layer2 != layer else \"SAME\"}')\n",
    "    return new_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publish model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/checkpoint/__init__.py\n",
    "%run ../utils/files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_model(run_name, task, override=False):\n",
    "    run_id = RunId(run_name, debug=False, task=task)\n",
    "\n",
    "    name = f'{run_id.task}-{run_id.full_name}.pt'\n",
    "    published_fpath = os.path.join(WORKSPACE_DIR, 'public_checkpoints', name)\n",
    "    \n",
    "    compiled_model = load_compiled_model(run_id)\n",
    "    \n",
    "    if not override and os.path.isfile(published_fpath):\n",
    "        print('Already published')\n",
    "        return published_fpath, compiled_model.metadata\n",
    "    \n",
    "    # Rename old layers\n",
    "    state_dict = compiled_model.model.state_dict()\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        new_key = rename_layer(key)\n",
    "        new_state_dict[new_key] = value\n",
    "    \n",
    "    # Save new checkpoint\n",
    "    torch.save(new_state_dict, published_fpath)\n",
    "    \n",
    "    print('Published to', published_fpath)\n",
    "    return published_fpath, compiled_model.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_fpath, metadata1 = publish_model('0402_062551', 'cls-seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_fpath, metadata2 = publish_model('0422_163242', 'cls-seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplfied definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "_ASSERT_IN_OUT_IMAGE_SIZE = False\n",
    "\n",
    "N_CL_DISEASES = 14\n",
    "N_SEG_LABELS = 4\n",
    "\n",
    "def get_adaptive_pooling_layer(drop=0):\n",
    "    \"\"\"Returns a torch layer with AdaptivePooling2d, plus dropout if needed.\"\"\"\n",
    "    layers = [nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten()]\n",
    "\n",
    "    if drop > 0:\n",
    "        layers.append(nn.Dropout(drop))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class ImageNetClsSegModel(nn.Module):\n",
    "    def __init__(self, freeze=False, dropout_features=0):\n",
    "        super().__init__()\n",
    "        densenet = models.densenet121(\n",
    "          drop_rate=0.3,\n",
    "          pretrained=False, # Not needed if using load_state_dict() later\n",
    "        )\n",
    "        densenet_features_size = 1024\n",
    "        \n",
    "        # Copy densenet features\n",
    "        self.features = densenet.features\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.features.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # NOTE: this setup works for image input sizes 256, 512, 1024, to output the exact\n",
    "        # same size in the segmentator.\n",
    "        # Other input sizes (as 200) may not work\n",
    "        self.segmentator = nn.Sequential(\n",
    "            # in: features_size, f-height, f-width\n",
    "            nn.ConvTranspose2d(densenet_features_size, 4, 4, 2, padding=1),\n",
    "            # out: 4, 2x fheight, 2x fwidth\n",
    "            nn.ConvTranspose2d(4, N_SEG_LABELS, 32, 16, padding=8),\n",
    "            # out: n_seg_labels, in_size, in_size\n",
    "        )\n",
    "\n",
    "        self.cl_reduction = get_adaptive_pooling_layer(drop=dropout_features)\n",
    "        \n",
    "        self.classifier = nn.Linear(densenet_features_size, N_CL_DISEASES)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size()[-2:]\n",
    "\n",
    "        x = self.features(x)\n",
    "        # shape: batch_size, n_features, features-height, features-width\n",
    "\n",
    "        classification = self.classifier(self.cl_reduction(x))\n",
    "        # shape: batch_size, n_cl_diseases\n",
    "\n",
    "        segmentation = self.segmentator(x)\n",
    "        # shape: batch_size, n_seg_labels, height, width\n",
    "\n",
    "        if _ASSERT_IN_OUT_IMAGE_SIZE:\n",
    "            out_size = segmentation.size()[-2:]\n",
    "            assert in_size == out_size, f'Image sizes do not match: in={in_size} vs out={out_size}'\n",
    "\n",
    "        return classification, segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageNetClsSegModel(dropout_features=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '/mnt/workspace/medical-ai/public_checkpoints/cls-seg-0422_163242_cxr14_densenet-121-cls-seg_drop0.3_dropf0.5_normS_lr3e-05_wd0.01_sch-roc-auc-p2-f0.5-c2_aug1-double__wd.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(fpath, map_location='cpu'))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
