{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from types import MethodType\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/__init__.py\n",
    "config_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BalanceDistribution = namedtuple('BalanceDistribution', [\n",
    "    'dataloader',\n",
    "    'n_positives',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_label = {\n",
    "    'No Finding': 'NF',\n",
    "    'Enlarged Cardiomediastinum': 'Enl Card',\n",
    "    'Pleural Effusion': 'Pleural-E',\n",
    "    'Pleural Other': 'Pleural-O',\n",
    "    'Support Devices': 'Dev',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(dist, n_rows=3, n_cols=5, bins=10):\n",
    "    \"\"\"Plots a balance distribution.\n",
    "    \n",
    "    Args:\n",
    "        dataloader -- Dataloader used to calculate distributions\n",
    "        n_positives -- array/tensor of shape (n_batches, n_diseases+1), with the amount of positives by batch\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    dataloader = dist.dataloader\n",
    "    n_positives = dist.n_positives.float()\n",
    "    \n",
    "    labels = list(dataloader.dataset.labels) + ['No Finding']\n",
    "    batch_size = dataloader.batch_size\n",
    "    \n",
    "    plt.suptitle(f'BS={batch_size}, SAMPLER={str(dataloader.sampler.__class__.__name__)}')\n",
    "\n",
    "    for i_label, label_name in enumerate(labels):\n",
    "        plt.subplot(n_rows, n_cols, i_label + 1)\n",
    "        \n",
    "        # TODO: allow plotting n_positives values across epochs,\n",
    "        # i.e. plt.plot(t, n_positives[:, i_label])\n",
    "        arr = n_positives[:, i_label]\n",
    "\n",
    "        vals, _, _ = plt.hist(arr, bins=bins)\n",
    "        if i_label % n_cols == 0: plt.ylabel('Frequency')\n",
    "        if i_label // n_cols == n_rows - 1: plt.xlabel('Positive samples in a batch')\n",
    "        \n",
    "\n",
    "        mean_value = arr.mean()\n",
    "        plt.vlines(mean_value, 0, vals.max(), color='red')\n",
    "        \n",
    "        label_name = shorter_label.get(label_name, label_name)\n",
    "        plt.title(f'{label_name}, {mean_value:.1f}, {mean_value/batch_size*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_balance(create_dataloader=prepare_data_classification, **kwargs):\n",
    "    \"\"\"Computes balance of labels in a dataloader.\n",
    "    \n",
    "    \"Balance\" is defined as the average amount of positive labels in a batch, per disease.\n",
    "    \n",
    "    Args:\n",
    "        create_dataloader -- function to create the dataloader\n",
    "        **kwargs -- passed to the `create_dataloader` function\n",
    "    \"\"\"\n",
    "    dataloader = create_dataloader(**kwargs)\n",
    "\n",
    "    n_batches = len(dataloader)\n",
    "    n_labels = len(dataloader.dataset.labels)\n",
    "\n",
    "    positives_by_label = []\n",
    "    \n",
    "    checked_for_monkeypatch = False\n",
    "\n",
    "    for batch in tqdm(iter(dataloader)):\n",
    "        labels = batch.labels.sum(dim=0) # shape: n_labels\n",
    "\n",
    "        if not checked_for_monkeypatch:\n",
    "            if not (batch.image == -1).all().item():\n",
    "                print(f'Warning: dataset may be loading images, images={batch.image}')\n",
    "            checked_for_monkeypath = True\n",
    "        \n",
    "        no_finding_count = batch.labels.sum(dim=1) # shape: batch_size\n",
    "        no_finding_count = (no_finding_count == 0).sum().unsqueeze(0) # shape: 1\n",
    "        no_finding_count = no_finding_count.type(labels.dtype)\n",
    "        \n",
    "        labels = torch.cat((labels, no_finding_count), dim=0) # shape: n_labels+1\n",
    "        \n",
    "        positives_by_label.append(labels)\n",
    "\n",
    "    positives_by_label = torch.stack(positives_by_label, dim=0)\n",
    "    # shape: n_batches, n_labels+1\n",
    "\n",
    "    print('Amount of positives by label, in average: ', positives_by_label.float().mean(dim=0).tolist())\n",
    "    stats = {\n",
    "        'sampler': str(dataloader.sampler.__class__.__name__),\n",
    "        'n_samples': len(dataloader.dataset),\n",
    "        'n_batches': len(dataloader),\n",
    "        'batch_size': dataloader.batch_size,\n",
    "    }\n",
    "    print(' '.join(f'{k}={v}' for k, v in stats.items()))\n",
    "\n",
    "    return BalanceDistribution(dataloader=dataloader, n_positives=positives_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py\n",
    "%run ../datasets/common/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey patch the method, to not load images\n",
    "def getitem_labelsonly(self, idx):\n",
    "    row = self.label_index.iloc[idx]\n",
    "    labels = row[self.labels].to_numpy().astype('int')\n",
    "    \n",
    "    return BatchItem(labels=labels)\n",
    "\n",
    "CXR14Dataset.__getitem__ = getitem_labelsonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXR_14_KWARGS = {\n",
    "    'dataset_name': 'cxr14',\n",
    "    'dataset_type': 'train',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_40 = compute_average_balance(batch_size=40, **CXR_14_KWARGS)\n",
    "plot_distributions(dist_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = dist_40\n",
    "\n",
    "batch_size = dist.dataloader.batch_size\n",
    "n_diseases = len(dist.dataloader.dataset.labels)\n",
    "\n",
    "d = dist.n_positives\n",
    "d = d.sum(axis=1) # shape: n_batches\n",
    "d = d / (batch_size * n_diseases)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_40_balanced = compute_average_balance(batch_size=40, balanced_sampler=True, **CXR_14_KWARGS)\n",
    "plot_distributions(dist_40_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dist_40_balanced.dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "batch.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = dist_40_balanced\n",
    "\n",
    "batch_size = dist.dataloader.batch_size\n",
    "n_diseases = len(dist.dataloader.dataset.labels)\n",
    "\n",
    "d = dist.n_positives\n",
    "d = d.sum(axis=1) # shape: n_batches\n",
    "d = d / (batch_size * n_diseases)\n",
    "\n",
    "(d < 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_100 = compute_average_balance(batch_size=100, **CXR_14_KWARGS)\n",
    "plot_distributions(dist_100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 40\n",
    "dist_40_os = compute_average_balance(batch_size=bs, oversample=True, **CXR_14_KWARGS)\n",
    "plot_distributions(dist_40_os, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bs = 40\n",
    "dist = compute_average_balance(batch_size=bs,\n",
    "                                     oversample=True,\n",
    "                                     oversample_label=1,\n",
    "                                     **CXR_14_KWARGS)\n",
    "plot_distributions(dist, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py\n",
    "%run ../datasets/common/__init__.py\n",
    "%run ../training/report_generation/flat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem_ignoreimages(self, idx):\n",
    "    report = self.reports[idx]\n",
    "    filename = report['filename']\n",
    "    labels = self.labels_by_report[filename]\n",
    "    \n",
    "    return BatchItem(labels=labels, report=report['tokens_idxs'], image=torch.tensor(-1))\n",
    "\n",
    "IUXRayDataset.__getitem__ = getitem_ignoreimages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Classification-wise (i.e. labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IU_KWARGS = {\n",
    "    'dataset_name': 'iu-x-ray',\n",
    "    'dataset_type': 'train',\n",
    "#     'create_dataloader': partial(\n",
    "#         prepare_data_report_generation,\n",
    "#         create_dataloader_fn=create_flat_dataloader,\n",
    "#     ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_10 = compute_average_balance(batch_size=10, **IU_KWARGS)\n",
    "plot_distributions(dist_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/nlp.py\n",
    "%run ../datasets/common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = prepare_data_report_generation(create_flat_dataloader,\n",
    "                                            dataset_name='iu-x-ray',\n",
    "                                            dataset_type='train',\n",
    "                                            batch_size=20,\n",
    "                                            shuffle=True,\n",
    "                                           )\n",
    "len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Load stuff to get sentences labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(dataloader.dataset.reports_dir, 'sentences_with_chexpert_labels.csv')\n",
    "sentence_labels_df = pd.read_csv(fpath, index_col='sentences')\n",
    "sentence_labels_df = sentence_labels_df[CHEXPERT_LABELS]\n",
    "sentence_labels_df.replace(-1, 1, inplace=True)\n",
    "sentence_labels_df.replace(-2, 0, inplace=True)\n",
    "sentence_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sentence_to_labels = sentence_labels_df.transpose().to_dict(orient='list')\n",
    "sentence_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader = ReportReader(dataloader.dataset.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_sentences_per_batch = []\n",
    "errors = defaultdict(list)\n",
    "\n",
    "labels_by_batch = []\n",
    "\n",
    "for batch in tqdm(iter(dataloader)):\n",
    "    sentences_counter = Counter()\n",
    "    batch_labels = np.zeros(len(CHEXPERT_LABELS) + 1)\n",
    "    \n",
    "    for report in batch.reports:\n",
    "        for sentence in sentence_iterator(report):\n",
    "            \n",
    "            sentence = report_reader.idx_to_text(sentence)\n",
    "            \n",
    "            # Count sentences\n",
    "            sentences_counter[sentence] += 1\n",
    "            \n",
    "            # Count labels\n",
    "            labels = sentence_to_labels.get(sentence, None)\n",
    "            if labels is None:\n",
    "                errors['no-labels-found'].append(sentence)\n",
    "                continue\n",
    "            no_finding = int(all(l == 0 for l in labels[1:-1]))\n",
    "            labels = np.array(labels + [no_finding]) # shape: n_diseases + 1\n",
    "            \n",
    "            batch_labels += labels\n",
    "\n",
    "    # Accumulate labels\n",
    "    labels_by_batch.append(batch_labels)\n",
    "\n",
    "    # Count sentences\n",
    "    n_sentences_in_batch = len(sentences_counter)\n",
    "    different_sentences_per_batch.append(n_sentences_in_batch)\n",
    "\n",
    "labels_by_batch = np.array(labels_by_batch) # shape: n_batches, (n_diseases+1)\n",
    "\n",
    "# Move NF to the first label\n",
    "labels_by_batch[:,0] = labels_by_batch[:,-1]\n",
    "labels_by_batch = np.delete(labels_by_batch, -1, 1) # shape: n_batches, n_diseases\n",
    "\n",
    "n_errors = {k:len(v) for k, v in errors.items()}\n",
    "\n",
    "n_errors, np.mean(different_sentences_per_batch), labels_by_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 15\n",
    "\n",
    "n_rows = 3\n",
    "n_cols = 5\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15,10), sharex=True)\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i_label, label_name in enumerate(CHEXPERT_LABELS):\n",
    "    subplot_i = i_label + 1\n",
    "    plt.subplot(n_rows, n_cols, subplot_i)\n",
    "        \n",
    "    plt.hist(labels_by_batch[:, i_label], bins=bins)\n",
    "    plt.title(label_name)\n",
    "    if i_label % n_cols == 0:\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    if i_label // n_cols == n_rows - 1:\n",
    "        plt.xlabel('Number of positives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_by_batch[:, 1:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = prepare_data_report_generation(create_flat_dataloader,\n",
    "                                            dataset_name='iu-x-ray',\n",
    "                                            dataset_type='train',\n",
    "                                            batch_size=20,\n",
    "                                            shuffle=True,\n",
    "                                           )\n",
    "len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = [\n",
    "    report_reader.idx_to_text(r)\n",
    "    for r in next(d).reports\n",
    "]\n",
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = range(len(different_sentences_per_batch))\n",
    "plt.plot(t, different_sentences_per_batch)\n",
    "\n",
    "plt.xlabel('Batch i')\n",
    "plt.ylabel('Different sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* for each sentence, search its labels in sentences_with_chexpert_labels.csv\n",
    "* Make a plot of labels seen through the batches (i.e. labels!=NF vs batch_i)\n",
    "\n",
    "* Same can be done by report (use dataset.labels_by_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(dataloader)\n",
    "n_labels = len(dataloader.dataset.labels)\n",
    "\n",
    "positives_by_label = []\n",
    "\n",
    "checked_for_monkeypatch = False\n",
    "\n",
    "for batch in tqdm(iter(dataloader)):\n",
    "    labels = batch.labels.sum(dim=0) # shape: n_labels\n",
    "\n",
    "    if not checked_for_monkeypatch:\n",
    "        if not (batch.image == -1).all().item():\n",
    "            print(f'Warning: dataset may be loading images, images={batch.images}')\n",
    "        checked_for_monkeypath = True\n",
    "\n",
    "    no_finding_count = batch.labels.sum(dim=1) # shape: batch_size\n",
    "    no_finding_count = (no_finding_count == 0).sum().unsqueeze(0) # shape: 1\n",
    "    no_finding_count = no_finding_count.type(labels.dtype)\n",
    "\n",
    "    labels = torch.cat((labels, no_finding_count), dim=0) # shape: n_labels+1\n",
    "\n",
    "    positives_by_label.append(labels)\n",
    "\n",
    "positives_by_label = torch.stack(positives_by_label, dim=0)\n",
    "# shape: n_batches, n_labels+1\n",
    "\n",
    "print('Amount of positives by label, in average: ', positives_by_label.float().mean(dim=0))\n",
    "print('Batch size: ', dataloader.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
