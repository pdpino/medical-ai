{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debug training processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n ../train_report_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "# DEVICE = torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/checkpoint/__init__.py\n",
    "%run ../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = RunId('0504_053805', False, 'rg')\n",
    "compiled_model = load_compiled_model_report_generation(run_id, device=DEVICE)\n",
    "\n",
    "compiled_model.metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = compiled_model.metadata['dataset_kwargs']['vocab']\n",
    "REPORT_READER = ReportReader(VOCAB)\n",
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 2\n",
    "\n",
    "dataset_kwargs = {\n",
    "    'dataset_name': 'iu-x-ray',\n",
    "    'hierarchical': True,\n",
    "    'max_samples': None,\n",
    "    'batch_size': BS,\n",
    "    'frontal_only': True,\n",
    "    'image_size': (256, 256),\n",
    "    'sort_samples': False,\n",
    "    'shuffle': True,\n",
    "    'masks': True,\n",
    "    'vocab': VOCAB,\n",
    "    # 'num_workers': 0,\n",
    "}\n",
    "\n",
    "train_dataloader = prepare_data_report_generation(dataset_type='train', **dataset_kwargs)\n",
    "val_dataloader = prepare_data_report_generation(dataset_type='val', **dataset_kwargs)\n",
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug hierarchical dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in train_dataloader:\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.masks.min(), batch.masks.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader = ReportReader(train_dataloader.dataset.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_idx = 0\n",
    "report = batch.reports[item_idx]\n",
    "mask = batch.masks[item_idx]\n",
    "report.size(), mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = interpolate(mask.unsqueeze(0).float(), (8, 8), mode='nearest').squeeze(0).long()\n",
    "mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "n_sentences = mask.size(0)\n",
    "n_cols = n_sentences\n",
    "\n",
    "for i_sentence in range(n_sentences):\n",
    "    submask = mask[i_sentence]\n",
    "    \n",
    "    title = f'Sentence {i_sentence}'\n",
    "    \n",
    "    min_value = submask.min().item()\n",
    "    if min_value == submask.max().item():\n",
    "        unique_value = min_value\n",
    "        title += f' (all={unique_value})'\n",
    "    \n",
    "    plt.subplot(1, n_cols, i_sentence + 1)\n",
    "    plt.imshow(submask)\n",
    "    plt.title(title)\n",
    "    # plt.axis('off')\n",
    "    \n",
    "    sentence = report_reader.idx_to_text(report[i_sentence])\n",
    "    print(f'{i_sentence}: {sentence}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "If not loaded before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/classification/__init__.py\n",
    "%run ../models/report_generation/cnn_to_seq.py\n",
    "%run ../models/checkpoint/__init__.py\n",
    "%run ../losses/optimizers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_run_name = '0706_134245_covid-kaggle_tfs-small_lr1e-06'\n",
    "debug_run = True\n",
    "\n",
    "compiled_cnn = load_compiled_model_classification(cnn_run_name,\n",
    "                                                  debug=debug_run,\n",
    "                                                  device=DEVICE)\n",
    "cnn = compiled_cnn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or new CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn('mobilenet-v2', # resnet-50 # densenet-121\n",
    "                 labels=[],\n",
    "                 imagenet=True,\n",
    "                 freeze=False,\n",
    "                ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_kwargs = {\n",
    "    'decoder_name': 'h-lstm-att-v2',\n",
    "    'vocab': VOCAB,\n",
    "    'embedding_size': 100,\n",
    "    'embedding_kwargs': { 'pretrained': 'radglove' },\n",
    "    'hidden_size': 100,\n",
    "    'features_size': cnn.features_size,\n",
    "    'teacher_forcing': True,\n",
    "    'dropout_recursive': 0,\n",
    "    'dropout_out': 0,\n",
    "    'double_bias': False,\n",
    "}\n",
    "decoder = create_decoder(**decoder_kwargs).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-2-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN2Seq(cnn, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = create_optimizer(model, custom_lr={ 'word_embedding': 0.05 }, lr=0.0001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Debug att-supervision loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../losses/out_of_target.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in train_dataloader:\n",
    "    i += 1\n",
    "    if i == 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch.stops.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch.stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = batch.masks\n",
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = F.interpolate(target.float(), (16, 16), mode='nearest') # .long()\n",
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shape = target.size()[:2]\n",
    "output = torch.rand(*shape, 16, 16)\n",
    "# output = torch.ones(*target.size())\n",
    "# output = output.view(*shape, -1)\n",
    "# output = torch.softmax(output, dim=-1)\n",
    "# output = output.view(*shape, 16, 16)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = OutOfTargetSumLoss()\n",
    "x = loss(output, target)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = F.binary_cross_entropy(output, target.float(), reduction='none')\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = loss[(target == 0) & (batch.stops.unsqueeze(-1).unsqueeze(-1) == 0)]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.tensor([]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for report in batch.reports:\n",
    "    print(REPORT_READER.idx_to_text(report.view(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_sentences = shape\n",
    "plt_index = 1\n",
    "for i_sample in range(n_samples):\n",
    "    for j_sentence in range(n_sentences):\n",
    "        mask = target[i_sample, j_sentence]\n",
    "        \n",
    "        print(batch.stops[i_sample, j_sentence], mask.min(), mask.max())\n",
    "        plt.subplot(n_samples, n_sentences, plt_index)\n",
    "        plt.imshow(mask)\n",
    "        plt_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# target = (torch.rand(1, 1, 256, 256) > 0.5).long()\n",
    "target = masks\n",
    "target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target2 = interpolate(target.float(), size=(16, 16), mode='nearest')\n",
    "target2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size, n_sentences = target.size()[:2]\n",
    "\n",
    "n_rows = batch_size\n",
    "n_cols = n_sentences * 2\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plot_index = 1\n",
    "for idx1 in range(batch_size):\n",
    "    for idx2 in range(n_sentences):\n",
    "        plt.subplot(n_rows, n_cols, plot_index)\n",
    "        plt.imshow(target[idx1][idx2])\n",
    "        plt.title(f'Original - {idx1},{idx2}')\n",
    "        plot_index += 1\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, plot_index)\n",
    "        plt.imshow(output[idx1][idx2])\n",
    "        plt.title(f'Downsampled - {idx1},{idx2}')\n",
    "        plot_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug h-reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organ-by-sentence metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../training/report_generation/hierarchical.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dataloader:\n",
    "    images = batch.images.to(DEVICE)\n",
    "    reports = batch.reports.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = compiled_model.model(images, reports, free=True,\n",
    "                                      max_words=100, max_sentences=100)\n",
    "    gen_words, gen_stops, gen_scores, gen_topics = output\n",
    "    \n",
    "    gen_reports = _flatten_gen_reports(gen_words, gen_stops, threshold=0.5)\n",
    "    gt_reports = _flatten_gt_reports(reports)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../metrics/report_generation/organ_by_sentence.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = OrganBySentence(VOCAB)\n",
    "m.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update((gen_reports, gt_reports))\n",
    "m.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(r):\n",
    "    for s in sentence_iterator(r):\n",
    "        print(REPORT_READER.idx_to_text(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r1, r2 in zip(gen_reports, gt_reports):\n",
    "    print_report(r1)\n",
    "    print('-'*30)\n",
    "    print_report(r2)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "255px",
    "width": "188px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
