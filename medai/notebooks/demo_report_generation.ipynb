{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../models/report_generation/__init__.py\n",
    "%run ../models/checkpoint/__init__.py\n",
    "%run ../utils/files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = '0716_211601_lstm-att_lr0.0001_densenet-121'\n",
    "# run_name = '0115_175006_h-lstm-att-v2_lr0.001_satt_densenet-121-v2_noes'\n",
    "# run_name = '0115_064249_h-lstm-att-v2_lr0.001_densenet-121-v2_noes_front'\n",
    "# run_name = '0401_222625_mimic-cxr_lstm-v2_lr0.0001_mobilenet-v2_size256'\n",
    "\n",
    "# run_id = RunId('0420_031015', False, 'rg', 'best-cnn')\n",
    "run_id = RunId('0426_143345', False, 'rg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder_name': 'h-lstm-v2',\n",
       " 'vocab_size': 1813,\n",
       " 'embedding_size': 100,\n",
       " 'hidden_size': 100,\n",
       " 'features_size': 1024,\n",
       " 'teacher_forcing': True,\n",
       " 'dropout_recursive': 0,\n",
       " 'dropout_out': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model = load_compiled_model_report_generation(run_id, device=DEVICE)\n",
    "_ = compiled_model.model.eval()\n",
    "compiled_model.metadata['decoder_kwargs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1813"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = compiled_model.metadata['vocab']\n",
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../training/report_generation/flat.py\n",
    "%run ../training/report_generation/hierarchical.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_name = compiled_model.metadata['decoder_kwargs']['decoder_name']\n",
    "HIERARCHICAL = is_decoder_hierarchical(decoder_name)\n",
    "if HIERARCHICAL:\n",
    "    create_dataloader = create_hierarchical_dataloader\n",
    "else:\n",
    "    create_dataloader = create_flat_dataloader\n",
    "HIERARCHICAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../datasets/__init__.py\n",
    "%run ../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3031, 385, 384)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset_kwargs = compiled_model.metadata['dataset_kwargs']\n",
    "dataset_kwargs = {\n",
    "    'create_dataloader_fn': create_dataloader,\n",
    "    'dataset_name': 'iu-x-ray',\n",
    "    'max_samples': None,\n",
    "    'frontal_only': True,\n",
    "    'image_size': (256, 256),\n",
    "    'vocab': VOCAB,\n",
    "    'batch_size': 10,\n",
    "    'vocab_greater': model_dataset_kwargs.get('vocab_greater', None),\n",
    "    'reports_version': model_dataset_kwargs.get('reports_version', LATEST_REPORTS_VERSION),\n",
    "}\n",
    "\n",
    "train_dataloader = prepare_data_report_generation(dataset_type='train', **dataset_kwargs)\n",
    "val_dataloader = prepare_data_report_generation(dataset_type='val', **dataset_kwargs)\n",
    "test_dataloader = prepare_data_report_generation(dataset_type='test', **dataset_kwargs)\n",
    "len(train_dataloader.dataset), len(val_dataloader.dataset), len(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization\n",
    "# from skimage.color import rgb2gray, gray2rgb\n",
    "# from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../training/report_generation/hierarchical.py\n",
    "%run ../utils/common.py\n",
    "%run ../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader = ReportReader(VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sample(image, report,\n",
    "                show=True, device=DEVICE, free=False, **kwargs):\n",
    "    # Prepare inputs\n",
    "    images = image.unsqueeze(0).to(device)\n",
    "    if HIERARCHICAL:\n",
    "        reports = split_sentences_and_pad(report)\n",
    "    else:\n",
    "        reports = torch.tensor(report)\n",
    "\n",
    "    reports = reports.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Pass thru model\n",
    "    if not HIERARCHICAL:\n",
    "        del kwargs['max_sentences']\n",
    "    tup = compiled_model.model(images, reports, free=free, **kwargs)\n",
    "    \n",
    "    # Parse outputs\n",
    "    if HIERARCHICAL:\n",
    "        generated = _flatten_gen_reports(tup[0], tup[1])\n",
    "    else:\n",
    "        generated = tup[0]\n",
    "        _, generated = generated.max(dim=-1)\n",
    "\n",
    "    generated = generated.squeeze(0).cpu()\n",
    "    \n",
    "    # Print result\n",
    "    original_report = report_reader.idx_to_text(report)\n",
    "    generated_report = report_reader.idx_to_text(generated)\n",
    "    if show:\n",
    "        print('GROUND TRUTH:\\n', original_report)\n",
    "        print('-'*20)\n",
    "        print('GENERATED:\\n', generated_report)\n",
    "        \n",
    "    return original_report, generated_report, tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH:\n",
      " no active disease .\n",
      "--------------------\n",
      "GENERATED:\n",
      " no acute cardiopulmonary abnormality identified . . . . . . . . . . process . . process . process . process . tumor for malignancy . dysmorphic removed three maintained maintained maintained . abnormalities . . artifact .\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "\n",
    "item = dataset[idx]\n",
    "image = item.image\n",
    "report = item.report\n",
    "\n",
    "gt, gen, other = eval_sample(image, report,\n",
    "                             free=True, max_sentences=100, max_words=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = other[1].detach().cpu()\n",
    "# stops = stops[0]\n",
    "print(stops.size())\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_words = other[0].detach().squeeze(0)\n",
    "out_words = out_words.argmax(dim=-1)\n",
    "out_words.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = other[2].detach().squeeze(0).cpu()\n",
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_color = image.detach().permute(1, 2, 0).cpu().numpy()\n",
    "image_color = arr_to_range(image_color)\n",
    "\n",
    "image_color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_idx = 1\n",
    "heatmap = scores[sentence_idx].numpy()\n",
    "heatmap = gray2rgb(heatmap)\n",
    "heatmap = resize(heatmap, image_color.shape)\n",
    "heatmap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader.idx_to_text(out_words[sentence_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization.visualize_image_attr_multiple(heatmap,\n",
    "                                            image_color,\n",
    "                                            methods=['original_image',\n",
    "                                                     'blended_heat_map'],\n",
    "                                            signs=['all', 'positive'],\n",
    "                                            cmap='jet',\n",
    "                                            show_colorbar=True,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug report-reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader = ReportReader(compiled_model.metadata['vocab'], ignore_pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 20\n",
    "\n",
    "item = train_dataset[idx]\n",
    "images = item.image\n",
    "images = item.image.unsqueeze(0).to(DEVICE)\n",
    "reports = split_sentences_and_pad(item.report)\n",
    "\n",
    "out = compiled_model.model(images, reports, free=False)\n",
    "out = out[0].argmax(dim=-1).squeeze(0).detach().cpu()\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reader.idx_to_text(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
