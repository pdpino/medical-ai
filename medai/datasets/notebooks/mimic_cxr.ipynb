{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME_PREFIX = 'mimic-cxr-2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-metadata.csv')\n",
    "metadata = pd.read_csv(fpath)\n",
    "print(len(metadata), len(metadata['dicom_id'].unique()))\n",
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-chexpert.csv')\n",
    "chexpert_df = pd.read_csv(fpath)\n",
    "chexpert_df.fillna(0, inplace=True)\n",
    "chexpert_df.replace(-1, 1, inplace=True)\n",
    "chexpert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'reports', 'reports_with_chexpert_labels.csv')\n",
    "chexpert_df_v2 = pd.read_csv(fpath)\n",
    "print(len(chexpert_df_v2))\n",
    "chexpert_df_v2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resemble the original chexpert_df dataframe:\n",
    "chexpert_df_v2['subject_id'] = [\n",
    "    int(row['filename'][5:13]) for _, row in chexpert_df_v2.iterrows()\n",
    "]\n",
    "chexpert_df_v2['study_id'] = [\n",
    "    int(row['filename'][15:23]) for _, row in chexpert_df_v2.iterrows()\n",
    "]\n",
    "chexpert_df_v2.replace({-2: 0, -1: 1}, inplace=True)\n",
    "chexpert_df_v2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check repeated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keys = ['subject_id', 'study_id', 'ViewPosition', 'StudyDate', 'StudyTime']\n",
    "df2 = metadata.merge(metadata, on=keys, how='left')\n",
    "df2 = df2.loc[df2['dicom_id_x'] != df2['dicom_id_y']]\n",
    "cols = keys + ['dicom_id_x', 'dicom_id_y', 'Rows_x', 'Columns_x', 'Rows_y', 'Columns_y']\n",
    "df2 = df2[cols]\n",
    "print(len(df2))\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unique_pairs = set()\n",
    "should_keep = list()\n",
    "for index, row in df2.iterrows():\n",
    "    d1 = row['dicom_id_x']\n",
    "    d2 = row['dicom_id_y']\n",
    "    \n",
    "    pair = ','.join(sorted([d1, d2]))\n",
    "    if pair not in unique_pairs:\n",
    "        should_keep.append(index)\n",
    "        unique_pairs.add(pair)\n",
    "len(should_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.loc[should_keep]\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df2), len(df2['dicom_id_x'].unique()), len(df2['subject_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_repeated_sample(index):\n",
    "    row = df2.iloc[index]\n",
    "    \n",
    "    subject_id = f'p{row[\"subject_id\"]}'\n",
    "    study_id = f's{row[\"study_id\"]}'\n",
    "    subfolder = subject_id[:3]\n",
    "    \n",
    "    print('Subject: ', subject_id)\n",
    "    print('Position: ', row['ViewPosition'])\n",
    "    \n",
    "    fpath_x = f'{row[\"dicom_id_x\"]}.jpg'\n",
    "    fpath_y = f'{row[\"dicom_id_y\"]}.jpg'\n",
    "\n",
    "    fpath_x = os.path.join(DATASET_DIR, 'images', subfolder, subject_id, study_id, fpath_x)\n",
    "    fpath_y = os.path.join(DATASET_DIR, 'images', subfolder, subject_id, study_id, fpath_y)\n",
    "    \n",
    "    image_x = Image.open(fpath_x)\n",
    "    image_y = Image.open(fpath_y)\n",
    "    print(image_x.size, image_x.mode)\n",
    "    print(image_y.size, image_y.mode)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_x, cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(image_y, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_repeated_sample(-21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = -1001\n",
    "row = metadata.iloc[idx]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subject_id = f'p{row[\"subject_id\"]}'\n",
    "study_id = f's{row[\"study_id\"]}'\n",
    "dicom_id = str(row['dicom_id'])\n",
    "image_fname = f'{dicom_id}.jpg'\n",
    "subfolder = subject_id[:3]\n",
    "subfolder, subject_id, study_id, image_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = os.path.join(subfolder, subject_id, study_id, image_fname)\n",
    "# name = 'p10/p10423865/s54322560/105f82f9-a511d520-332232d1-82563ed2-42ea685b.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_fpath = os.path.join(DATASET_DIR, 'images', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image = Image.open(image_fpath)\n",
    "print(image.size, image.mode)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report_fpath = os.path.join(DATASET_DIR, 'raw-reports', subfolder, subject_id, f'{study_id}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(report_fpath) as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Images by patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_images_by_patient = Counter(metadata['subject_id'])\n",
    "n_distinct_patients = len(n_images_by_patient)\n",
    "n_distinct_patients, len(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patients_and_amounts = sorted(n_images_by_patient.items(), key=lambda x: x[1], reverse=True)\n",
    "patients_and_amounts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patients_ids, amounts = zip(*patients_and_amounts)\n",
    "plt.plot(range(len(amounts)), amounts)\n",
    "plt.xlabel('Patient ID')\n",
    "plt.ylabel('N images')\n",
    "plt.title('N images by patient (MIMIC)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "amounts = np.array(amounts)\n",
    "cum_amounts = np.cumsum(amounts) / len(metadata)\n",
    "total_patients = len(amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(range(len(cum_amounts))) / total_patients, cum_amounts)\n",
    "plt.title('N images vs N patients')\n",
    "plt.ylabel('Fraction of images')\n",
    "plt.xlabel('Fraction of patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for perc in [0.2, 0.3, 0.4, 0.45, 0.5, 0.7, 0.8]:\n",
    "    n_patients = np.argmax(cum_amounts > perc) + 1\n",
    "    perc_patients = n_patients / total_patients * 100\n",
    "    \n",
    "    s1 = f'Top {n_patients:,} patients ({perc_patients:.1f}%)'\n",
    "    s2 = f'{int(perc*100)}% of the images'\n",
    "    print(f'{s1:<30} account for {s2}')\n",
    "print(f'Total patients: {total_patients:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Projection by type of patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metadata.fillna('--', inplace=True)\n",
    "metadata.replace('LL', 'LATERAL', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_proj_in_subset(condition, title):\n",
    "    patients = [patient for patient, amount in n_images_by_patient.items() if condition(amount)]\n",
    "\n",
    "    df = metadata\n",
    "    d = df.loc[df['subject_id'].isin(set(patients))]\n",
    "    images_by_proj = Counter(d['ViewPosition'])\n",
    "\n",
    "    images_by_proj = {\n",
    "        k: images_by_proj[k]\n",
    "        for k in ['PA', 'AP', 'LATERAL']\n",
    "    }\n",
    "    \n",
    "    plt.bar(images_by_proj.keys(), images_by_proj.values())\n",
    "    plt.ylabel('N images')\n",
    "    plt.title(title)\n",
    "    \n",
    "    return patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "THRESH = 100\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "pat1 = plot_proj_in_subset(lambda x: x > THRESH, f'Patients with > {THRESH}')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "pat2 = plot_proj_in_subset(lambda x: x <= THRESH, f'Patients with <= {THRESH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process\n",
    "\n",
    "i.e. run only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create master csv\n",
    "\n",
    "Containing image_id, study_id, filenames and chexpert labels (by image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only studies with a report present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n ../preprocess/mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_df = load_raw_reports_df()\n",
    "reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies_with_report = set(int(report[1:]) for report in reports_df['study'])\n",
    "len(studies_with_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check metadata vs chexpert discrepancies\n",
    "\n",
    "* Only studies with a report are kept\n",
    "* There are a few studies with no report, present in metadata and chexpert_df csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOSEN_CHEXPERT = chexpert_df\n",
    "CHOSEN_CHEXPERT = chexpert_df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata), len(CHOSEN_CHEXPERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies1 = set(metadata['study_id'])\n",
    "studies2 = set(CHOSEN_CHEXPERT['study_id'])\n",
    "assert studies2.issubset(studies1)\n",
    "len(studies1), len(studies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies11 = studies1.intersection(studies_with_report)\n",
    "studies22 = studies2.intersection(studies_with_report)\n",
    "assert studies11 == studies22\n",
    "len(studies11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge metadata and chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filtered = metadata.loc[metadata['study_id'].isin(studies_with_report)]\n",
    "len(metadata_filtered), len(set(metadata_filtered['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_filtered = CHOSEN_CHEXPERT.loc[CHOSEN_CHEXPERT['study_id'].isin(studies_with_report)]\n",
    "assert len(chexpert_filtered) == len(set(chexpert_filtered['study_id']))\n",
    "len(chexpert_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies1 = set(metadata_filtered['study_id'])\n",
    "studies2 = set(chexpert_filtered['study_id'])\n",
    "assert studies1 == studies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = metadata_filtered.merge(\n",
    "    chexpert_filtered, on=['study_id', 'subject_id'], how='inner')\n",
    "len(master_df), len(set(master_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-split.csv')\n",
    "split_df = pd.read_csv(fpath)\n",
    "split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df.merge(split_df, on=['dicom_id', 'study_id', 'subject_id'], how='inner')\n",
    "len(master_df), len(set(master_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(subject_id, study_id, dicom_id):\n",
    "    subject_id = f'p{subject_id}'\n",
    "    study_id = f's{study_id}'\n",
    "    image_fname = f'{dicom_id}.jpg'\n",
    "    subfolder = subject_id[:3]\n",
    "\n",
    "    image_fpath = os.path.join(subfolder, subject_id, study_id, image_fname)\n",
    "    report_fpath = os.path.join(subfolder, subject_id, f'{study_id}.txt')\n",
    "    \n",
    "    return image_fpath, report_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fpaths, report_fpaths = zip(*[\n",
    "    get_filenames(*ids)\n",
    "    for ids in zip(master_df['subject_id'], master_df['study_id'], master_df['dicom_id'])\n",
    "])\n",
    "len(image_fpaths), len(report_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['image_fpath'] = image_fpaths\n",
    "master_df['report_fpath'] = report_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Add report_length (chexpert_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if 'Reports' in master_df:\n",
    "    master_df['report_length'] = = [\n",
    "        len(row['Reports'].split())\n",
    "        for _, row in master_df.iterrows()\n",
    "    ]\n",
    "master_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check lateral or frontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check weird positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "positions = list(Counter(master_df['ViewPosition']).keys())\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weird_pos = positions[5:]\n",
    "weird_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['image_fpath',\n",
    "        'ViewPosition', 'PerformedProcedureStepDescription', 'ViewCodeSequence_CodeMeaning',\n",
    "        # 'dicom_id',\n",
    "       ]\n",
    "df = master_df[cols]\n",
    "weird_images = df.loc[df['ViewPosition'].isin(weird_pos)]\n",
    "print(len(weird_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weird_images.sort_values('ViewPosition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' '.join(list(weird_images['image_fpath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FRONTAL_POSITIONS = [\n",
    "    'PA', 'AP',\n",
    "    ### These were manually reviewed and are frontal positions:\n",
    "    'AP AXIAL', 'LAO', 'LPO', 'RAO',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check nan positions\n",
    "\n",
    "FIXME: For now, samples with ViewPosition == nan, maybe frontal or lateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter(master_df['ViewPosition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['image_fpath',\n",
    "        'ViewPosition', 'PerformedProcedureStepDescription', 'ViewCodeSequence_CodeMeaning',\n",
    "        # 'dicom_id',\n",
    "       ]\n",
    "df = master_df[cols]\n",
    "nan_positions = df.loc[df['ViewPosition'].isnull()]\n",
    "len(nan_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nan_positions['ViewCodeSequence_CodeMeaning'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' '.join(list(nan_positions['image_fpath'])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save master csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['dicom_id', 'subject_id', 'study_id',\n",
    "        'image_fpath', 'report_fpath',\n",
    "        'ViewPosition', 'split',\n",
    "        ]\n",
    "if 'report_length' in master_df:\n",
    "    cols.append('report_length')\n",
    "cols.extend(CHEXPERT_DISEASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = master_df[cols]\n",
    "out_df.replace('validate', 'val', inplace=True)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out_df), len(set(out_df['subject_id'])), len(set(out_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(out_df['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Check where you are saving first!!')\n",
    "# fpath = os.path.join(DATASET_DIR, 'master_metadata.v4-2-fixed.csv')\n",
    "# out_df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and tokenize reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Review reports and tokens manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/nlp.py\n",
    "%run ../mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(DATASET_DIR, 'reports', 'reports.clean.v1.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "token_appearances = Counter()\n",
    "for r in reports.values():\n",
    "    for token in r['clean_text'].split():\n",
    "        token_appearances[token] += 1\n",
    "len(token_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "more_than_k_appearances = lambda x: [(k, v) for k, v in token_appearances.items() if v > x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(more_than_k_appearances(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[(k, v) for k, v in token_appearances.items() if re.search(r'twe', k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(more_than_k_appearances(10), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_reports_with_tokens(tokens, search_in='clean_text', absent_in=None):\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = [tokens]\n",
    "    found = []\n",
    "    for report in reports.values():\n",
    "        text = report[search_in]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if re.search(token, text):\n",
    "                if absent_in is not None:\n",
    "                    if not re.search(token, report[absent_in]):\n",
    "                        continue\n",
    "                found.append(report)\n",
    "                break\n",
    "                \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = find_reports_with_tokens(r'\\b[kjhv]\\b', absent_in='text')\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences_appears = get_sentences_appearances(r['clean_text'] for r in reports.values())\n",
    "sentences = list(sentences_appears)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = [s for s in sentences if re.search(r'\\A\\W', s)]\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Actually debug tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../preprocess/tokenize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = text_to_tokens('M.D.')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Run preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../preprocess/mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Takes around 1min\n",
    "reports, token_appearances, errors = preprocess_mimic_cxr(\n",
    "    'v4-2', override=True, target_keys=['findings', 'text'])\n",
    "len(reports), len(token_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: pass studies=mini_studies to save a version with only reports from mini-mimic\n",
    "\n",
    "## took ~6seconds\n",
    "df_organs, errors = create_sentences_with_organs('v4', show=True)\n",
    "df_organs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "REPORTS_DF = load_raw_reports_df()\n",
    "REPORTS_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "master_df = pd.read_csv(fpath)\n",
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_raw_report(study_id):\n",
    "    if isinstance(study_id, str):\n",
    "        study_id = int(study_id.strip('s'))\n",
    "\n",
    "    d = master_df.loc[master_df['study_id'] == study_id]\n",
    "    \n",
    "    report_fpaths = list(d['report_fpath'].unique())\n",
    "    assert len(report_fpaths) == 1, f'Not 1 subject: {report_fpaths}'\n",
    "    report_fpath = report_fpaths[0]\n",
    "    print(report_fpath)\n",
    "    report_fpath = os.path.join(DATASET_DIR, 'raw-reports', report_fpath)\n",
    "    \n",
    "    with open(report_fpath) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies = list(f's{s}' for s in errors['tokens-empty'])\n",
    "len(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for study_id in studies:\n",
    "    print('=' * 60)\n",
    "    print('Study ID: ', study_id)\n",
    "\n",
    "    report = load_raw_report(study_id)\n",
    "    print(report)\n",
    "\n",
    "    print('-' * 30)\n",
    "\n",
    "    d = REPORTS_DF.loc[REPORTS_DF['study'] == study_id]\n",
    "    ids = list(d.index)\n",
    "    assert len(ids) == 1, f'Not 1 study: {d}'\n",
    "    d = d.loc[ids[0]]\n",
    "    for k in ['text', 'comparison', 'findings', 'impression', 'last_paragraph']:\n",
    "        print(f'{k}: {d[k]}')\n",
    "\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "d = pd.read_csv(fpath)\n",
    "d = d.loc[d['split'] == 'train']\n",
    "train_images = list(d['image_fpath'].unique())\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_folder = os.path.join(DATASET_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%time\n",
    "\n",
    "mean, std = compute_mean_std(ImageFolderIterator(image_folder, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_appearances = {\n",
    "    sentence: sentences_appears[sentence]\n",
    "    for sentence in errors['all-empty']\n",
    "}\n",
    "n_errors = sum(error_appearances.values())\n",
    "perc = n_errors / total_appearances * 100\n",
    "f'{n_errors:,}', f'{total_appearances:,}', f'{perc:.0f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = sorted(error_appearances.items(), key=lambda x: x[1], reverse=True)\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save sentence2organ in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/__init__.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from medai.datasets.iu_xray import DATASET_DIR as IU_DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(IU_DATASET_DIR, 'reports', 'sentences_with_organs_OLD.csv')\n",
    "iu_df = pd.read_csv(fpath)\n",
    "iu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df = iu_df.append(mimic_df, ignore_index=True)\n",
    "len(final_df), len(iu_df) + len(mimic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.groupby('sentences').last()\n",
    "final_df.reset_index(drop=False, inplace=True)\n",
    "print(len(final_df))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(WORKSPACE_DIR, 'sentences_with_organs.csv')\n",
    "final_df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply chexpert labeler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Option 1: use available labels\n",
    "\n",
    "MIMIC reports already come with Chexpert labels, so all there is to do is adapt the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Load original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(DATASET_DIR, 'mimic-cxr-2.0.0-chexpert.csv')\n",
    "\n",
    "original_df = pd.read_csv(fname)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Add full filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_report_fpaths(subject_id, study_id):\n",
    "    \"\"\"Given subject and study ids, returns the report filepath.\"\"\"\n",
    "    subject_id = f'p{subject_id}'\n",
    "    study_id = f's{study_id}'\n",
    "    subfolder = subject_id[:3]\n",
    "\n",
    "    report_fpath = os.path.join(subfolder, subject_id, f'{study_id}.txt')\n",
    "    \n",
    "    return report_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    get_report_fpaths(subject_id, study_id)\n",
    "    for subject_id, study_id in zip(original_df['subject_id'], original_df['study_id'])\n",
    "]\n",
    "len(filenames), len(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "original_df['filename'] = filenames\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Add cleaned reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(DATASET_DIR, 'reports', 'reports.clean.v4-2.json')\n",
    "with open(fname, 'r') as f:\n",
    "    clean_reports = json.load(f)\n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "original_df = original_df.loc[original_df['study_id'].isin(set(clean_reports))]\n",
    "len(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports = [\n",
    "    re.sub(r'\\s+', ' ', clean_reports[str(study_id)]['clean_text'])\n",
    "    for study_id in original_df['study_id']\n",
    "]\n",
    "len(reports), len(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "original_df['Reports'] = reports\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['filename', 'Reports'] + CHEXPERT_DISEASES\n",
    "adapted_df = original_df[cols]\n",
    "adapted_df.fillna(-2, inplace=True)\n",
    "adapted_df = adapted_df.astype({c:np.int8 for c in CHEXPERT_DISEASES})\n",
    "adapted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'reports', 'reports_with_chexpert_labels.csv')\n",
    "if False and os.path.isfile(fpath):\n",
    "    raise Exception('Overriding file!')\n",
    "adapted_df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Option 2: calculate again\n",
    "\n",
    "* Some findings/impression sections are poorly extracted, but the chexpert-labels were calculated for the full report --> mismatch!!\n",
    "* E.g.: extracted findings section is: \"is a .\", but the chexpert-labels are positive for some abnormalities.\n",
    "* Solution: apply the labeler again! Takes a lot of time, but run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %run ../preprocess/mimic_cxr_chexpert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Read chexpert labels to check them out!\n",
    "ACTUAL_DISEASES = CHEXPERT_DISEASES[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_DIR, 'reports', 'reports_with_chexpert_labels.csv'))\n",
    "df = df.replace({ -2: 0 })\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = df\n",
    "d = d.loc[(d[ACTUAL_DISEASES] == 0).all(axis=1)]\n",
    "d.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(d['Reports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d.loc[d['Reports'].str.startswith('no acute')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create mini-mimic\n",
    "\n",
    "Mini-mimic stats:\n",
    "\n",
    "* Total images: 43,590, train: 42,435, val: 430, test: 725\n",
    "* Frontal images: 29,189, train: 28,380, val: 289, test: 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FPATH = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "df = pd.read_csv(FPATH)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_mini = list()\n",
    "percentages = {\n",
    "    'train': 0.12,\n",
    "    'val': 0.15,\n",
    "    'test': 0.15,\n",
    "}\n",
    "\n",
    "for split in ('train', 'val', 'test'):\n",
    "    sub_df = df.loc[df['split'] == split]\n",
    "    \n",
    "    # Do not use images without frontal-lateral definition\n",
    "    sub_df = sub_df.dropna(axis=0, subset=['ViewPosition'])\n",
    "    \n",
    "    images = list(sub_df['dicom_id'])\n",
    "    k = int(percentages[split] * len(images))\n",
    "    \n",
    "    print(f'Choosing {k:,} from {split}')\n",
    "    is_mini.extend(random.sample(images, k))\n",
    "len(is_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Add column to master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_mini = set(is_mini)\n",
    "\n",
    "is_mini_column = [\n",
    "    int(dicom_id in is_mini)\n",
    "    for dicom_id in df.dicom_id\n",
    "]\n",
    "len(is_mini), len(is_mini_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['mini'] = is_mini_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(FPATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Move mini-mimic to SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FPATH = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "# df = pd.read_csv(FPATH)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[df.mini == 1]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Sum space needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_size = 0\n",
    "\n",
    "images_dir = os.path.join(DATASET_DIR, 'images')\n",
    "for image_path in tqdm(df.image_fpath):\n",
    "    fpath = os.path.join(images_dir, image_path)\n",
    "    r = os.stat(fpath)\n",
    "    total_size += r.st_size / 1024 # kbytes\n",
    "    \n",
    "total_size /= 1024 # mbytes\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_size / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Copy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dir = os.path.join(DATASET_DIR, 'images')\n",
    "target_dir = os.path.join(DATASET_DIR_FAST, 'images')\n",
    "for image_path in tqdm(df.image_fpath):\n",
    "    src_fpath = os.path.join(src_dir, image_path)\n",
    "    target_fpath = os.path.join(target_dir, image_path)\n",
    "    os.makedirs(os.path.dirname(target_fpath), exist_ok=True)\n",
    "    copyfile(src_fpath, target_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create images-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TARGET_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pbar = tqdm(total=377110)\n",
    "\n",
    "for root, dirs, filenames in os.walk(images_src):\n",
    "    for filename in filenames:\n",
    "        # Original image\n",
    "        src_path = os.path.join(root, filename)\n",
    "        \n",
    "        # Small image\n",
    "        dest_folder = root.replace('/images/', '/images-small/')\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "        dest_path = os.path.join(dest_folder, filename)\n",
    "\n",
    "        if os.path.isfile(dest_path):\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        src_image = Image.open(src_path)\n",
    "        dest_image = src_image.resize(TARGET_SIZE)\n",
    "        \n",
    "        dest_image.save(dest_path)\n",
    "        src_image.close()\n",
    "        \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Debug Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = MIMICCXRDataset('val', sort_samples=True, image_size=(256, 256))\n",
    "len(dataset), len(dataset.reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dataset = MIMICCXRDataset('train', sort_samples=True)\n",
    "len(dataset), len(dataset.reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item = dataset[4]\n",
    "item.image.size(), item.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item.image.min(), item.image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(dataset.reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(tensor_to_range01(item.image).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMICCXRDataset('train')\n",
    "train_dataset_mini = MIMICCXRDataset('train', mini=1)\n",
    "val_dataset = MIMICCXRDataset('val')\n",
    "val_dataset_mini = MIMICCXRDataset('val', mini=1)\n",
    "len(train_dataset), len(train_dataset_mini), len(val_dataset), len(val_dataset_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if dataset._mini is None:\n",
    "        return dataset.dataset_type\n",
    "    return f'mini{dataset._mini}-{dataset.dataset_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels_distribution(dataset):\n",
    "    amounts_by_disease = dataset.master_df[CHEXPERT_DISEASES].sum(\n",
    "        axis=0).sort_values(ascending=False)\n",
    "\n",
    "    plt.title(get_dataset_name(dataset), fontsize=20)\n",
    "    plt.bar(amounts_by_disease.index, amounts_by_disease.values)\n",
    "    plt.xticks(rotation=60, fontsize=15, ha='right')\n",
    "    plt.ylabel('Amount of samples', fontsize=15)\n",
    "    plt.ylim(0, max(amounts_by_disease) * 1.15)\n",
    "    y_padding = int(max(amounts_by_disease) * 0.03)\n",
    "    \n",
    "    n_samples = len(dataset.master_df)\n",
    "    for index, (disease, amount) in enumerate(amounts_by_disease.iteritems()):\n",
    "        amount = int(amount)\n",
    "        perc = amount / n_samples * 100\n",
    "        plt.text(index, amount + y_padding, f'{amount:,}\\n{perc:.0f}%', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, n_rows * 8))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_labels_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_labels_distribution(val_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_labels_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_labels_distribution(val_dataset_mini)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_words_distribution(dataset):\n",
    "    df = dataset.master_df.groupby('report_fpath').first()\n",
    "    lengths = df['report_length']\n",
    "    plt.title(f'Distribution of report-length ({get_dataset_name(dataset)})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    plt.xlabel('Number of words')\n",
    "    _ = plt.hist(lengths.values, bins=25, range=(0,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(7 * n_cols, 5*n_rows))\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_n_words_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_n_words_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_n_words_distribution(val_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_n_words_distribution(val_dataset_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontal vs lateral distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_view_position_distribution(dataset):\n",
    "    amounts = Counter(dataset.master_df['ViewPosition'])\n",
    "    \n",
    "    reduced_amounts = Counter()\n",
    "    for key, value in amounts.items():\n",
    "        key = str(key)\n",
    "        if key == 'nan':\n",
    "            reduced_key = 'nan'\n",
    "        elif key in _FRONTAL_POSITIONS:\n",
    "            reduced_key = 'frontal'\n",
    "        else:\n",
    "            reduced_key = 'lateral'\n",
    "            \n",
    "        reduced_amounts[reduced_key] += value\n",
    "    \n",
    "    plt.title(f'Frontal vs lateral ({get_dataset_name(dataset)})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    # plt.xticks(rotation=90)\n",
    "    \n",
    "    reduced_amounts = sorted(reduced_amounts.items(), key=lambda x: x[1], reverse=True)\n",
    "    keys, values = zip(*reduced_amounts)\n",
    "    plt.bar(keys, values)\n",
    "    \n",
    "    plt.ylim(0, max(values) * 1.2)\n",
    "    y_padding = max(values) * 0.03\n",
    "    n_samples = len(dataset)\n",
    "    for index, value in enumerate(values):\n",
    "        perc = value / n_samples * 100\n",
    "        text = f'{value:,}\\n{perc:.2f}%'\n",
    "        plt.text(index, value + y_padding, text, ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(n_cols * 7, n_rows * 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_view_position_distribution(train_dataset)\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_view_position_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_view_position_distribution(val_dataset)\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_view_position_distribution(val_dataset_mini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
