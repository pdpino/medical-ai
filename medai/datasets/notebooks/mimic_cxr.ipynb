{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FNAME_PREFIX = 'mimic-cxr-2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-metadata.csv')\n",
    "metadata = pd.read_csv(fpath)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-chexpert.csv')\n",
    "chexpert_df = pd.read_csv(fpath)\n",
    "chexpert_df.fillna(0, inplace=True)\n",
    "chexpert_df.replace(-1, 1, inplace=True)\n",
    "chexpert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = -1001\n",
    "row = metadata.iloc[idx]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subject_id = f'p{row[\"subject_id\"]}'\n",
    "study_id = f's{row[\"study_id\"]}'\n",
    "dicom_id = str(row['dicom_id'])\n",
    "image_fname = f'{dicom_id}.jpg'\n",
    "subfolder = subject_id[:3]\n",
    "subfolder, subject_id, study_id, image_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_fpath = os.path.join(DATASET_DIR, 'images', subfolder, subject_id, study_id, image_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image = Image.open(image_fpath)\n",
    "print(image.size)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report_fpath = os.path.join(DATASET_DIR, 'reports', subfolder, subject_id, f'{study_id}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(report_fpath) as f:\n",
    "    text = f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process\n",
    "\n",
    "i.e. run only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create master csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Keep only studies with a report present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../preprocess/mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_df = load_raw_reports_df()\n",
    "reports_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies_with_report = set(int(report[1:]) for report in reports_df['study'])\n",
    "len(studies_with_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check metadata vs chexpert discrepancies\n",
    "\n",
    "* Only studies with a report are kept\n",
    "* There are a few studies with no report, present in metadata and chexpert_df csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(metadata), len(chexpert_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies1 = set(metadata['study_id'])\n",
    "studies2 = set(chexpert_df['study_id'])\n",
    "len(studies1), len(studies2), studies2.issubset(studies1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies11 = studies1.intersection(studies_with_report)\n",
    "studies22 = studies2.intersection(studies_with_report)\n",
    "len(studies11), len(studies22), studies11 == studies22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Merge metadata and chexpert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metadata_filtered = metadata.loc[metadata['study_id'].isin(studies_with_report)]\n",
    "len(metadata_filtered), len(set(metadata_filtered['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_filtered = chexpert_df.loc[chexpert_df['study_id'].isin(studies_with_report)]\n",
    "len(chexpert_filtered), len(set(chexpert_filtered['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies1 = set(metadata_filtered['study_id'])\n",
    "studies2 = set(chexpert_filtered['study_id'])\n",
    "assert studies1 == studies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df = metadata_filtered.merge(\n",
    "    chexpert_filtered, on=['study_id', 'subject_id'], how='inner')\n",
    "len(master_df), len(set(master_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Merge with split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{FNAME_PREFIX}-split.csv')\n",
    "split_df = pd.read_csv(fpath)\n",
    "split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df = master_df.merge(split_df, on=['dicom_id', 'study_id', 'subject_id'], how='inner')\n",
    "len(master_df), len(set(master_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_filenames(subject_id, study_id, dicom_id):\n",
    "    subject_id = f'p{subject_id}'\n",
    "    study_id = f's{study_id}'\n",
    "    image_fname = f'{dicom_id}.jpg'\n",
    "    subfolder = subject_id[:3]\n",
    "\n",
    "    image_fpath = os.path.join(subfolder, subject_id, study_id, image_fname)\n",
    "    report_fpath = os.path.join(subfolder, subject_id, f'{study_id}.txt')\n",
    "    \n",
    "    return image_fpath, report_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_fpaths, report_fpaths = zip(*[\n",
    "    get_filenames(*ids)\n",
    "    for ids in zip(master_df['subject_id'], master_df['study_id'], master_df['dicom_id'])\n",
    "])\n",
    "len(image_fpaths), len(report_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df['image_fpath'] = image_fpaths\n",
    "master_df['report_fpath'] = report_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check lateral or frontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check weird positions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "positions = list(Counter(master_df['ViewPosition']).keys())\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weird_pos = positions[5:]\n",
    "weird_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['image_fpath',\n",
    "        'ViewPosition', 'PerformedProcedureStepDescription', 'ViewCodeSequence_CodeMeaning',\n",
    "        # 'dicom_id',\n",
    "       ]\n",
    "df = master_df[cols]\n",
    "weird_images = df.loc[df['ViewPosition'].isin(weird_pos)]\n",
    "print(len(weird_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weird_images.sort_values('ViewPosition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' '.join(list(weird_images['image_fpath']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FRONTAL_POSITIONS = ['PA', 'AP', 'AP AXIAL', 'LAO', 'LPO', 'RAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check nan positions\n",
    "\n",
    "FIXME: For now, samples with ViewPosition == nan, maybe frontal or lateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter(master_df['ViewPosition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['image_fpath',\n",
    "        'ViewPosition', 'PerformedProcedureStepDescription', 'ViewCodeSequence_CodeMeaning',\n",
    "        # 'dicom_id',\n",
    "       ]\n",
    "df = master_df[cols]\n",
    "nan_positions = df.loc[df['ViewPosition'].isnull()]\n",
    "len(nan_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nan_positions['ViewCodeSequence_CodeMeaning'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "' '.join(list(nan_positions['image_fpath'])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save master csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../common/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['dicom_id', 'subject_id', 'study_id',\n",
    "        'image_fpath', 'report_fpath',\n",
    "        'ViewPosition', 'split',\n",
    "        ] + CHEXPERT_DISEASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_df = master_df[cols]\n",
    "out_df.replace('validate', 'val', inplace=True)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(out_df), len(set(out_df['subject_id'])), len(set(out_df['study_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Counter(out_df['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "out_df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and tokenize reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Review reports and tokens manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/nlp.py\n",
    "%run ../mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(DATASET_DIR, 'reports', 'reports.clean.v1.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "token_appearances = Counter()\n",
    "for r in reports.values():\n",
    "    for token in r['clean_text'].split():\n",
    "        token_appearances[token] += 1\n",
    "len(token_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "more_than_k_appearances = lambda x: [(k, v) for k, v in token_appearances.items() if v > x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(more_than_k_appearances(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[(k, v) for k, v in token_appearances.items() if re.search(r'twe', k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(more_than_k_appearances(10), key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_reports_with_tokens(tokens, search_in='clean_text', absent_in=None):\n",
    "    if isinstance(tokens, str):\n",
    "        tokens = [tokens]\n",
    "    found = []\n",
    "    for report in reports.values():\n",
    "        text = report[search_in]\n",
    "        \n",
    "        for token in tokens:\n",
    "            if re.search(token, text):\n",
    "                if absent_in is not None:\n",
    "                    if not re.search(token, report[absent_in]):\n",
    "                        continue\n",
    "                found.append(report)\n",
    "                break\n",
    "                \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = find_reports_with_tokens(r'\\b[kjhv]\\b', absent_in='text')\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences_appears = get_sentences_appearances(r['clean_text'] for r in reports.values())\n",
    "sentences = list(sentences_appears)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = [s for s in sentences if re.search(r'\\A\\W', s)]\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually debug tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../preprocess/tokenize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = text_to_tokens('M.D.')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n ../preprocess/mimic_cxr.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes around 1min\n",
    "reports, token_appearances, errors = preprocess_mimic_cxr('v3')\n",
    "len(reports), len(token_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Check errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "REPORTS_DF = load_raw_reports_df()\n",
    "REPORTS_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "master_df = pd.read_csv(fpath)\n",
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_raw_report(study_id):\n",
    "    if isinstance(study_id, str):\n",
    "        study_id = int(study_id.strip('s'))\n",
    "\n",
    "    d = master_df.loc[master_df['study_id'] == study_id]\n",
    "    \n",
    "    report_fpaths = list(d['report_fpath'].unique())\n",
    "    assert len(report_fpaths) == 1, f'Not 1 subject: {report_fpaths}'\n",
    "    report_fpath = report_fpaths[0]\n",
    "    print(report_fpath)\n",
    "    report_fpath = os.path.join(DATASET_DIR, 'raw-reports', report_fpath)\n",
    "    \n",
    "    with open(report_fpath) as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "studies = list(f's{s}' for s in errors['tokens-empty'])\n",
    "len(studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for study_id in studies:\n",
    "    print('=' * 60)\n",
    "    print('Study ID: ', study_id)\n",
    "\n",
    "    report = load_raw_report(study_id)\n",
    "    print(report)\n",
    "\n",
    "    print('-' * 30)\n",
    "\n",
    "    d = REPORTS_DF.loc[REPORTS_DF['study'] == study_id]\n",
    "    ids = list(d.index)\n",
    "    assert len(ids) == 1, f'Not 1 study: {d}'\n",
    "    d = d.loc[ids[0]]\n",
    "    for k in ['text', 'comparison', 'findings', 'impression', 'last_paragraph']:\n",
    "        print(f'{k}: {d[k]}')\n",
    "\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "d = pd.read_csv(fpath)\n",
    "d = d.loc[d['split'] == 'train']\n",
    "train_images = list(d['image_fpath'].unique())\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_folder = os.path.join(DATASET_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%time\n",
    "\n",
    "mean, std = compute_mean_std(ImageFolderIterator(image_folder, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sentence2organ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../common/sentences2organs/compute.py\n",
    "%run ../common/constants.py\n",
    "%run ../../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(DATASET_DIR, 'reports', 'reports.clean.v1.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports = list(json.load(f).values())\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentences_appears = get_sentences_appearances(r['clean_text'] for r in reports)\n",
    "sentences = list(sentences_appears)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_appearances = sum(sentences_appears.values())\n",
    "total_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "organs_for_sentences, errors = find_organs_for_sentences(sentences, show=True)\n",
    "len(organs_for_sentences), len(errors['all-empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mimic_df = pd.DataFrame(organs_for_sentences, columns=JSRT_ORGANS)\n",
    "mimic_df['sentences'] = sentences\n",
    "mimic_df = mimic_df[['sentences'] + JSRT_ORGANS]\n",
    "mimic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error_appearances = {\n",
    "    sentence: sentences_appears[sentence]\n",
    "    for sentence in errors['all-empty']\n",
    "}\n",
    "n_errors = sum(error_appearances.values())\n",
    "perc = n_errors / total_appearances * 100\n",
    "f'{n_errors:,}', f'{total_appearances:,}', f'{perc:.0f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = sorted(error_appearances.items(), key=lambda x: x[1], reverse=True)\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save sentence2organ in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/__init__.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from medai.datasets.iu_xray import DATASET_DIR as IU_DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(IU_DATASET_DIR, 'reports', 'sentences_with_organs_OLD.csv')\n",
    "iu_df = pd.read_csv(fpath)\n",
    "iu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df = iu_df.append(mimic_df, ignore_index=True)\n",
    "len(final_df), len(iu_df) + len(mimic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.groupby('sentences').last()\n",
    "final_df.reset_index(drop=False, inplace=True)\n",
    "print(len(final_df))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(WORKSPACE_DIR, 'sentences_with_organs.csv')\n",
    "final_df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create mini-mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FPATH = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "df = pd.read_csv(FPATH)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_mini = list()\n",
    "percentages = {\n",
    "    'train': 0.12,\n",
    "    'val': 0.15,\n",
    "    'test': 0.15,\n",
    "}\n",
    "\n",
    "for split in ('train', 'val', 'test'):\n",
    "    sub_df = df.loc[df['split'] == split]\n",
    "    \n",
    "    # Do not use images without frontal-lateral definition\n",
    "    sub_df = sub_df.dropna(axis=0, subset=['ViewPosition'])\n",
    "    \n",
    "    images = list(sub_df['dicom_id'])\n",
    "    k = int(percentages[split] * len(images))\n",
    "    \n",
    "    print(f'Choosing {k:,} from {split}')\n",
    "    is_mini.extend(random.sample(images, k))\n",
    "len(is_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Add column to master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_mini = set(is_mini)\n",
    "\n",
    "is_mini_column = [\n",
    "    int(dicom_id in is_mini)\n",
    "    for dicom_id in df.dicom_id\n",
    "]\n",
    "len(is_mini), len(is_mini_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['mini'] = is_mini_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(FPATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move mini-mimic to SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPATH = os.path.join(DATASET_DIR, 'master_metadata.csv')\n",
    "# df = pd.read_csv(FPATH)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.mini == 1]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sum space needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_size = 0\n",
    "\n",
    "images_dir = os.path.join(DATASET_DIR, 'images')\n",
    "for image_path in tqdm(df.image_fpath):\n",
    "    fpath = os.path.join(images_dir, image_path)\n",
    "    r = os.stat(fpath)\n",
    "    total_size += r.st_size / 1024 # kbytes\n",
    "    \n",
    "total_size /= 1024 # mbytes\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_size / 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(DATASET_DIR, 'images')\n",
    "target_dir = os.path.join(DATASET_DIR_FAST, 'images')\n",
    "for image_path in tqdm(df.image_fpath):\n",
    "    src_fpath = os.path.join(src_dir, image_path)\n",
    "    target_fpath = os.path.join(target_dir, image_path)\n",
    "    os.makedirs(os.path.dirname(target_fpath), exist_ok=True)\n",
    "    copyfile(src_fpath, target_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Debug Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = MIMICCXRDataset('test', sort_samples=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item = dataset[4]\n",
    "item.image.size(), item.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item.image.min(), item.image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(tensor_to_range01(item.image).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../mimic_cxr.py\n",
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MIMICCXRDataset('train')\n",
    "train_dataset_mini = MIMICCXRDataset('train', mini=1)\n",
    "val_dataset = MIMICCXRDataset('val')\n",
    "val_dataset_mini = MIMICCXRDataset('val', mini=1)\n",
    "len(train_dataset), len(train_dataset_mini), len(val_dataset), len(val_dataset_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset):\n",
    "    if dataset._mini is None:\n",
    "        return dataset.dataset_type\n",
    "    return f'mini{dataset._mini}-{dataset.dataset_type}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_labels_distribution(dataset):\n",
    "    amounts_by_disease = dataset.master_df[CHEXPERT_DISEASES].sum(\n",
    "        axis=0).sort_values(ascending=False)\n",
    "\n",
    "    plt.title(get_dataset_name(dataset), fontsize=20)\n",
    "    plt.bar(amounts_by_disease.index, amounts_by_disease.values)\n",
    "    plt.xticks(rotation=60, fontsize=15, ha='right')\n",
    "    plt.ylabel('Amount of samples', fontsize=15)\n",
    "    plt.ylim(0, max(amounts_by_disease) * 1.15)\n",
    "    y_padding = int(max(amounts_by_disease) * 0.03)\n",
    "    \n",
    "    n_samples = len(dataset.master_df)\n",
    "    for index, (disease, amount) in enumerate(amounts_by_disease.iteritems()):\n",
    "        amount = int(amount)\n",
    "        perc = amount / n_samples * 100\n",
    "        plt.text(index, amount + y_padding, f'{amount:,}\\n{perc:.0f}%', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, n_rows * 8))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_labels_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_labels_distribution(val_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_labels_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_labels_distribution(val_dataset_mini)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_words_distribution(dataset):\n",
    "    df = dataset.master_df.groupby('report_fpath').first()\n",
    "    lengths = df['report_length']\n",
    "    plt.title(f'Distribution of report-length ({get_dataset_name(dataset)})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    plt.xlabel('Number of words')\n",
    "    _ = plt.hist(lengths.values, bins=25, range=(0,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(7 * n_cols, 5*n_rows))\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_n_words_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_n_words_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_n_words_distribution(val_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_n_words_distribution(val_dataset_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frontal vs lateral distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_view_position_distribution(dataset):\n",
    "    amounts = Counter(dataset.master_df['ViewPosition'])\n",
    "    \n",
    "    reduced_amounts = Counter()\n",
    "    for key, value in amounts.items():\n",
    "        key = str(key)\n",
    "        if key == 'nan':\n",
    "            reduced_key = 'nan'\n",
    "        elif key in _FRONTAL_POSITIONS:\n",
    "            reduced_key = 'frontal'\n",
    "        else:\n",
    "            reduced_key = 'lateral'\n",
    "            \n",
    "        reduced_amounts[reduced_key] += value\n",
    "    \n",
    "    plt.title(f'Frontal vs lateral ({get_dataset_name(dataset)})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    # plt.xticks(rotation=90)\n",
    "    \n",
    "    reduced_amounts = sorted(reduced_amounts.items(), key=lambda x: x[1], reverse=True)\n",
    "    keys, values = zip(*reduced_amounts)\n",
    "    plt.bar(keys, values)\n",
    "    \n",
    "    plt.ylim(0, max(values) * 1.2)\n",
    "    y_padding = max(values) * 0.03\n",
    "    n_samples = len(dataset)\n",
    "    for index, value in enumerate(values):\n",
    "        perc = value / n_samples * 100\n",
    "        text = f'{value:,}\\n{perc:.2f}%'\n",
    "        plt.text(index, value + y_padding, text, ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 2\n",
    "\n",
    "plt.figure(figsize=(n_cols * 7, n_rows * 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_view_position_distribution(train_dataset)\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_view_position_distribution(train_dataset_mini)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 3)\n",
    "plot_view_position_distribution(val_dataset)\n",
    "plt.subplot(n_rows, n_cols, 4)\n",
    "plot_view_position_distribution(val_dataset_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
