{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/mnt/data/radgraph/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../radgraph.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(DATA_DIR, 'dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as f:\n",
    "    all_samples = json.load(f)\n",
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_samples.keys())[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.components import node_connected_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../radgraph.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardiomegaly examples\n",
    "# key = 'p10/p10003412/s59172281.txt' # Unremarkable cardiac silhouette # Target: 9\n",
    "# key = 'p15/p15003878/s55991257.txt' # Cardiomegaly stable # Target: 26??\n",
    "# Heart size, etc\n",
    "\n",
    "# Opacities\n",
    "# key = 'p18/p18012429/s50784640.txt' # opacity # Target: 14\n",
    "key = 'p15/p15005501/s54469606.txt' # Focal infiltrate # Target: 21\n",
    "\n",
    "# Other\n",
    "# key = 'p15/p15003878/s57167019.txt'\n",
    "# key = 'p18/p18001816/s54309228.txt'\n",
    "# key = 'p15/p15003878/s57380048.txt'\n",
    "# key = 'p15/p15003878/s58677239.txt' # with uncertain\n",
    "# key = 'p15/p15001233/s54924087.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = all_samples[key]\n",
    "text = d['text'].split()\n",
    "d['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = d['entities']\n",
    "len(entities.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_report_radgraph(entities)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_id_to_tokens(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_radgraph(graph, n_cols=3, labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '14'\n",
    "subset = list(node_connected_component(graph.to_undirected(), target))\n",
    "print_id_to_tokens(graph, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = graph.subgraph(subset)\n",
    "plot_radgraph(gg, figsize=(15,8), layout='planar', labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Group all findings\n",
    "\n",
    "TODO: check edge cases:\n",
    "\n",
    "* p10/p10003412/s59172281.txt: unremarkable cardiac and mediastinal silhouettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_keys = ['id', 'findings', 'f_labels', 'locations', 'l_labels']\n",
    "class CoreFinding(namedtuple('CoreFinding', _keys)):\n",
    "    def __str__(self):\n",
    "        return f'{self.id}: {self.findings} ({self.f_labels}) - {self.locations} ({self.l_labels})'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "    def to_text(self):\n",
    "        return (self.findings + ' ' + self.locations).lower()\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.to_text() < other.to_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def entities_to_findings(entities):\n",
    "    graph = create_report_radgraph(entities)\n",
    "    nodes_data = graph.nodes.data()\n",
    "    \n",
    "    # Create useful subgraphs\n",
    "    modifiers_subgraph = graph.copy()\n",
    "    for a, b, info in graph.edges.data():\n",
    "        if info['relation'] not in ('modify', 'suggestive_of'):\n",
    "            modifiers_subgraph.remove_edge(a, b)\n",
    "\n",
    "    located_at_subgraph = graph.copy()\n",
    "    for a, b, info in graph.edges.data():\n",
    "        if info['relation'] not in ('located_at',):\n",
    "            located_at_subgraph.remove_edge(a, b)\n",
    "            \n",
    "    # Utils\n",
    "    is_finding = lambda node: 'OBS' in nodes_data[node]['label']\n",
    "    is_location = lambda node: 'ANAT' in nodes_data[node]['label']\n",
    "    get_order = lambda node: nodes_data[node]['start']\n",
    "    get_tokens = lambda node: nodes_data[node]['tokens']\n",
    "    get_label = lambda node: nodes_data[node]['label']\n",
    "    \n",
    "    def group_to_string(group):\n",
    "        if not group:\n",
    "            return '', ''\n",
    "        group = sorted(group, key=get_order)\n",
    "        labels = set(get_label(node) for node in group)\n",
    "        labels = ' '.join(str(l) for l in labels)\n",
    "\n",
    "        tokens = [get_tokens(node) for node in group]\n",
    "        tokens = ' '.join(str(g) for g in tokens)\n",
    "        return tokens, labels\n",
    "    \n",
    "    # Iterate through nodes for findings\n",
    "    core_findings = []\n",
    "    for node in graph.nodes:\n",
    "        if not is_finding(node):\n",
    "            continue\n",
    "\n",
    "        # Successors\n",
    "        modifies_nodes = list(modifiers_subgraph.successors(node))\n",
    "        if len(modifies_nodes) > 0:\n",
    "            continue\n",
    "\n",
    "        # Findings\n",
    "        ancestors = nx.ancestors(modifiers_subgraph, node)\n",
    "        branch = [node] + list(ancestors)\n",
    "        findings, f_labels = group_to_string(branch)\n",
    "\n",
    "        # Location\n",
    "        located_at = [\n",
    "            m\n",
    "            for n in branch\n",
    "            for m in located_at_subgraph.successors(n)\n",
    "        ]\n",
    "        location, l_labels = group_to_string([\n",
    "            s\n",
    "            for n in located_at if is_location(n)\n",
    "            for s in list(nx.ancestors(modifiers_subgraph, n)) + [n]\n",
    "        ])\n",
    "\n",
    "        core_findings.append(CoreFinding(\n",
    "            id=node,\n",
    "            findings=findings,\n",
    "            f_labels=f_labels,\n",
    "            locations=location,\n",
    "            l_labels=l_labels,\n",
    "        ))\n",
    "    return core_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_findings = dict()\n",
    "for report_id, sample in tqdm(all_samples.items()):\n",
    "    core_findings = entities_to_findings(sample['entities'])\n",
    "    all_findings[report_id] = core_findings\n",
    "len(all_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "next(iter(all_findings.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoreFindings -->  ChexpertLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try finding by patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_findings(keywords):\n",
    "    target_findings = []\n",
    "    out = []\n",
    "    for key, sample_findings in all_findings.items():\n",
    "        for core_finding in sample_findings:\n",
    "            report = core_finding.to_text()\n",
    "            if any(re.search(keyword, report) for keyword in keywords):\n",
    "                target_findings.append((core_finding, key))\n",
    "            else:\n",
    "                out.append((core_finding, key))\n",
    "    return target_findings, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiom_findings, out = find_target_findings([\n",
    "    'cardiomegaly',\n",
    "    r'\\bcardiac',\n",
    "    'cardiac silhouette',\n",
    "    'cardiac contour',\n",
    "    'heart',\n",
    "])\n",
    "sorted(cardiom_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumo_findings, out = find_target_findings([\n",
    "    'pneumothorax',\n",
    "    'pneumothoax',\n",
    "    'pneumothoraces',\n",
    "])\n",
    "sorted(pneumo_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings1, out = find_target_findings([\n",
    "    'opaci',\n",
    "    # 'infiltrat',\n",
    "])\n",
    "sorted(findings1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try labelling manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_unique_findings = set(\n",
    "    core_finding.to_text()\n",
    "    for sample_findings in all_findings.values()\n",
    "    for core_finding in sample_findings\n",
    ")\n",
    "len(flat_unique_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FINDING_TO_LABEL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_manually(verbose=False):\n",
    "    shortcut_to_label = {\n",
    "        k.lower(): v\n",
    "        for k, v in CHEXPERT_SHORT2LABEL.items()\n",
    "    }\n",
    "    \n",
    "    total = len(flat_unique_findings)\n",
    "    \n",
    "    for index, finding in enumerate(flat_unique_findings):\n",
    "        if finding in _FINDING_TO_LABEL:\n",
    "            continue\n",
    "\n",
    "        while True:\n",
    "            labels = input(f'({index}/{total}) {finding}: ')\n",
    "            if labels == 'q' or labels == 'quit':\n",
    "                return\n",
    "\n",
    "            labels = [l.strip().lower() for l in labels.strip().split(',')]\n",
    "\n",
    "            unrecognized_labels = [\n",
    "                l\n",
    "                for l in labels\n",
    "                if l not in shortcut_to_label and l != '-'\n",
    "            ]\n",
    "            if unrecognized_labels:\n",
    "                print('ERROR: Some labels not recognized: ', unrecognized_labels)\n",
    "                continue\n",
    "\n",
    "            labels = [\n",
    "                shortcut_to_label[l]\n",
    "                for l in labels\n",
    "                if l in shortcut_to_label\n",
    "            ]\n",
    "\n",
    "            break\n",
    "\n",
    "        if verbose:\n",
    "            print(labels)\n",
    "            \n",
    "        _FINDING_TO_LABEL[finding] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_label_manually()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %run ../../metrics/report_generation/abn_match/chexpert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "for sample_findings in all_findings.values():\n",
    "    for core_finding in sample_findings:\n",
    "        report = core_finding.locations + ' ' + core_finding.findings\n",
    "        for word in report.split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeler = ChexpertLighterLabeler(vocab, device='cpu') # DO NOT USE THIS!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for findings in all_findings.values():\n",
    "    for finding in findings:\n",
    "        report = finding.locations + ' ' + finding.findings\n",
    "        labels = labeler.label_report(report)\n",
    "        break\n",
    "    break\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ReportRadGraph(sample['entities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.ancestors(graph.graph, '11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '11'\n",
    "subset = list(node_connected_component(graph.graph.to_undirected(), target))\n",
    "graph.print_id_to_tokens(subset)\n",
    "gg = graph.graph.subgraph(subset)\n",
    "plot_radgraph(gg, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
