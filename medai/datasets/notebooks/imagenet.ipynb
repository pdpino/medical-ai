{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../imagenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '' # Fill with base folder if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DEVKIT_DIR = os.path.join(DATA_DIR, 'ILSVRC2012_devkit_t12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parse_meta_mat(devkit_root):\n",
    "    \"\"\"Copied from ImageNet torch model.\n",
    "    \n",
    "    https://pytorch.org/vision/stable/_modules/torchvision/datasets/imagenet.html#ImageNet\n",
    "    \"\"\"\n",
    "    metafile = os.path.join(devkit_root, \"data\", \"meta.mat\")\n",
    "    meta = sio.loadmat(metafile, squeeze_me=True)['synsets']\n",
    "    nums_children = list(zip(*meta))[4]\n",
    "    meta = [meta[idx] for idx, num_children in enumerate(nums_children)\n",
    "            if num_children == 0]\n",
    "    idcs, wnids, classes = list(zip(*meta))[:3]\n",
    "    classes = [tuple(clss.split(', ')) for clss in classes]\n",
    "    idx_to_wnid = {idx: wnid for idx, wnid in zip(idcs, wnids)}\n",
    "    wnid_to_classes = {wnid: clss for wnid, clss in zip(wnids, classes)}\n",
    "    return idx_to_wnid, wnid_to_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx_to_wnid, wnid_to_classes = parse_meta_mat(DEVKIT_DIR)\n",
    "len(idx_to_wnid), len(wnid_to_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wnid_ordered = [idx_to_wnid[i+1] for i in range(len(idx_to_wnid))]\n",
    "len(wnid_ordered), wnid_ordered[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes_ordered = [\n",
    "    wnid_to_classes[wnid][0]\n",
    "    for wnid in wnid_ordered\n",
    "]\n",
    "len(classes_ordered), classes_ordered[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'dataset', 'wnids.txt'), 'w') as f:\n",
    "    for wnid in wnid_ordered:\n",
    "        f.write(f'{wnid}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'dataset', 'wnid_to_label.json'), 'w') as f:\n",
    "    json.dump(wnid_to_classes, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Validation metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DEVKIT_DIR, 'data', 'ILSVRC2012_validation_ground_truth.txt')\n",
    "with open(fpath, 'r') as f:\n",
    "    val_gts = [(int(l.strip()) - 1) for l in f] # Go from 1 to 1000 inclusive\n",
    "len(val_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_names = sorted(os.listdir(os.path.join(DATA_DIR, 'dataset', 'images', 'val')))\n",
    "len(image_names), image_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metadata = [\n",
    "    (image_name, wnid_ordered[gt_idx])\n",
    "    for image_name, gt_idx in zip(image_names, val_gts)\n",
    "]\n",
    "len(metadata), metadata[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata, columns=['image_name', 'wnid'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_DIR, 'dataset', 'val_metadata.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parent_folder = os.path.join(DATA_DIR, 'ILSVRC2012_img_train')\n",
    "folders = os.listdir(parent_folder)\n",
    "folders = [f for f in folders if '.tar' not in f]\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metadata = []\n",
    "\n",
    "for folder in folders:\n",
    "    for image_name in os.listdir(os.path.join(parent_folder, folder)):\n",
    "        metadata.append((os.path.join(folder, image_name), folder))\n",
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata, columns=['image_name', 'wnid'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATA_DIR, 'dataset', 'train_metadata.csv')\n",
    "df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Compute mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATASET_DIR, 'train_metadata.csv'))\n",
    "train_images = list(df['image_name'])\n",
    "del df\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images_dir = os.path.join(DATASET_DIR, 'images', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(ImageFolderIterator(images_dir, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create mini-imagenet\n",
    "\n",
    "Smaller version of the dataset, with the same classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, f'{split}_metadata.csv')\n",
    "df = pd.read_csv(fpath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_class = df.groupby('wnid')['image_name'].apply(list).to_dict()\n",
    "len(grouped_by_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_by_class = 10 if split == 'val' else 100\n",
    "chosen_samples = []\n",
    "for samples_by_class in grouped_by_class.values():\n",
    "    chosen_samples.extend(random.sample(samples_by_class, n_samples_by_class))\n",
    "len(chosen_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_samples = set(chosen_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mini'] = [\n",
    "    int(image_name in chosen_samples)\n",
    "    for image_name in df['image_name']\n",
    "]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "df = pd.read_csv(os.path.join(DATASET_DIR, f'{split}_metadata.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check errors\n",
    "\n",
    "- Check samples with errors\n",
    "- Get shapes (failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = Counter()\n",
    "errors = []\n",
    "\n",
    "for idx in tqdm(range(len(df))):\n",
    "    row = df.iloc[idx]\n",
    "    image_name = row['image_name']\n",
    "\n",
    "    try:\n",
    "        image = Image.open(os.path.join(DATASET_DIR, 'images', split, image_name))\n",
    "    except UserWarning as e:\n",
    "        errors.append((image_name, e))\n",
    "        # print('get exif error', image_name)\n",
    "    shapes[image.size] += 1\n",
    "    \n",
    "    image.close()\n",
    "    \n",
    "len(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapes), len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix EXIF errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(DATASET_DIR, 'images/train/n04152593/n04152593_17460.JPEG')\n",
    "image_fp = Image.open(fpath)\n",
    "image = image_fp.convert('RGB')\n",
    "image_fp.close()\n",
    "plt.imshow(image)\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piexif.remove(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../imagenet.py\n",
    "%run ../__init__.py\n",
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageNetDataset('train')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[-10]\n",
    "item.image.size(), item.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(dataset._wnid_to_label_name[dataset.labels[item.labels]])\n",
    "plt.imshow(tensor_to_range01(item.image).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'dataset_name': 'imagenet',\n",
    "    'dataset_type': 'train',\n",
    "    'shuffle': True,\n",
    "}\n",
    "dataloader = prepare_data_classification(**kwargs)\n",
    "len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
