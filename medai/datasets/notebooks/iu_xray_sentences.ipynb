{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply chexpert labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(REPORTS_DIR, 'reports.clean.json')\n",
    "with open(fname, 'r') as f:\n",
    "    clean_reports = list(json.load(f).values())\n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_by_filename = {\n",
    "    r['filename']: r['clean_text']\n",
    "    for r in clean_reports\n",
    "}\n",
    "len(reports_by_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = pd.DataFrame(reports_by_filename, columns=['reports'])\n",
    "print(len(df_reports))\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = _apply_labeler_to_column(df_reports, 'reports',\n",
    "                                  fill_empty=-2, fill_uncertain=-1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = _concat_df_matrix(df_reports, labels)\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply MIRQI labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_mirqi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df[['Reports', 'filename']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mirqi_df = _apply_mirqi_to_df(df, gt_col_name='Reports', gen_col_name='Reports')\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valoration_to_int = {\n",
    "    'POSITIVE': 1,\n",
    "    'NEGATIVE': 0,\n",
    "    'UNCERTAIN': -1,\n",
    "}\n",
    "\n",
    "WRONG_LEN_ATTRIBUTES = defaultdict(list)\n",
    "\n",
    "def expand_attributes(row):\n",
    "    attributes = row['attributes-gt']\n",
    "    attributes = [s.strip('()') for s in attributes.split(') (')]\n",
    "    attributes = [s.split('|') for s in attributes]\n",
    "    \n",
    "    for tup in attributes:\n",
    "        if len(tup) != 4:\n",
    "            WRONG_LEN_ATTRIBUTES['len-not-4'].append(tup)\n",
    "            continue\n",
    "        text, label, value, additional = tup\n",
    "        row[label] = valoration_to_int[value]\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df = mirqi_df.apply(expand_attributes, axis=1)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_cols = ['filename', 'Reports', 'attributes-gt', 'attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f']\n",
    "columns = base_cols + [c for c in mirqi_df if c not in base_cols]\n",
    "mirqi_df = mirqi_df[columns]\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df.replace(np.nan, -2, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')\n",
    "mirqi_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(REPORTS_DIR, 'reports.clean.v3.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports_as_dict = json.load(f)\n",
    "    reports = list(reports_as_dict.values())\n",
    "len(reports_as_dict), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counter = get_sentences_appearances(r['clean_text'] for r in reports)\n",
    "len(sentence_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check not-so-common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sentence_counter.items())\n",
    "l = sorted(l, key=lambda x: x[1], reverse=False)\n",
    "l[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check short sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sentence_counter.items(), key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentence = 'hand .'\n",
    "appears_in = [\n",
    "    report\n",
    "    for report in reports\n",
    "    if target_sentence in report['clean_text']\n",
    "]\n",
    "len(appears_in), appears_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label sentences with chexpert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n ../../metrics/report_generation/chexpert.py\n",
    "# %run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentences', 'appearances']\n",
    "df_sentences = pd.DataFrame(sentence_counter.items(), columns=columns)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = apply_labeler_to_column(df_sentences, 'sentences',\n",
    "                                 fill_empty=-2, fill_uncertain=-1,\n",
    "                                 caller_id='iu-notebook')\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences = _concat_df_matrix(df_sentences, labels)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load sentences for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences = pd.read_csv(fpath)\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Count sentences' groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Count normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal = df_sentences[df_sentences['No Finding'] == 1]\n",
    "snt_abnormal = df_sentences[df_sentences['No Finding'] == 0]\n",
    "len(snt_normal), len(snt_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_abnormal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Number of abnormal sentences per report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_sentence_normal = dict()\n",
    "for index, row in df_sentences.iterrows():\n",
    "    sentence = row['sentences']\n",
    "    is_normal = row['No Finding']\n",
    "    is_sentence_normal[sentence] = is_normal\n",
    "len(is_sentence_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for report in reports:\n",
    "    number_of_abnormal = sum(\n",
    "        1 - is_sentence_normal[sentence]\n",
    "        for sentence in split_sentences(report['clean_text'])\n",
    "    )\n",
    "    res.append(number_of_abnormal)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Top-K most common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['sentences', 'appearances']\n",
    "df = df_sentences[cols].sort_values('appearances', ascending=False).head(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot sentences appearances distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences.sort_values('appearances', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "appearances = list(df_sentences['appearances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(appearances, bins=30)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Sentence appearances distribution')\n",
    "\n",
    "plt.ylabel('Number of sentences')\n",
    "plt.xlabel('Number of appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.bar(list(range(len(values))), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collect synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = load_synonyms('iu_xray')\n",
    "len(SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FOR_LATER = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEEN_SENTENCES = set()\n",
    "for representative, syns in SYNONYMS.items():\n",
    "    SEEN_SENTENCES.add(representative)\n",
    "    for s in syns:\n",
    "        SEEN_SENTENCES.add(s)\n",
    "len(SEEN_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        s = int(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences, skip_later=True):\n",
    "    index_to_repr = {\n",
    "        index: representative\n",
    "        for index, representative in enumerate(SYNONYMS.keys())\n",
    "    }\n",
    "    \n",
    "    def _print_reprs():\n",
    "        print('-'*20)\n",
    "        for index, representative in index_to_repr.items():\n",
    "            print(f'{index} - {representative}')\n",
    "    \n",
    "    def _add_new(sentence):\n",
    "        index_to_repr[len(SYNONYMS)] = sentence\n",
    "        SYNONYMS[sentence] = []\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "\n",
    "    def _add_as_syn(sentence, option):\n",
    "        option = int(option)\n",
    "            \n",
    "        if option not in index_to_repr:\n",
    "            print(f'No synonym found for option={option}')\n",
    "            raise\n",
    "        representative = index_to_repr[option]\n",
    "\n",
    "        if representative not in SYNONYMS:\n",
    "            print(f'representative {representative} not in SYNS')\n",
    "            # Internal error!\n",
    "            raise\n",
    "\n",
    "        SYNONYMS[representative].append(sentence)\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "        \n",
    "    _print_reprs()\n",
    "    \n",
    "    sentence_idx = 0\n",
    "    while sentence_idx < len(sentences):\n",
    "        sentence = sentences[sentence_idx]\n",
    "        sentence = clean_sentence(sentence)\n",
    "        \n",
    "        if sentence in SEEN_SENTENCES or (not skip_later and sentence in FOR_LATER):\n",
    "            sentence_idx += 1\n",
    "            continue\n",
    "            \n",
    "        option = input(f'\"{sentence}\" --> ')\n",
    "        \n",
    "        if is_number(option):\n",
    "            _add_as_syn(sentence, option)\n",
    "            sentence_idx += 1\n",
    "        elif option == 'l': # later\n",
    "            FOR_LATER.add(sentence)\n",
    "            sentence_idx += 1\n",
    "        elif ',' in option: # split and allocate\n",
    "            added_new = False\n",
    "            for suboption in option.split(','):\n",
    "                suboption = suboption.strip()\n",
    "                if suboption == 'n':\n",
    "                    new_sentence = input('\\t\\tInput new sentence: ')\n",
    "                    _add_new(new_sentence)\n",
    "                    added_new = True\n",
    "                else:\n",
    "                    _add_as_syn(sentence, suboption)\n",
    "\n",
    "            if added_new:\n",
    "                _print_reprs()\n",
    "                \n",
    "            sentence_idx += 1\n",
    "        elif option == 'n': # new\n",
    "            _add_new(sentence)\n",
    "            _print_reprs()\n",
    "            sentence_idx += 1\n",
    "        elif option == 'b':\n",
    "            print('Breaking')\n",
    "            break\n",
    "        else:\n",
    "            print(f'Option not recognized: {option}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "some_sentences = df_sentences.groupby('Fracture')['sentences'].apply(list)\n",
    "some_sentences = sorted(some_sentences[0], key=lambda x: len(x))\n",
    "process_sentences(some_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_synonyms('iu_xray', SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect Max amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted([(len(s.split()), s) for s in sentence_counter], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " ### Max amount of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(report['clean_text'].split()) for report in reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(split_sentences(report['clean_text'])) for report in reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences + organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common/sentences2organs/compute.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df_sentences['sentences'])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_organs, errors = save_sentences_with_organs(DATASET_DIR, sentences)\n",
    "len(df_organs), len(errors['all-empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Review empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors['all-empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.loc[df_sentences['sentences'].isin(set(errors['all-empty']))]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['appearances'].sum(), df_sentences['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.sort_values('appearances', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
