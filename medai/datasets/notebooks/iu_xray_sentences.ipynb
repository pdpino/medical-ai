{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply chexpert labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(REPORTS_DIR, 'reports.clean.json')\n",
    "with open(fname, 'r') as f:\n",
    "    clean_reports = list(json.load(f).values())\n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_by_filename = {\n",
    "    r['filename']: r['clean_text']\n",
    "    for r in clean_reports\n",
    "}\n",
    "len(reports_by_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = pd.DataFrame(reports_by_filename, columns=['reports'])\n",
    "print(len(df_reports))\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = _apply_labeler_to_column(df_reports, 'reports',\n",
    "                                  fill_empty=-2, fill_uncertain=-1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = _concat_df_matrix(df_reports, labels)\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply MIRQI labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_mirqi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df[['Reports', 'filename']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mirqi_df = _apply_mirqi_to_df(df, gt_col_name='Reports', gen_col_name='Reports')\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valoration_to_int = {\n",
    "    'POSITIVE': 1,\n",
    "    'NEGATIVE': 0,\n",
    "    'UNCERTAIN': -1,\n",
    "}\n",
    "\n",
    "WRONG_LEN_ATTRIBUTES = defaultdict(list)\n",
    "\n",
    "def expand_attributes(row):\n",
    "    attributes = row['attributes-gt']\n",
    "    attributes = [s.strip('()') for s in attributes.split(') (')]\n",
    "    attributes = [s.split('|') for s in attributes]\n",
    "    \n",
    "    for tup in attributes:\n",
    "        if len(tup) != 4:\n",
    "            WRONG_LEN_ATTRIBUTES['len-not-4'].append(tup)\n",
    "            continue\n",
    "        text, label, value, additional = tup\n",
    "        row[label] = valoration_to_int[value]\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df = mirqi_df.apply(expand_attributes, axis=1)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_cols = ['filename', 'Reports', 'attributes-gt', 'attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f']\n",
    "columns = base_cols + [c for c in mirqi_df if c not in base_cols]\n",
    "mirqi_df = mirqi_df[columns]\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df.replace(np.nan, -2, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')\n",
    "mirqi_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_sentences(report, end_token='.'):\n",
    "    report = report.split()\n",
    "    if report[-1] != end_token:\n",
    "        report.append(end_token)\n",
    "\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for word in report:\n",
    "        sentence.append(word)\n",
    "        if word == end_token:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "            \n",
    "    return [' '.join(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(REPORTS_DIR, 'reports.clean.v2.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports_as_dict = json.load(f)\n",
    "    reports = list(reports_as_dict.values())\n",
    "len(reports_as_dict), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Count appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentence_counter = defaultdict(list)\n",
    "for report in reports:\n",
    "    for sentence in split_sentences(report['clean_text']):\n",
    "        sentence_counter[sentence].append(report['filename'])\n",
    "len(sentence_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check not-so-common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(sentence_counter.items())\n",
    "l = sorted(l, key=lambda x: x[1], reverse=True)\n",
    "l[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check short sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted([\n",
    "    (sentence, len(appearances))\n",
    "    for sentence, appearances in sentence_counter.items()\n",
    "], key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_sentence = 'hand .'\n",
    "appearances = sentence_counter[target_sentence]\n",
    "appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_report = appearances[0]\n",
    "[\n",
    "    report\n",
    "    for report in reports\n",
    "    if report['filename'] == target_report\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Label sentences with chexpert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../metrics/report_generation/chexpert.py\n",
    "# %run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = ['sentences', 'appearances']\n",
    "df_sentences = pd.DataFrame([\n",
    "    (sentence, len(appearances))\n",
    "    for sentence, appearances in sentence_counter.items()\n",
    "], columns=columns)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = apply_labeler_to_column(df_sentences, 'sentences',\n",
    "                                 fill_empty=-2, fill_uncertain=-1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences = _concat_df_matrix(df_sentences, labels)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load sentences for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences = pd.read_csv(fpath)\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Count sentences' groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Count normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal = df_sentences[df_sentences['No Finding'] == 1]\n",
    "snt_abnormal = df_sentences[df_sentences['No Finding'] == 0]\n",
    "len(snt_normal), len(snt_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_abnormal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Number of abnormal sentences per report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_sentence_normal = dict()\n",
    "for index, row in df_sentences.iterrows():\n",
    "    sentence = row['sentences']\n",
    "    is_normal = row['No Finding']\n",
    "    is_sentence_normal[sentence] = is_normal\n",
    "len(is_sentence_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for report in reports:\n",
    "    number_of_abnormal = sum(\n",
    "        1 - is_sentence_normal[sentence]\n",
    "        for sentence in split_sentences(report['clean_text'])\n",
    "    )\n",
    "    res.append(number_of_abnormal)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Top-K most common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['sentences', 'appearances']\n",
    "df = df_sentences[cols].sort_values('appearances', ascending=False).head(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot sentences appearances distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences.sort_values('appearances', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "appearances = list(df_sentences['appearances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(appearances, bins=30)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Sentence appearances distribution')\n",
    "\n",
    "plt.ylabel('Number of sentences')\n",
    "plt.xlabel('Number of appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.bar(list(range(len(values))), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collect synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = load_synonyms('iu_xray')\n",
    "len(SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FOR_LATER = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEEN_SENTENCES = set()\n",
    "for representative, syns in SYNONYMS.items():\n",
    "    SEEN_SENTENCES.add(representative)\n",
    "    for s in syns:\n",
    "        SEEN_SENTENCES.add(s)\n",
    "len(SEEN_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        s = int(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences, skip_later=True):\n",
    "    index_to_repr = {\n",
    "        index: representative\n",
    "        for index, representative in enumerate(SYNONYMS.keys())\n",
    "    }\n",
    "    \n",
    "    def _print_reprs():\n",
    "        print('-'*20)\n",
    "        for index, representative in index_to_repr.items():\n",
    "            print(f'{index} - {representative}')\n",
    "    \n",
    "    def _add_new(sentence):\n",
    "        index_to_repr[len(SYNONYMS)] = sentence\n",
    "        SYNONYMS[sentence] = []\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "\n",
    "    def _add_as_syn(sentence, option):\n",
    "        option = int(option)\n",
    "            \n",
    "        if option not in index_to_repr:\n",
    "            print(f'No synonym found for option={option}')\n",
    "            raise\n",
    "        representative = index_to_repr[option]\n",
    "\n",
    "        if representative not in SYNONYMS:\n",
    "            print(f'representative {representative} not in SYNS')\n",
    "            # Internal error!\n",
    "            raise\n",
    "\n",
    "        SYNONYMS[representative].append(sentence)\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "        \n",
    "    _print_reprs()\n",
    "    \n",
    "    sentence_idx = 0\n",
    "    while sentence_idx < len(sentences):\n",
    "        sentence = sentences[sentence_idx]\n",
    "        sentence = clean_sentence(sentence)\n",
    "        \n",
    "        if sentence in SEEN_SENTENCES or (not skip_later and sentence in FOR_LATER):\n",
    "            sentence_idx += 1\n",
    "            continue\n",
    "            \n",
    "        option = input(f'\"{sentence}\" --> ')\n",
    "        \n",
    "        if is_number(option):\n",
    "            _add_as_syn(sentence, option)\n",
    "            sentence_idx += 1\n",
    "        elif option == 'l': # later\n",
    "            FOR_LATER.add(sentence)\n",
    "            sentence_idx += 1\n",
    "        elif ',' in option: # split and allocate\n",
    "            added_new = False\n",
    "            for suboption in option.split(','):\n",
    "                suboption = suboption.strip()\n",
    "                if suboption == 'n':\n",
    "                    new_sentence = input('\\t\\tInput new sentence: ')\n",
    "                    _add_new(new_sentence)\n",
    "                    added_new = True\n",
    "                else:\n",
    "                    _add_as_syn(sentence, suboption)\n",
    "\n",
    "            if added_new:\n",
    "                _print_reprs()\n",
    "                \n",
    "            sentence_idx += 1\n",
    "        elif option == 'n': # new\n",
    "            _add_new(sentence)\n",
    "            _print_reprs()\n",
    "            sentence_idx += 1\n",
    "        elif option == 'b':\n",
    "            print('Breaking')\n",
    "            break\n",
    "        else:\n",
    "            print(f'Option not recognized: {option}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "some_sentences = df_sentences.groupby('Fracture')['sentences'].apply(list)\n",
    "some_sentences = sorted(some_sentences[0], key=lambda x: len(x))\n",
    "process_sentences(some_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_synonyms('iu_xray', SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect Max amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted([(len(s.split()), s) for s in sentence_counter], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " ### Max amount of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(report['clean_text'].split()) for report in reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(split_sentences(report['clean_text'])) for report in reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences + organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrganLabeler = namedtuple('OrganLabeler',\n",
    "                          ['mentions_other', 'mentions_heart', 'mentions_lungs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Use chexpert-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Heart rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_heart = df_sentences.groupby([\n",
    "    'Enlarged Cardiomediastinum',\n",
    "    'Cardiomegaly',\n",
    "])['sentences'].apply(list)\n",
    "grouped_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_heart[(-2.0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "heart_col1 = 'Enlarged Cardiomediastinum'\n",
    "heart_col2 = 'Cardiomegaly'\n",
    "\n",
    "def mentions_heart(sample):\n",
    "    empty1 = sample[heart_col1] == -2\n",
    "    empty2 = sample[heart_col2] == -2\n",
    "    return int(not empty1 or not empty2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[30]\n",
    "sample['sentences'], mentions_heart(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lungs rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungs_cols = [\n",
    "    'Lung Lesion',\n",
    "    'Lung Opacity',\n",
    "    'Edema',\n",
    "    'Consolidation',\n",
    "    'Pneumonia',\n",
    "    'Atelectasis',\n",
    "    'Pneumothorax',\n",
    "    'Pleural Effusion',\n",
    "    'Pleural Other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_lungs = df_sentences.groupby(\n",
    "    lambda x: any(y != -2 for y in df_sentences.loc[x, lungs_cols]),\n",
    ")['sentences'].apply(list)\n",
    "grouped_lungs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungs_appear = grouped_lungs[True]\n",
    "len(lungs_appear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_BOTH = re.compile(r'both|bilateral')\n",
    "PATTERN_RIGHT = re.compile('right')\n",
    "PATTERN_LEFT = re.compile('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lung = defaultdict(list)\n",
    "\n",
    "for sentence in lungs_appear:\n",
    "    both = PATTERN_BOTH.search(sentence)\n",
    "    right = PATTERN_RIGHT.search(sentence)\n",
    "    left = PATTERN_LEFT.search(sentence)\n",
    "            \n",
    "    if left and right and both: key = 'all'\n",
    "    elif left and right: key = 'left-right'\n",
    "    elif left and both: key = 'both-left'\n",
    "    elif both and right: key = 'both-right'\n",
    "    elif both: key = 'both'\n",
    "    elif right: key = 'right'\n",
    "    elif left: key = 'left'\n",
    "    else: key = 'none'\n",
    "    \n",
    "    by_lung[key].append(sentence)\n",
    "\n",
    "[(k, len(g)) for k, g in by_lung.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_lung['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions_lungs(sample):\n",
    "    all_empty = all(label == -2 for label in sample[lungs_cols])\n",
    "    \n",
    "    if all_empty:\n",
    "        return 0, 0\n",
    "    \n",
    "    sentence = sample['sentences']\n",
    "    if PATTERN_BOTH.search(sentence):\n",
    "        return 1, 1\n",
    "    \n",
    "    left = PATTERN_LEFT.search(sentence)\n",
    "    right = PATTERN_RIGHT.search(sentence)\n",
    "    \n",
    "    if not right and not left:\n",
    "        # None found (\"both\", \"right\", \"left\")\n",
    "        return 1, 1\n",
    "    \n",
    "    return int(bool(left)), int(bool(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = 'there is a 1 cm nodular opacity in the right costophrenic xxxx , increased since comparison examination .'\n",
    "# 3523\n",
    "\n",
    "# s =  'there is focal airspace disease in the right lung base concerning for pneumonia or aspiration .'\n",
    "# 4777\n",
    "\n",
    "s = 'left basilar opacity compatible pleural effusion and atelectasis .'\n",
    "# 6058\n",
    "df_sentences[df_sentences['sentences'] == s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[6058]\n",
    "sample['sentences'], mentions_lungs(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other rules (background, bones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_cols = [\n",
    "    'Fracture',\n",
    "    'Support Devices',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_other = df_sentences.groupby(\n",
    "    lambda x: any(y != -2 for y in df_sentences.loc[x, other_cols]),\n",
    ")['sentences'].apply(list)\n",
    "grouped_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_present = grouped_other[True]\n",
    "other_absent = grouped_other[False]\n",
    "len(other_present), len(other_absent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mentions_other(sample):\n",
    "    all_empty = all(label == -2 for label in sample[other_cols])\n",
    "    \n",
    "    return int(not all_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'no displaced rib fracture visualized .'\n",
    "# 250\n",
    "df_sentences[df_sentences['sentences'] == s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[250]\n",
    "sample['sentences'], mentions_other(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Gather chexpert-label-based OrganLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_organ_labeler = OrganLabeler(\n",
    "    mentions_other=mentions_other,\n",
    "    mentions_heart=mentions_heart,\n",
    "    mentions_lungs=mentions_lungs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Regex-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIRQI phrases loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRQI_DIR = os.path.abspath('../../../../software/MIRQI/predefined/phrases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phrases(label, mention=True):\n",
    "    mention = 'mention' if mention else 'unmention'\n",
    "\n",
    "    fname = os.path.join(MIRQI_DIR, mention, f'{label}.txt')\n",
    "    with open(fname, 'r') as f:\n",
    "        lines = [l.strip().replace('_', ' ') for l in f.readlines()]\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heart regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_mentions = load_phrases('cardiomegaly') + load_phrases('enlarged_cardiomediastinum')\n",
    "# Edema heart related\n",
    "heart_mentions += ['heart failure', 'chf', 'vascular congestion', 'vascular prominence']\n",
    "# Others\n",
    "heart_mentions += ['heart', 'aorta', 'aortic', ' cardio', 'mediastinal', 'mediastinum']\n",
    "len(heart_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEX_HEART = re.compile('|'.join(heart_mentions))\n",
    "def regex_mentions_heart(sample):\n",
    "    sentence = sample['sentences']\n",
    "    return int(bool(REGEX_HEART.search(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[3233]\n",
    "sample['sentences'], regex_mentions_heart(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lung regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_diseases = ['airspace_disease', 'airspace_opacity', 'atelectasis', 'calcinosis',\n",
    "                 'consolidation', 'emphysema',\n",
    "                 'hypoinflation', 'lung_lesion',\n",
    "                 'pleural_effusion', 'pleural_other',\n",
    "                 'pneumonia', 'pneumothorax',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lungs_mentions = [\n",
    "    ph\n",
    "    for disease in lung_diseases\n",
    "    for ph in load_phrases(disease)\n",
    "]\n",
    "# Edema lung related \n",
    "lungs_mentions += [\n",
    "    'edema', 'pulmonary congestion',\n",
    "    'clear lung',\n",
    "    'the lung',\n",
    "    'pleural space',\n",
    "    'pleural air collection',\n",
    "]\n",
    "len(lungs_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from attempt 1\n",
    "PATTERN_BOTH = re.compile(r'both|bilateral')\n",
    "PATTERN_RIGHT = re.compile('right')\n",
    "PATTERN_LEFT = re.compile('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEXES_LUNGS = [\n",
    "    re.compile(r'lungs?\\s(are\\s)?clear'),\n",
    "    re.compile(r'(right|left) lung'),\n",
    "    re.compile(r'\\Alung'),\n",
    "    re.compile(r'lungs? volume'),\n",
    "    re.compile(r'pulmon\\w*\\s(vascul\\w*)?'),\n",
    "    re.compile('expanded lungs?'),\n",
    "    re.compile('(right|left) (upper |lower )?lobe'),\n",
    "    re.compile('|'.join(lungs_mentions)),\n",
    "]\n",
    "def regex_mentions_lungs(sample):\n",
    "    sentence = sample['sentences']\n",
    "    any_lung = any(pattern.search(sentence) for pattern in REGEXES_LUNGS)\n",
    "    \n",
    "    if not any_lung:\n",
    "        return 0, 0\n",
    "    \n",
    "    if PATTERN_BOTH.search(sentence):\n",
    "        return 1, 1\n",
    "    \n",
    "    left = PATTERN_LEFT.search(sentence)\n",
    "    right = PATTERN_RIGHT.search(sentence)\n",
    "    \n",
    "    if not right and not left:\n",
    "        # None found (\"both\", \"right\", \"left\")\n",
    "        return 1, 1\n",
    "    \n",
    "    return int(bool(left)), int(bool(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[1200]\n",
    "sample['sentences'], regex_mentions_lungs(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_diseases = ['scoliosis', 'support_devices', 'fracture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_mentions = [ph for disease in other_diseases for ph in load_phrases(disease)]\n",
    "\n",
    "other_mentions += ['bony', 'bone',\n",
    "                   'spine', 'osseous', 'osseus', 'skeletal',\n",
    "                   'spondylosis', 'trachea']\n",
    "\n",
    "# Other support devices\n",
    "other_mentions += ['ivc', 'clips']\n",
    "\n",
    "len(other_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEX_OTHER = re.compile('|'.join(other_mentions))\n",
    "def regex_mentions_other(sample):\n",
    "    sentence = sample['sentences']\n",
    "    return int(bool(REGEX_OTHER.search(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[1000]\n",
    "sample['sentences'], regex_mentions_other(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Other other!\n",
    "\n",
    "Not used for now\n",
    "\n",
    "TODO: keep reviewing these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phrases = load_phrases('other_finding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phrases = [\n",
    "    'blunt', # Lungs\n",
    "    'elevation',  # hemidiaphragm elevation\n",
    "    'bronchospasm', # None\n",
    "    'asthma', # None\n",
    "    'interstitial markings', # Lungs\n",
    "    'plaque', # Lungs\n",
    "    'osteophytosis', # None\n",
    "    'aortic disease', # heart or lungs\n",
    "    'bronchiolitis', # Lungs\n",
    "    'thickening',\n",
    "    'cephalization',\n",
    "    'aspiration',\n",
    "    'bullae',\n",
    "    'contusion',\n",
    "    'atherosclero',\n",
    "    'osteopenia',\n",
    "    'metastasis',\n",
    "    'granuloma',\n",
    "    'pneumomediastinum',\n",
    "    'pneumoperitoneum',\n",
    "    'osteodystrophy',\n",
    "    'cuffing',\n",
    "    'irregular lucency',\n",
    "    'inflam',\n",
    "    'fissure',\n",
    "    'prominen',\n",
    "    'kyphosis',\n",
    "    'defib',\n",
    "    'bullet',\n",
    "    'reticula',\n",
    "    'thoracentesis',\n",
    "    'bronchitis',\n",
    "    'volume loss',\n",
    "    'deformity',\n",
    "    'hemorrhage',\n",
    "    'hematoma',\n",
    "    'radiopaque',\n",
    "    'aerophagia',\n",
    "    'arthropathy',\n",
    "    'tracheostomy',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 9\n",
    "# regex_phrases = '|'.join(phrases)\n",
    "regex_phrases = phrases[idx]\n",
    "print(regex_phrases)\n",
    "samples = list(df_sentences[df_sentences['sentences'].str.contains(regex_phrases)]['sentences'])\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_organ_labeler = OrganLabeler(\n",
    "    mentions_other=regex_mentions_other,\n",
    "    mentions_heart=regex_mentions_heart,\n",
    "    mentions_lungs=regex_mentions_lungs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label all organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../jsrt.py\n",
    "%run ../common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORGAN_BACKGROUND, ORGAN_HEART, ORGAN_LEFT_LUNG, ORGAN_RIGHT_LUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORGAN_LABELER = chexpert_organ_labeler\n",
    "ORGAN_LABELER = regex_organ_labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRONG_ONES = defaultdict(list)\n",
    "\n",
    "def find_organs(sample):\n",
    "    background = heart = right_lung = left_lung = 0\n",
    "\n",
    "    if ORGAN_LABELER.mentions_other(sample):\n",
    "        background = heart = right_lung = left_lung = 1\n",
    "    else:\n",
    "        heart = ORGAN_LABELER.mentions_heart(sample)\n",
    "        left_lung, right_lung = ORGAN_LABELER.mentions_lungs(sample)\n",
    "\n",
    "    if background + heart + right_lung + left_lung == 0:\n",
    "        WRONG_ONES['all-empty'].append(sample.name)\n",
    "        # If nothing is identified, set all to 1\n",
    "        background = heart = right_lung = left_lung = 1\n",
    "\n",
    "    sample[ORGAN_BACKGROUND] = background\n",
    "    sample[ORGAN_HEART] = heart\n",
    "    sample[ORGAN_RIGHT_LUNG] = right_lung\n",
    "    sample[ORGAN_LEFT_LUNG] = left_lung\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_sentences_2 = df_sentences.apply(find_organs, axis=1)\n",
    "df_sentences_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Review empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, len(v)) for k, v in WRONG_ONES.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = WRONG_ONES['all-empty']\n",
    "sample = df_sentences.iloc[a]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['appearances'].sum(), df_sentences['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.sort_values('appearances', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.iloc[1056]['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentences'] + JSRT_ORGANS\n",
    "sentences_and_organs = df_sentences_2[columns]\n",
    "sentences_and_organs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_organs.csv')\n",
    "sentences_and_organs.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
