{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply chexpert labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(REPORTS_DIR, 'reports.clean.json')\n",
    "with open(fname, 'r') as f:\n",
    "    clean_reports = list(json.load(f).values())\n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_by_filename = {\n",
    "    r['filename']: r['clean_text']\n",
    "    for r in clean_reports\n",
    "}\n",
    "len(reports_by_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = pd.DataFrame(reports_by_filename, columns=['reports'])\n",
    "print(len(df_reports))\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = _apply_labeler_to_column(df_reports, 'reports',\n",
    "                                  fill_empty=-2, fill_uncertain=-1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_reports = _concat_df_matrix(df_reports, labels)\n",
    "df_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply MIRQI labeler to reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../eval_report_generation_mirqi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df[['Reports', 'filename']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mirqi_df = _apply_mirqi_to_df(df, gt_col_name='Reports', gen_col_name='Reports')\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "valoration_to_int = {\n",
    "    'POSITIVE': 1,\n",
    "    'NEGATIVE': 0,\n",
    "    'UNCERTAIN': -1,\n",
    "}\n",
    "\n",
    "WRONG_LEN_ATTRIBUTES = defaultdict(list)\n",
    "\n",
    "def expand_attributes(row):\n",
    "    attributes = row['attributes-gt']\n",
    "    attributes = [s.strip('()') for s in attributes.split(') (')]\n",
    "    attributes = [s.split('|') for s in attributes]\n",
    "    \n",
    "    for tup in attributes:\n",
    "        if len(tup) != 4:\n",
    "            WRONG_LEN_ATTRIBUTES['len-not-4'].append(tup)\n",
    "            continue\n",
    "        text, label, value, additional = tup\n",
    "        row[label] = valoration_to_int[value]\n",
    "        \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df = mirqi_df.apply(expand_attributes, axis=1)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_cols = ['filename', 'Reports', 'attributes-gt', 'attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f']\n",
    "columns = base_cols + [c for c in mirqi_df if c not in base_cols]\n",
    "mirqi_df = mirqi_df[columns]\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df.replace(np.nan, -2, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')\n",
    "mirqi_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(REPORTS_DIR, 'reports.clean.v2.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports_as_dict = json.load(f)\n",
    "    reports = list(reports_as_dict.values())\n",
    "len(reports_as_dict), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_counter = get_sentences_appearances(r['clean_text'] for r in reports)\n",
    "len(sentence_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check not-so-common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(sentence_counter.items())\n",
    "l = sorted(l, key=lambda x: x[1], reverse=True)\n",
    "l[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check short sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([\n",
    "    (sentence, len(appearances))\n",
    "    for sentence, appearances in sentence_counter.items()\n",
    "], key=lambda x: len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sentence = 'hand .'\n",
    "appearances = sentence_counter[target_sentence]\n",
    "appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_report = appearances[0]\n",
    "[\n",
    "    report\n",
    "    for report in reports\n",
    "    if report['filename'] == target_report\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Label sentences with chexpert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../../metrics/report_generation/chexpert.py\n",
    "# %run -n ../../eval_report_generation_chexpert_labeler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = ['sentences', 'appearances']\n",
    "df_sentences = pd.DataFrame([\n",
    "    (sentence, len(appearances))\n",
    "    for sentence, appearances in sentence_counter.items()\n",
    "], columns=columns)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "labels = apply_labeler_to_column(df_sentences, 'sentences',\n",
    "                                 fill_empty=-2, fill_uncertain=-1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences = _concat_df_matrix(df_sentences, labels)\n",
    "print(len(df_sentences))\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load sentences for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_chexpert_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>appearances</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there is no pulmonary edema .</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is no focal consolidation .</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are no xxxx of a pleural effusion .</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is no evidence of pneumothorax .</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  appearances  No Finding  \\\n",
       "0  the cardiac silhouette and mediastinum size ar...            6         1.0   \n",
       "1                      there is no pulmonary edema .           12         1.0   \n",
       "2                  there is no focal consolidation .           34         1.0   \n",
       "3          there are no xxxx of a pleural effusion .            3         1.0   \n",
       "4             there is no evidence of pneumothorax .           23         1.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Cardiomegaly  Lung Lesion  Lung Opacity  Edema  \\\n",
       "0                         0.0           0.0         -2.0          -2.0   -2.0   \n",
       "1                        -2.0          -2.0         -2.0          -2.0    0.0   \n",
       "2                        -2.0          -2.0         -2.0          -2.0   -2.0   \n",
       "3                        -2.0          -2.0         -2.0          -2.0   -2.0   \n",
       "4                        -2.0          -2.0         -2.0          -2.0   -2.0   \n",
       "\n",
       "   Consolidation  Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  \\\n",
       "0           -2.0       -2.0         -2.0          -2.0              -2.0   \n",
       "1           -2.0       -2.0         -2.0          -2.0              -2.0   \n",
       "2            0.0       -2.0         -2.0          -2.0              -2.0   \n",
       "3           -2.0       -2.0         -2.0          -2.0               0.0   \n",
       "4           -2.0       -2.0         -2.0           0.0              -2.0   \n",
       "\n",
       "   Pleural Other  Fracture  Support Devices  \n",
       "0           -2.0      -2.0             -2.0  \n",
       "1           -2.0      -2.0             -2.0  \n",
       "2           -2.0      -2.0             -2.0  \n",
       "3           -2.0      -2.0             -2.0  \n",
       "4           -2.0      -2.0             -2.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.read_csv(fpath)\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6439"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Count sentences' groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Count normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal = df_sentences[df_sentences['No Finding'] == 1]\n",
    "snt_abnormal = df_sentences[df_sentences['No Finding'] == 0]\n",
    "len(snt_normal), len(snt_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_normal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "snt_abnormal['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Number of abnormal sentences per report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "is_sentence_normal = dict()\n",
    "for index, row in df_sentences.iterrows():\n",
    "    sentence = row['sentences']\n",
    "    is_normal = row['No Finding']\n",
    "    is_sentence_normal[sentence] = is_normal\n",
    "len(is_sentence_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for report in reports:\n",
    "    number_of_abnormal = sum(\n",
    "        1 - is_sentence_normal[sentence]\n",
    "        for sentence in split_sentences(report['clean_text'])\n",
    "    )\n",
    "    res.append(number_of_abnormal)\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Top-K most common sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['sentences', 'appearances']\n",
    "df = df_sentences[cols].sort_values('appearances', ascending=False).head(5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Plot sentences appearances distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences.sort_values('appearances', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "appearances = list(df_sentences['appearances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(appearances, bins=30)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Sentence appearances distribution')\n",
    "\n",
    "plt.ylabel('Number of sentences')\n",
    "plt.xlabel('Number of appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.bar(list(range(len(values))), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Collect synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = load_synonyms('iu_xray')\n",
    "len(SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SYNONYMS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FOR_LATER = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "SEEN_SENTENCES = set()\n",
    "for representative, syns in SYNONYMS.items():\n",
    "    SEEN_SENTENCES.add(representative)\n",
    "    for s in syns:\n",
    "        SEEN_SENTENCES.add(s)\n",
    "len(SEEN_SENTENCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        s = int(s)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences, skip_later=True):\n",
    "    index_to_repr = {\n",
    "        index: representative\n",
    "        for index, representative in enumerate(SYNONYMS.keys())\n",
    "    }\n",
    "    \n",
    "    def _print_reprs():\n",
    "        print('-'*20)\n",
    "        for index, representative in index_to_repr.items():\n",
    "            print(f'{index} - {representative}')\n",
    "    \n",
    "    def _add_new(sentence):\n",
    "        index_to_repr[len(SYNONYMS)] = sentence\n",
    "        SYNONYMS[sentence] = []\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "\n",
    "    def _add_as_syn(sentence, option):\n",
    "        option = int(option)\n",
    "            \n",
    "        if option not in index_to_repr:\n",
    "            print(f'No synonym found for option={option}')\n",
    "            raise\n",
    "        representative = index_to_repr[option]\n",
    "\n",
    "        if representative not in SYNONYMS:\n",
    "            print(f'representative {representative} not in SYNS')\n",
    "            # Internal error!\n",
    "            raise\n",
    "\n",
    "        SYNONYMS[representative].append(sentence)\n",
    "        SEEN_SENTENCES.add(sentence)\n",
    "        \n",
    "    _print_reprs()\n",
    "    \n",
    "    sentence_idx = 0\n",
    "    while sentence_idx < len(sentences):\n",
    "        sentence = sentences[sentence_idx]\n",
    "        sentence = clean_sentence(sentence)\n",
    "        \n",
    "        if sentence in SEEN_SENTENCES or (not skip_later and sentence in FOR_LATER):\n",
    "            sentence_idx += 1\n",
    "            continue\n",
    "            \n",
    "        option = input(f'\"{sentence}\" --> ')\n",
    "        \n",
    "        if is_number(option):\n",
    "            _add_as_syn(sentence, option)\n",
    "            sentence_idx += 1\n",
    "        elif option == 'l': # later\n",
    "            FOR_LATER.add(sentence)\n",
    "            sentence_idx += 1\n",
    "        elif ',' in option: # split and allocate\n",
    "            added_new = False\n",
    "            for suboption in option.split(','):\n",
    "                suboption = suboption.strip()\n",
    "                if suboption == 'n':\n",
    "                    new_sentence = input('\\t\\tInput new sentence: ')\n",
    "                    _add_new(new_sentence)\n",
    "                    added_new = True\n",
    "                else:\n",
    "                    _add_as_syn(sentence, suboption)\n",
    "\n",
    "            if added_new:\n",
    "                _print_reprs()\n",
    "                \n",
    "            sentence_idx += 1\n",
    "        elif option == 'n': # new\n",
    "            _add_new(sentence)\n",
    "            _print_reprs()\n",
    "            sentence_idx += 1\n",
    "        elif option == 'b':\n",
    "            print('Breaking')\n",
    "            break\n",
    "        else:\n",
    "            print(f'Option not recognized: {option}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "some_sentences = df_sentences.groupby('Fracture')['sentences'].apply(list)\n",
    "some_sentences = sorted(some_sentences[0], key=lambda x: len(x))\n",
    "process_sentences(some_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_synonyms('iu_xray', SYNONYMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect Max amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted([(len(s.split()), s) for s in sentence_counter], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " ### Max amount of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(report['clean_text'].split()) for report in reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Max amount of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max(len(split_sentences(report['clean_text'])) for report in reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences + organs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Attempt 1: Use chexpert-labels\n",
    "\n",
    "Delete this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "OrganLabeler = namedtuple('OrganLabeler',\n",
    "                          ['mentions_other', 'mentions_heart', 'mentions_lungs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Heart rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_heart = df_sentences.groupby([\n",
    "    'Enlarged Cardiomediastinum',\n",
    "    'Cardiomegaly',\n",
    "])['sentences'].apply(list)\n",
    "grouped_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_heart[(-2.0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "heart_col1 = 'Enlarged Cardiomediastinum'\n",
    "heart_col2 = 'Cardiomegaly'\n",
    "\n",
    "def mentions_heart(sample):\n",
    "    empty1 = sample[heart_col1] == -2\n",
    "    empty2 = sample[heart_col2] == -2\n",
    "    return int(not empty1 or not empty2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[30]\n",
    "sample['sentences'], mentions_heart(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Lungs rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lungs_cols = [\n",
    "    'Lung Lesion',\n",
    "    'Lung Opacity',\n",
    "    'Edema',\n",
    "    'Consolidation',\n",
    "    'Pneumonia',\n",
    "    'Atelectasis',\n",
    "    'Pneumothorax',\n",
    "    'Pleural Effusion',\n",
    "    'Pleural Other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_lungs = df_sentences.groupby(\n",
    "    lambda x: any(y != -2 for y in df_sentences.loc[x, lungs_cols]),\n",
    ")['sentences'].apply(list)\n",
    "grouped_lungs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lungs_appear = grouped_lungs[True]\n",
    "len(lungs_appear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATTERN_BOTH = re.compile(r'both|bilateral')\n",
    "PATTERN_RIGHT = re.compile('right')\n",
    "PATTERN_LEFT = re.compile('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "by_lung = defaultdict(list)\n",
    "\n",
    "for sentence in lungs_appear:\n",
    "    both = PATTERN_BOTH.search(sentence)\n",
    "    right = PATTERN_RIGHT.search(sentence)\n",
    "    left = PATTERN_LEFT.search(sentence)\n",
    "            \n",
    "    if left and right and both: key = 'all'\n",
    "    elif left and right: key = 'left-right'\n",
    "    elif left and both: key = 'both-left'\n",
    "    elif both and right: key = 'both-right'\n",
    "    elif both: key = 'both'\n",
    "    elif right: key = 'right'\n",
    "    elif left: key = 'left'\n",
    "    else: key = 'none'\n",
    "    \n",
    "    by_lung[key].append(sentence)\n",
    "\n",
    "[(k, len(g)) for k, g in by_lung.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "by_lung['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mentions_lungs(sample):\n",
    "    all_empty = all(label == -2 for label in sample[lungs_cols])\n",
    "    \n",
    "    if all_empty:\n",
    "        return 0, 0\n",
    "    \n",
    "    sentence = sample['sentences']\n",
    "    if PATTERN_BOTH.search(sentence):\n",
    "        return 1, 1\n",
    "    \n",
    "    left = PATTERN_LEFT.search(sentence)\n",
    "    right = PATTERN_RIGHT.search(sentence)\n",
    "    \n",
    "    if not right and not left:\n",
    "        # None found (\"both\", \"right\", \"left\")\n",
    "        return 1, 1\n",
    "    \n",
    "    return int(bool(left)), int(bool(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# s = 'there is a 1 cm nodular opacity in the right costophrenic xxxx , increased since comparison examination .'\n",
    "# 3523\n",
    "\n",
    "# s =  'there is focal airspace disease in the right lung base concerning for pneumonia or aspiration .'\n",
    "# 4777\n",
    "\n",
    "s = 'left basilar opacity compatible pleural effusion and atelectasis .'\n",
    "# 6058\n",
    "df_sentences[df_sentences['sentences'] == s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[6058]\n",
    "sample['sentences'], mentions_lungs(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Other rules (background, bones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_cols = [\n",
    "    'Fracture',\n",
    "    'Support Devices',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grouped_other = df_sentences.groupby(\n",
    "    lambda x: any(y != -2 for y in df_sentences.loc[x, other_cols]),\n",
    ")['sentences'].apply(list)\n",
    "grouped_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_present = grouped_other[True]\n",
    "other_absent = grouped_other[False]\n",
    "len(other_present), len(other_absent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def mentions_other(sample):\n",
    "    all_empty = all(label == -2 for label in sample[other_cols])\n",
    "    \n",
    "    return int(not all_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = 'no displaced rib fracture visualized .'\n",
    "# 250\n",
    "df_sentences[df_sentences['sentences'] == s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = df_sentences.iloc[250]\n",
    "sample['sentences'], mentions_other(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Gather chexpert-label-based OrganLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_organ_labeler = OrganLabeler(\n",
    "    mentions_other=mentions_other,\n",
    "    mentions_heart=mentions_heart,\n",
    "    mentions_lungs=mentions_lungs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Regex-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common/sentences2organs.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6439"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(df_sentences['sentences'])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6439, 1219)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organs, errors = find_organs_for_sentences(sentences)\n",
    "len(organs), len(errors['all-empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Review empty ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors['all-empty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sentences.loc[df_sentences['sentences'].isin(set(errors['all-empty']))]\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['appearances'].sum(), df_sentences['appearances'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.sort_values('appearances', ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_names = [ORGAN_BACKGROUND, ORGAN_HEART, ORGAN_LEFT_LUNG, ORGAN_RIGHT_LUNG]\n",
    "df_organs = pd.DataFrame(organs, columns=organ_names)\n",
    "sentences_and_organs = pd.concat([df_sentences, df_organs], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentences'] + organ_names\n",
    "sentences_and_organs = sentences_and_organs[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(REPORTS_DIR, 'sentences_with_organs.csv')\n",
    "sentences_and_organs.to_csv(fpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
