{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess reports\n",
    "\n",
    "Clean and tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Debug tokenize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../preprocess/tokenize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"findings/pneumothorax \"\"\"\n",
    "text_to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check already clean reports\n",
    "\n",
    "Look for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(REPORTS_DIR, 'reports.clean.v3.json'), 'r') as f:\n",
    "    reports_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def search_in_reports(target):\n",
    "    found = []\n",
    "    for r in reports_dict.values():\n",
    "        clean_text = r['clean_text']\n",
    "        if re.search(target, clean_text):\n",
    "            found.append({\n",
    "                k: r[k]\n",
    "                for k in ('filename', 'clean_text', 'findings', 'impression')\n",
    "            })\n",
    "    print('Found: ', len(found))\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search_in_reports(r'\\bexample\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run preprocess\n",
    "\n",
    "- Tokenize reports, create json with clean reports and vocabularies\n",
    "- Create sentences_with_chexpert_labels.csv (takes about 12min)\n",
    "- Create sentences_with_organs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n ../preprocess/iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports, tokens_appearances, errors = preprocess_iu_x_ray('v4-1', [0],\n",
    "                                                          override=False,\n",
    "                                                          impression_fallback=False,\n",
    "                                                         )\n",
    "len(reports), len(tokens_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab41 = load_vocab(REPORTS_DIR, 'v4-1')\n",
    "vocab4 = load_vocab(REPORTS_DIR, 'v4')\n",
    "len(vocab4), len(vocab41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences_chexpert, errors = create_sentences_with_organs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_sentences_chexpert = create_sentences_with_chexpert_labels()\n",
    "len(df_sentences_chexpert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, n_appears in tokens.items():\n",
    "    if 'NUMBER' in token:\n",
    "        print(token, n_appears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Check in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TARGET_TOKENS = ['NUMBER[^\\s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = []\n",
    "for report in reports.values():\n",
    "    for token in TARGET_TOKENS:\n",
    "        if re.search(token, report['clean_text']):\n",
    "            found.append(report)\n",
    "            \n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rotate images\n",
    "\n",
    "NOTE: are already rotated!!\n",
    "(Run this only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info_fname = os.path.join(DATASET_DIR, 'info.json')\n",
    "with open(info_fname, 'r') as f:\n",
    "    info = json.load(f)\n",
    "len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info['marks']['rotated_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rotations = [\n",
    "    ('left', -90),\n",
    "    ('right', 90),\n",
    "    ('bottom', 180),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, degrees in rotations:\n",
    "    images_key = f'rotated_{key}'\n",
    "    for image_name in info['marks'][images_key]:\n",
    "        filepath = os.path.join(DATASET_DIR, 'images', image_name)\n",
    "        img = Image.open(filepath).rotate(degrees)\n",
    "        # img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_folder = os.path.join(DATASET_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset('train')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = [\n",
    "    i if i.endswith('.png') else f'{i}.png'\n",
    "    for i in [r['image_name'] for r in dataset.reports]\n",
    "]\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(ImageFolderIterator(image_folder, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summed = torch.zeros(3, 256, 256)\n",
    "\n",
    "for image_name in tqdm(image_names):\n",
    "    fpath = os.path.join(image_folder, image_name)\n",
    "    image = transform(Image.open(fpath).convert('RGB'))\n",
    "    summed += image\n",
    "    \n",
    "summed /= len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "average_image = summed.mean(dim=0)\n",
    "average_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(average_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `IUXrayDataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset(\n",
    "    dataset_type='test',\n",
    "    masks=True,\n",
    "    masks_version='v2',\n",
    "    frontal_only=True,\n",
    "    image_size=(512, 512),\n",
    "    seg_multilabel=False,\n",
    ")\n",
    "len(dataset), len(dataset.word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[100]\n",
    "image = item.image\n",
    "labels = item.labels\n",
    "report = item.report\n",
    "image.size(), labels.size(), len(report), \\\n",
    "    (isinstance(item.masks, torch.Tensor) and item.masks.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.masks.min(), item.masks.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "plt.figure(figsize=(n_cols*5, n_rows*5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plt.title(item.image_fname)\n",
    "plt.imshow(tensor_to_range01(image).permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "if item.masks.ndim == 3:\n",
    "    for index, organ in enumerate(JSRT_ORGANS):\n",
    "        mask = item.masks[index]\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, index + 2)\n",
    "        plt.imshow(mask)\n",
    "        plt.title(organ)\n",
    "        plt.axis('off')\n",
    "\n",
    "        min_value = mask.min().item()\n",
    "        max_value = mask.max().item()\n",
    "        print(organ, min_value, max_value)\n",
    "elif item.masks.ndim == 2:\n",
    "    plt.subplot(n_rows, n_cols, 2)\n",
    "    plt.imshow(item.masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../iu_xray.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = IUXRayDataset('train')\n",
    "val_dataset = IUXRayDataset('val')\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_labels_distribution(dataset):\n",
    "    amounts_by_disease = sum(\n",
    "        (dataset.labels_by_report[r['filename']] for r in dataset.reports),\n",
    "        torch.zeros(len(CHEXPERT_DISEASES)),\n",
    "    ).tolist()\n",
    "    max_amount = max(amounts_by_disease)\n",
    "    amounts_by_disease = list(zip(CHEXPERT_DISEASES, amounts_by_disease))\n",
    "    amounts_by_disease = sorted(amounts_by_disease, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    n_samples = len(dataset)\n",
    "    plt.title(f'{dataset.dataset_type} (n={n_samples:,})', fontsize=20)\n",
    "    plt.bar(*zip(*amounts_by_disease))\n",
    "    plt.xticks(rotation=60, fontsize=15, ha='right')\n",
    "    plt.ylabel('Amount of images', fontsize=18)\n",
    "    plt.ylim(0, max_amount * 1.15)\n",
    "    y_padding = int(max_amount * 0.03)\n",
    "    \n",
    "    for index, (disease, amount) in enumerate(amounts_by_disease):\n",
    "        amount = int(amount)\n",
    "        perc = amount / n_samples * 100\n",
    "        plt.text(index, amount + y_padding, f'{amount:,}\\n{perc:.0f}%', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_labels_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_labels_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Report lengths distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_n_words_distribution(dataset):\n",
    "    lengths = [len(r['tokens_idxs']) for r in dataset.reports]\n",
    "    plt.title(f'Report-lengths ({dataset.dataset_type}, total={len(dataset):,})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    plt.xlabel('Number of words')\n",
    "    _ = plt.hist(lengths, bins=25, range=(0, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_n_words_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_n_words_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Frontal vs lateral distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_view_position_distribution(dataset):\n",
    "    def _reduce_pos(position):\n",
    "        return position.replace('-left', '').replace('-right', '')\n",
    "    positions = Counter([_reduce_pos(r['position']) for r in dataset.reports])\n",
    "    \n",
    "    plt.title(f'Frontal vs lateral ({dataset.dataset_type})', fontsize=20)\n",
    "    plt.ylabel('Amount of images', fontsize=15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    \n",
    "    positions = sorted(positions.items(), key=lambda x: x[1], reverse=True)\n",
    "    keys, values = zip(*positions)\n",
    "    plt.bar(keys, values, width=0.2)\n",
    "    \n",
    "    plt.ylim(0, max(values) * 1.2)\n",
    "    y_padding = max(values) * 0.03\n",
    "    n_samples = len(dataset)\n",
    "    for index, value in enumerate(values):\n",
    "        perc = value / n_samples * 100\n",
    "        text = f'{value:,}\\n{perc:.2f}%'\n",
    "        plt.text(index, value + y_padding, text, ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_view_position_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_view_position_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect different vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_full = load_vocab('iu_xray')\n",
    "vocab_1 = load_vocab('iu_xray', 1)\n",
    "vocab_10 = load_vocab('iu_xray', 10)\n",
    "len(vocab_full), len(vocab_1), len(vocab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "assert set(vocab_10).issubset(vocab_1)\n",
    "assert set(vocab_1).issubset(vocab_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_of_vocab_1 = set(vocab_full) - set(vocab_1)\n",
    "out_of_vocab_10 = set(vocab_1) - set(vocab_10)\n",
    "len(out_of_vocab_1), len(out_of_vocab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_of_vocab_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get sample reports\n",
    "\n",
    "For LATINX in AI workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycocoevalcap.bleu import bleu_scorer\n",
    "from pycocoevalcap.rouge import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../common.py\n",
    "%run ../iu_xray.py\n",
    "%run ../../utils/nlp.py\n",
    "%run ../../utils/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CONSTANT_REPORT = \"\"\"the heart is normal in size . the mediastinum is unremarkable . \n",
    "the lungs are clear .\n",
    "there is no pneumothorax or pleural effusion . no focal airspace disease .\n",
    "no pleural effusion or pneumothorax .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset(dataset_type='all')\n",
    "report_reader = ReportReader(dataset.get_vocab())\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = GT_IDX\n",
    "item = dataset[idx]\n",
    "image = arr_to_range(item.image.permute(1, 2, 0))\n",
    "report_base = report_reader.idx_to_text(item.report)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "print(report_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "GT_IDX = 7289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    'the cardiac silhouette is enlarged',\n",
    "    # 'the lungs are hyper',\n",
    "    # 'the heart is',\n",
    "]\n",
    "not_target = [\n",
    "    # 'the lungs are clear',\n",
    "#     'the mediastinum is unremarkable',\n",
    "#     'the mediastinum is stable',\n",
    "#     'the mediastinum is normal',\n",
    "#     'the mediastinum is within normal limits',\n",
    "]\n",
    "found = []\n",
    "found_names = set()\n",
    "for idx, report in enumerate(dataset.reports):\n",
    "    filename = report['filename']\n",
    "    report = report_reader.idx_to_text(report['tokens_idxs'])\n",
    "    if all(t in report for t in target) and all(t not in report for t in not_target):\n",
    "        if filename not in found_names:\n",
    "            found.append((idx, report))\n",
    "        found_names.add(filename)\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = 'the heart is enlarged. the mediastinum is unremarkable . the lungs are hyperinflated with mildly coarsened interstitial markings . '\n",
    "# the lungs are hyperexpanded\n",
    "# the lungs are hyperinflated with mildly coarsened interstitial markings\n",
    "# the lungs are hyperinflated with biapical pleural-parenchymal scarring and upward retraction of the xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def measure_bleu_rouge(gen, gt):\n",
    "    scorer = bleu_scorer.BleuScorer(n=4)\n",
    "    scorer += (gen, [gt])\n",
    "    bleu_1_4, _ = scorer.compute_score()\n",
    "    \n",
    "    scorer = rouge.Rouge()\n",
    "    rouge_score = scorer.calc_score([gen], [gt])\n",
    "    \n",
    "    print('BLEU 1-4: ', bleu_1_4)\n",
    "    print('BLEU: ', np.mean(bleu_1_4))\n",
    "    print('ROUGE-L: ', rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report_1 = \"\"\"the heart is normal in size . the mediastinum is unremarkable . \n",
    "the lungs are clear .\"\"\"\n",
    "report_2 = \"\"\"the heart is normal . the mediastinum is otherwise unremarkable . \n",
    "lungs are both clear .\"\"\"\n",
    "measure_bleu_rouge(report_1, report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report = report_reader.idx_to_text(dataset[GT_IDX].report)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt = \"\"\"the cardiac silhouette is enlarged .\n",
    "the lungs are hyperexpanded with flattening of the bilateral hemidiaphragms .\n",
    "no pneumothorax or pleural effusion .\"\"\"\n",
    "# the lungs are hyperinflated with mildly coarsened interstitial markings .\n",
    "# with flattening of the bilateral hemidiaphragms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = \"\"\"the cardiac silhouette is normal in size .\n",
    "the lungs are clear .\n",
    "no pneumothorax or pleural effusion .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt = \"the cardiac silhouette is enlarged . the lungs are hyperexpanded with flattening of the bilateral hemidiaphragms . no pneumothorax or pleural effusion .\"\n",
    "gen = \"the cardiac silhouette is normal in size and configuration . the lungs are clear . no pneumothorax or pleural effusion .\"\n",
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check no-findings vs labels==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "mirqi_path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_df = pd.read_csv(chexpert_path, index_col=0)\n",
    "chexpert_df.replace(-1, 1, inplace=True)\n",
    "chexpert_df.replace(-2, 0, inplace=True)\n",
    "chexpert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df = pd.read_csv(mirqi_path, index_col=0)\n",
    "mirqi_df.drop(columns=['attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f'], inplace=True)\n",
    "mirqi_df.rename(columns={'attributes-gt': 'attributes'}, inplace=True)\n",
    "mirqi_df.replace(-1, 1, inplace=True)\n",
    "mirqi_df.replace(-2, 0, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_columns = set(['filename', 'Reports', 'attributes'])\n",
    "MIRQI_LABELS = [c for c in mirqi_df.columns if c not in base_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(chexpert_df), len(mirqi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = chexpert_df.merge(mirqi_df, on='filename', suffixes=['_chx', '_mirqi'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_by_condition = defaultdict(set)\n",
    "\n",
    "for index, row in chexpert_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    report = row['Reports']\n",
    "    labels = row[CHEXPERT_LABELS]\n",
    "\n",
    "    tup = (index, filename, report)\n",
    "\n",
    "    no_findings = labels['No Finding']\n",
    "    \n",
    "    if no_findings == 1:\n",
    "        reports_by_condition['no-findings-1'].add(tup)\n",
    "        if any(l != 0 for l in labels[1:-1]):\n",
    "            # Exclude no-findings and support-devices\n",
    "            reports_by_condition['inconsistent'].add(tup)\n",
    "    else:\n",
    "        if not any(l != 0 for l in labels[1:-1]):\n",
    "            reports_by_condition['no-findings-absent'].add(tup)\n",
    "    \n",
    "    if all(l != 1 for l in labels):\n",
    "        reports_by_condition['no-1s'].add(tup)\n",
    "    \n",
    "[(k, len(v)) for k, v in reports_by_condition.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-absent'])\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df.loc[mirqi_df['filename'] == '256.xml'][MIRQI_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-1s'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-1'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
