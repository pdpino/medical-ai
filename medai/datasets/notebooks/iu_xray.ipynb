{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_fname = os.path.join(REPORTS_DIR, 'reports.json')\n",
    "with open(reports_fname, 'r') as f:\n",
    "    reports_as_dict = json.load(f)\n",
    "    reports = list(reports_as_dict.values())\n",
    "len(reports_as_dict), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_fname = os.path.join(DATASET_DIR, 'info.json')\n",
    "with open(info_fname, 'r') as f:\n",
    "    info = json.load(f)\n",
    "len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(info_fname, 'w') as f:\n",
    "    json.dump(info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['marks']['rotated_left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Rotate images\n",
    "\n",
    "NOTE: are already rotated!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rotations = [\n",
    "    ('left', -90),\n",
    "    ('right', 90),\n",
    "    ('bottom', 180),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, degrees in rotations:\n",
    "    images_key = f'rotated_{key}'\n",
    "    for image_name in info['marks'][images_key]:\n",
    "        filepath = os.path.join(DATASET_DIR, 'images', image_name)\n",
    "        img = Image.open(filepath).rotate(degrees)\n",
    "        # img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'The previously<BR>described XXXX deformity'\n",
    "text = \"\"\"1. low lung volumes\n",
    "2. exam limited on lateral: view by superimposed soft tissue and bony structures of the arm\n",
    "3. lungs appear grossly clear . no evidence of pneumonia .\"\"\"\n",
    "re.sub(r'< ?br ?\\\\?>', ' ', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_consecutive_dots(tokens):\n",
    "    clean_tokens = []\n",
    "    last_was_dot = False\n",
    "    for token in tokens:\n",
    "        is_dot = (token == '.')\n",
    "        if last_was_dot and is_dot:\n",
    "            continue\n",
    "\n",
    "        clean_tokens.append(token)\n",
    "        last_was_dot = is_dot\n",
    "            \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_consecutive_dots(['.', '.', 'asdf', 'hello', '.', 'abc', '.', '.', 'c', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_TOKEN = 'NUMBER'\n",
    "\n",
    "def text_to_tokens(text):\n",
    "    text = text.lower()\n",
    "    # Remove html tags\n",
    "    text = re.sub(r'(\\[)?&amp;[gl]t;(\\])?', ' ', text)\n",
    "    \n",
    "    # PM or AM token\n",
    "    text = re.sub(r'\\s(a|p)\\.?m\\.?\\s', r' \\1m ', text)\n",
    "    \n",
    "    # Replace two dots\n",
    "    text = re.sub(r':', ' . ', text)\n",
    "    \n",
    "    # Replace multiple comma/semicolon with simple coma\n",
    "    text = re.sub(r'(;|,+)', r',', text)\n",
    "    \n",
    "    # Replace numbers with decimals by token\n",
    "    text = re.sub(r'\\d+(\\.|/)\\d+', NUMBER_TOKEN, text)\n",
    "    \n",
    "    # Replace break line tag\n",
    "    text = re.sub(r'< ?br ?\\\\?>', ' ', text)\n",
    "    text = re.sub(r'[\\[\\]<>]', '', text) # Remove brackets [] <>\n",
    "    text = re.sub(r'(\\(|\\))', r' \\1 ', text) # Give space to parenthesis\n",
    "    \n",
    "    text = re.sub(r'\\.+', r'.', text) # Replace multiple dots with one dot\n",
    "    \n",
    "    # Number as enumerators, like \"1. bla bla, 2. bla bla\"\n",
    "    text = re.sub(r'(\\W|\\A)\\d+\\.[^\\d]', r' . ', text)\n",
    "    # text = re.sub(r'(\\d)\\.', r'\\1 .', text)\n",
    "    \n",
    "    # Add space between text and dot/comma\n",
    "    text = re.sub(r'([a-zA-Z0-9])(\\.|,|/)', r'\\1 \\2', text)\n",
    "    text = re.sub(r'(\\.|,|/)([a-zA-Z0-9])', r'\\1 \\2', text)\n",
    "    \n",
    "    # Other numbers\n",
    "    text = re.sub(r'(\\W|\\A)\\d+(a|st|nd|th|rd|\\%|mm|xxxx)?', r'\\1 {}'.format(NUMBER_TOKEN), text)\n",
    "    # text = re.sub(r'\\A\\d+(a|st|nd|th|rd|\\%|mm|xxxx)?', r'\\1 {}'.format(NUMBER_TOKEN), text)\n",
    "    \n",
    "    # Remove apostrophe\n",
    "    text = re.sub(r'(\\w+)\\'[st]?', r'\\1 ', text) # XXXX't is a typo\n",
    "    \n",
    "    # text = re.sub(r'NUMBER\\.', 'NUMBER .', text)\n",
    "    \n",
    "    tokens = remove_consecutive_dots(text.split())\n",
    "    if tokens[0] == '.':\n",
    "        tokens = tokens[1:]\n",
    "        \n",
    "    if tokens[-1] != '.':\n",
    "        tokens.append('.')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_tokens(\"3 p.m. message xxxx' l10 l20. there's /11 3. mild clavicle: bilateral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_TOKENS = set(['p.m.', 'pm', 'am'])\n",
    "token_appearances = Counter()\n",
    "errors = defaultdict(list)\n",
    "\n",
    "cleaned_reports_as_dict = dict()\n",
    "\n",
    "for report in reports:\n",
    "    filename = report['filename']\n",
    "    findings = report['findings']\n",
    "    impression = report['impression']\n",
    "\n",
    "    n_images = len(report['images'])\n",
    "    if n_images == 0:\n",
    "        errors['no-images'].append(filename)\n",
    "        continue\n",
    "    \n",
    "    text = findings\n",
    "    if findings is None and impression is None:\n",
    "        errors['text-none'].append(filename)\n",
    "        continue\n",
    "    elif findings is None:\n",
    "        errors['findings-none'].append(filename)\n",
    "        text = impression\n",
    "    elif impression is None:\n",
    "        errors['impression-none'].append(filename)\n",
    "\n",
    "    # Clean and tokenize text\n",
    "    tokens = [token for token in text_to_tokens(text) if token not in IGNORE_TOKENS]\n",
    "    token_appearances += {\n",
    "        token: 1\n",
    "        for token in tokens\n",
    "    }\n",
    "\n",
    "    cleaned_report = {k: v for k, v in report.items()}\n",
    "    cleaned_report['clean_text'] = ' '.join(tokens)\n",
    "\n",
    "    cleaned_reports_as_dict[filename] = cleaned_report\n",
    "\n",
    "print({k: len(v) for k, v in errors.items()})\n",
    "print('Different tokens: ', len(token_appearances))\n",
    "print('Tokens with more than 1 appearance: ',\n",
    "      len([k for k, v in token_appearances.items() if v > 1]))\n",
    "len(cleaned_reports_as_dict), len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(k, v) for k, v in token_appearances.items() if re.search(':', k)],\n",
    "       key=lambda x:x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_as_dict[errors['no-images'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review specific tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = []\n",
    "\n",
    "for report in cleaned_reports_as_dict.values():\n",
    "    name = report['filename']\n",
    "    findings = report['findings']\n",
    "    impression = report['impression']\n",
    "    \n",
    "    clean = report.get('clean_text', None)\n",
    "    if not clean:\n",
    "        try:\n",
    "            clean = cleaned_reports_as_dict[name]['clean_text']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # s = re.search(r'\\W\\d\\b', clean)\n",
    "    # s = re.search(r'xxxx opacity in the left midlung', clean)\n",
    "    target = ':'\n",
    "    s = re.search(target, clean) # or re.search(target, impression or '')\n",
    "    if s:\n",
    "        found.append((name, findings, impression, clean)) # s.group(0)\n",
    "\n",
    "print(len(found))\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save cleaned reports\n",
    "\n",
    "NOTE: Save after image info below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(REPORTS_DIR, 'reports.clean.v2.json')\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(cleaned_reports_as_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add side to image info (in cleaned reports)\n",
    "\n",
    "TODO: move this to a script!!!\n",
    "\n",
    "`side` can be one of (`frontal`, `lateral-left`, `lateral-right`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_JSON_VERSION = 'reports.clean.v2.json'\n",
    "fname = os.path.join(REPORTS_DIR, REPORTS_JSON_VERSION)\n",
    "with open(fname, 'r') as f:\n",
    "    clean_reports = json.load(f)\n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_images = set(info['marks']['wrong'])\n",
    "broken_images = set(info['marks']['broken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for report_name, report_dict in clean_reports.items():\n",
    "    new_images_info = []\n",
    "    for image_info in report_dict['images']:\n",
    "        image_name = image_info['id']\n",
    "        image_name = f'{image_name}.png'\n",
    "\n",
    "        image_info['side'] = info['classification'][image_name]\n",
    "        image_info['wrong'] = image_name in wrong_images\n",
    "        image_info['broken'] = image_name in broken_images\n",
    "\n",
    "        new_images_info.append(image_info)\n",
    "    \n",
    "    report_dict['images'] = new_images_info\n",
    "    clean_reports[report_name] = report_dict\n",
    "    \n",
    "len(clean_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(REPORTS_DIR, REPORTS_JSON_VERSION)\n",
    "with open(fname, 'w') as f:\n",
    "    json.dump(clean_reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save common vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py\n",
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IUXRayDataset(dataset_type='train', recompute_vocab=True)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_dataset.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_vocab = load_vocab('iu_xray')\n",
    "len(prev_vocab), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1220\n",
    "a = [(k, v) for k, v in vocab.items() if v == idx][0]\n",
    "b = [(k, v) for k, v in prev_vocab.items() if v == idx][0]\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vocab('iu_xray', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_folder = os.path.join(DATASET_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset('train')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = [\n",
    "    i if i.endswith('.png') else f'{i}.png'\n",
    "    for i in [r['image_name'] for r in dataset.reports]\n",
    "]\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(ImageFolderIterator(image_folder, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summed = torch.zeros(3, 256, 256)\n",
    "\n",
    "for image_name in tqdm(image_names):\n",
    "    fpath = os.path.join(image_folder, image_name)\n",
    "    image = transform(Image.open(fpath).convert('RGB'))\n",
    "    summed += image\n",
    "    \n",
    "summed /= len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "average_image = summed.mean(dim=0)\n",
    "average_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(average_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `IUXrayDataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset(dataset_type='all', masks=True, frontal_only=True)\n",
    "len(dataset), len(dataset.word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[0]\n",
    "image = item.image\n",
    "labels = item.labels\n",
    "report = item.report\n",
    "image.size(), labels.size(), len(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for index, organ in enumerate(JSRT_ORGANS):\n",
    "    plt.subplot(1, 4, index + 1)\n",
    "    plt.imshow(item.masks[index])\n",
    "    plt.title(organ)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_labels_presence_for('Cardiomegaly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Review different image shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shapes = set()\n",
    "\n",
    "for idx in range(len(dataset)):\n",
    "    image, _ = dataset[idx]\n",
    "    shapes.add(image.numpy().shape)\n",
    "\n",
    "len(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load single images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = DATASET_DIR + '/images/CXR5_IM-2117-1003002.png'\n",
    "img = Image.open(fname)\n",
    "img_tensor = transforms.ToTensor()(img)\n",
    "img.size, img_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inspect tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "counter = defaultdict(lambda: 0)\n",
    "for report in reports:\n",
    "    tags = report['tags_manual']\n",
    "    for tag in tags:\n",
    "        counter[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(((k, v) for k, v in counter.items()), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get sample reports\n",
    "\n",
    "For LATINX in AI workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycocoevalcap.bleu import bleu_scorer\n",
    "from pycocoevalcap.rouge import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../common.py\n",
    "%run ../iu_xray.py\n",
    "%run ../../utils/nlp.py\n",
    "%run ../../utils/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CONSTANT_REPORT = \"\"\"the heart is normal in size . the mediastinum is unremarkable . \n",
    "the lungs are clear .\n",
    "there is no pneumothorax or pleural effusion . no focal airspace disease .\n",
    "no pleural effusion or pneumothorax .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset(dataset_type='all')\n",
    "report_reader = ReportReader(dataset.get_vocab())\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = GT_IDX\n",
    "item = dataset[idx]\n",
    "image = arr_to_range(item.image.permute(1, 2, 0))\n",
    "report_base = report_reader.idx_to_text(item.report)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "print(report_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "GT_IDX = 7289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target = [\n",
    "    'the cardiac silhouette is enlarged',\n",
    "    # 'the lungs are hyper',\n",
    "    # 'the heart is',\n",
    "]\n",
    "not_target = [\n",
    "    # 'the lungs are clear',\n",
    "#     'the mediastinum is unremarkable',\n",
    "#     'the mediastinum is stable',\n",
    "#     'the mediastinum is normal',\n",
    "#     'the mediastinum is within normal limits',\n",
    "]\n",
    "found = []\n",
    "found_names = set()\n",
    "for idx, report in enumerate(dataset.reports):\n",
    "    filename = report['filename']\n",
    "    report = report_reader.idx_to_text(report['tokens_idxs'])\n",
    "    if all(t in report for t in target) and all(t not in report for t in not_target):\n",
    "        if filename not in found_names:\n",
    "            found.append((idx, report))\n",
    "        found_names.add(filename)\n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = 'the heart is enlarged. the mediastinum is unremarkable . the lungs are hyperinflated with mildly coarsened interstitial markings . '\n",
    "# the lungs are hyperexpanded\n",
    "# the lungs are hyperinflated with mildly coarsened interstitial markings\n",
    "# the lungs are hyperinflated with biapical pleural-parenchymal scarring and upward retraction of the xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def measure_bleu_rouge(gen, gt):\n",
    "    scorer = bleu_scorer.BleuScorer(n=4)\n",
    "    scorer += (gen, [gt])\n",
    "    bleu_1_4, _ = scorer.compute_score()\n",
    "    \n",
    "    scorer = rouge.Rouge()\n",
    "    rouge_score = scorer.calc_score([gen], [gt])\n",
    "    \n",
    "    print('BLEU 1-4: ', bleu_1_4)\n",
    "    print('BLEU: ', np.mean(bleu_1_4))\n",
    "    print('ROUGE-L: ', rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report_1 = \"\"\"the heart is normal in size . the mediastinum is unremarkable . \n",
    "the lungs are clear .\"\"\"\n",
    "report_2 = \"\"\"the heart is normal . the mediastinum is otherwise unremarkable . \n",
    "lungs are both clear .\"\"\"\n",
    "measure_bleu_rouge(report_1, report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report = report_reader.idx_to_text(dataset[GT_IDX].report)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt = \"\"\"the cardiac silhouette is enlarged .\n",
    "the lungs are hyperexpanded with flattening of the bilateral hemidiaphragms .\n",
    "no pneumothorax or pleural effusion .\"\"\"\n",
    "# the lungs are hyperinflated with mildly coarsened interstitial markings .\n",
    "# with flattening of the bilateral hemidiaphragms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen = \"\"\"the cardiac silhouette is normal in size .\n",
    "the lungs are clear .\n",
    "no pneumothorax or pleural effusion .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gt = \"the cardiac silhouette is enlarged . the lungs are hyperexpanded with flattening of the bilateral hemidiaphragms . no pneumothorax or pleural effusion .\"\n",
    "gen = \"the cardiac silhouette is normal in size and configuration . the lungs are clear . no pneumothorax or pleural effusion .\"\n",
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "measure_bleu_rouge(gen, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Check no-findings vs labels==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "mirqi_path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chexpert_df = pd.read_csv(chexpert_path, index_col=0)\n",
    "chexpert_df.replace(-1, 1, inplace=True)\n",
    "chexpert_df.replace(-2, 0, inplace=True)\n",
    "chexpert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df = pd.read_csv(mirqi_path, index_col=0)\n",
    "mirqi_df.drop(columns=['attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f'], inplace=True)\n",
    "mirqi_df.rename(columns={'attributes-gt': 'attributes'}, inplace=True)\n",
    "mirqi_df.replace(-1, 1, inplace=True)\n",
    "mirqi_df.replace(-2, 0, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base_columns = set(['filename', 'Reports', 'attributes'])\n",
    "MIRQI_LABELS = [c for c in mirqi_df.columns if c not in base_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(chexpert_df), len(mirqi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = chexpert_df.merge(mirqi_df, on='filename', suffixes=['_chx', '_mirqi'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports_by_condition = defaultdict(set)\n",
    "\n",
    "for index, row in chexpert_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    report = row['Reports']\n",
    "    labels = row[CHEXPERT_LABELS]\n",
    "\n",
    "    tup = (index, filename, report)\n",
    "\n",
    "    no_findings = labels['No Finding']\n",
    "    \n",
    "    if no_findings == 1:\n",
    "        reports_by_condition['no-findings-1'].add(tup)\n",
    "        if any(l != 0 for l in labels[1:-1]):\n",
    "            # Exclude no-findings and support-devices\n",
    "            reports_by_condition['inconsistent'].add(tup)\n",
    "    else:\n",
    "        if not any(l != 0 for l in labels[1:-1]):\n",
    "            reports_by_condition['no-findings-absent'].add(tup)\n",
    "    \n",
    "    if all(l != 1 for l in labels):\n",
    "        reports_by_condition['no-1s'].add(tup)\n",
    "    \n",
    "[(k, len(v)) for k, v in reports_by_condition.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-absent'])\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mirqi_df.loc[mirqi_df['filename'] == '256.xml'][MIRQI_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-1s'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-1'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
