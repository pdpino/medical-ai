{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS_DIR = os.path.join(DATASET_DIR, 'reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess reports\n",
    "\n",
    "Clean and tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Debug tokenize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../preprocess/tokenize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"findings/pneumothorax \"\"\"\n",
    "text_to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check already clean reports\n",
    "\n",
    "Look for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(REPORTS_DIR, 'reports.clean.v3.json'), 'r') as f:\n",
    "    reports_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def search_in_reports(target):\n",
    "    found = []\n",
    "    for r in reports_dict.values():\n",
    "        clean_text = r['clean_text']\n",
    "        if re.search(target, clean_text):\n",
    "            found.append({\n",
    "                k: r[k]\n",
    "                for k in ('filename', 'clean_text', 'findings', 'impression')\n",
    "            })\n",
    "    print('Found: ', len(found))\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "search_in_reports(r'\\bexample\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Run preprocess\n",
    "\n",
    "- Tokenize reports, create json with clean reports and vocabularies\n",
    "- Create sentences_with_chexpert_labels.csv (takes about 12min)\n",
    "- Create sentences_with_organs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n ../preprocess/iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reports, tokens_appearances, errors = preprocess_iu_x_ray(\n",
    "    'v5-3',\n",
    "    [0],\n",
    "    override=True,\n",
    "    # impression_fallback=False,\n",
    "    # concat_if=True,\n",
    "    concat_fi=True,\n",
    ")\n",
    "len(reports), len(tokens_appearances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sentences_chexpert, errors = create_sentences_with_organs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_sentences_chexpert = create_sentences_with_chexpert_labels()\n",
    "len(df_sentences_chexpert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### v5-2 and v5-3\n",
    "\n",
    "- The vocabulary simulates the one used in the Co-att paper\n",
    "- Manually keep the 1000 top words, and override the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "total_appearances = sum(tokens_appearances.values())\n",
    "len(tokens_appearances), total_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = [(k, v, v/total_appearances*100) for k, v in tokens_appearances.items()]\n",
    "t = sorted(t, key=lambda x: x[1], reverse=True)\n",
    "t[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_n = 1000\n",
    "perc = sum(x[2] for x in t[:top_n])\n",
    "TOP_N_WORDS = set(x[0] for x in t[:top_n])\n",
    "print(f'Top {top_n:,} words cover {perc:.2f}% of the appearances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab = load_vocab(REPORTS_DIR, 'v5-3')\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Copied from _compute_vocab()\n",
    "new_vocab = {\n",
    "    PAD_TOKEN: PAD_IDX,\n",
    "    START_TOKEN: START_IDX,\n",
    "    END_TOKEN: END_IDX,\n",
    "    UNKNOWN_TOKEN: UNKNOWN_IDX,\n",
    "    END_OF_SENTENCE_TOKEN: END_OF_SENTENCE_IDX,\n",
    "}\n",
    "\n",
    "for token in vocab:\n",
    "    if token not in TOP_N_WORDS:\n",
    "        continue\n",
    "    if token not in new_vocab:\n",
    "        new_vocab[token] = len(new_vocab)\n",
    "len(new_vocab), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_save_vocab(REPORTS_DIR, 'v5-3', new_vocab, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Check in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for token, n_appears in tokens.items():\n",
    "    if 'NUMBER' in token:\n",
    "        print(token, n_appears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TARGET_TOKENS = ['NUMBER[^\\s]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "found = []\n",
    "for report in reports.values():\n",
    "    for token in TARGET_TOKENS:\n",
    "        if re.search(token, report['clean_text']):\n",
    "            found.append(report)\n",
    "            \n",
    "len(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rotate images\n",
    "\n",
    "NOTE: are already rotated!!\n",
    "(Run this only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info_fname = os.path.join(DATASET_DIR, 'info.json')\n",
    "with open(info_fname, 'r') as f:\n",
    "    info = json.load(f)\n",
    "len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "info['marks']['rotated_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rotations = [\n",
    "    ('left', -90),\n",
    "    ('right', 90),\n",
    "    ('bottom', 180),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, degrees in rotations:\n",
    "    images_key = f'rotated_{key}'\n",
    "    for image_name in info['marks'][images_key]:\n",
    "        filepath = os.path.join(DATASET_DIR, 'images', image_name)\n",
    "        img = Image.open(filepath).rotate(degrees)\n",
    "        # img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Calculate image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../../utils/images.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_folder = os.path.join(DATASET_DIR, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset('train')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = [\n",
    "    i if i.endswith('.png') else f'{i}.png'\n",
    "    for i in [r['image_name'] for r in dataset.reports]\n",
    "]\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean, std = compute_mean_std(ImageFolderIterator(image_folder, train_images), show=True)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summed = torch.zeros(3, 256, 256)\n",
    "\n",
    "for image_name in tqdm(image_names):\n",
    "    fpath = os.path.join(image_folder, image_name)\n",
    "    image = transform(Image.open(fpath).convert('RGB'))\n",
    "    summed += image\n",
    "    \n",
    "summed /= len(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "average_image = summed.mean(dim=0)\n",
    "average_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(average_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Coatt labels\n",
    "\n",
    "Come from: https://github.com/ZexinYan/Medical-Report-Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_labels(split):\n",
    "    fpath = os.path.join(DATASET_DIR, 'coatt-labels', f'{split}_data.txt')\n",
    "    df = pd.read_csv(fpath, header=None, sep=' ', names=COATT_LABELS)\n",
    "    print(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df = load_labels('train')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_df = load_labels('val')\n",
    "val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_df = load_labels('test')\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images = set(train_df.index)\n",
    "val_images = set(val_df.index)\n",
    "test_images = set(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_images.intersection(val_images), \\\n",
    "val_images.intersection(test_images), \\\n",
    "train_images.intersection(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df = pd.concat([train_df, val_df, test_df], axis=0)\n",
    "print(len(master_df), len(train_df) + len(val_df) + len(test_df))\n",
    "master_df = master_df.reset_index()\n",
    "master_df = master_df.rename(columns={'index': 'image_id'})\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Merge with report filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(REPORTS_DIR, 'reports.clean.v4.json')) as f:\n",
    "    reports = list(json.load(f).values())\n",
    "len(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_name_to_report_filename = {}\n",
    "for report in reports:\n",
    "    filename = report['filename']\n",
    "    for image in report['images']:\n",
    "        image_id = image['id']\n",
    "        image_name_to_report_filename[image_id] = filename\n",
    "len(image_name_to_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "set(master_df['image_id']) - set(image_name_to_report_filename.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df['filename'] = [\n",
    "    image_name_to_report_filename.get(image_id, '')\n",
    "    for image_id in master_df['image_id']\n",
    "]\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = ['image_id', 'filename', *COATT_LABELS]\n",
    "master_df = master_df[cols]\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master_df.to_csv(os.path.join(DATASET_DIR, 'coatt-labels', 'metadata.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MTI tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../preprocess/iu_xray.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_reports = load_raw_reports()\n",
    "len(raw_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _clean_tag(tag):\n",
    "    tag = tag.lower()\n",
    "    tag = re.sub(r'\\W', ' ', tag)\n",
    "    tag = re.sub(r'\\s+', ' ', tag)\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tag_counter = Counter()\n",
    "for report in raw_reports.values():\n",
    "    for tag in report['tags_auto']:\n",
    "        tag = _clean_tag(tag)\n",
    "        tag_counter[tag] += 1\n",
    "len(tag_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(tag_counter.items(), key=lambda x:x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "step = 4\n",
    "tags = list(tag_counter)\n",
    "for i in range(0, len(tags), step):\n",
    "    print(', '.join(f\"'{tag}'\" for tag in tags[i:i+step]) + ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "all_reports = []\n",
    "for report_id, report in raw_reports.items():\n",
    "    tags = set(\n",
    "        _clean_tag(tag)\n",
    "        for tag in report['tags_auto']\n",
    "    )\n",
    "    tags_onehot = [\n",
    "        int(t in tags)\n",
    "        for t in IU_MTI_TAGS\n",
    "    ]\n",
    "    \n",
    "    all_tags.append(tags_onehot)\n",
    "    all_reports.append(report_id)\n",
    "tags_df = pd.DataFrame(all_tags, columns=IU_MTI_TAGS)\n",
    "tags_df['filename'] = all_reports\n",
    "cols = ['filename'] + IU_MTI_TAGS\n",
    "tags_df = tags_df[cols]\n",
    "tags_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tags_df.to_csv(os.path.join(DATASET_DIR, 'mti-tags.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: reduce synonyms??\n",
    "# syns = {\n",
    "#     'atelectases': 'atelectasis',\n",
    "#     'atheroscleroses': 'atherosclerosis',\n",
    "#     'bronchiectases': 'bronchiectasis',\n",
    "#     'histoplasmoma': 'histoplasmosis',\n",
    "#     'histoplasmoses': 'histoplasmosis',\n",
    "#     'humeral fractures': 'humeral fracture',\n",
    "#     'tuberculoses': 'tuberculosis',\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `IUXrayDataset` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../utils/common.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../iu_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IUXRayDataset(\n",
    "    dataset_type='test',\n",
    "    # masks=True,\n",
    "    # masks_version='v2',\n",
    "    # frontal_only=True,\n",
    "    image_size=(1024, 1024),\n",
    "    # seg_multilabel=False,\n",
    "    # labels='mti',\n",
    "    images_version='16bit-1024p',\n",
    "    # image_format='I;16',\n",
    "    image_format='I',\n",
    ")\n",
    "len(dataset), len(dataset.word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = dataset[100]\n",
    "image = item.image\n",
    "labels = item.labels\n",
    "report = item.report\n",
    "image.size(), labels.size(), len(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(item.masks, torch.Tensor):\n",
    "    print(item.masks.min(), item.masks.max(), item.masks.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 2\n",
    "n_cols = 3\n",
    "\n",
    "plt.figure(figsize=(n_cols*5, n_rows*5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plt.title(item.image_fname)\n",
    "plt.imshow(tensor_to_range01(image).permute(1, 2, 0))\n",
    "# plt.axis('off')\n",
    "\n",
    "if isinstance(item.masks, torch.Tensor) and item.masks.ndim == 3:\n",
    "    for index, organ in enumerate(JSRT_ORGANS):\n",
    "        mask = item.masks[index]\n",
    "\n",
    "        plt.subplot(n_rows, n_cols, index + 2)\n",
    "        plt.imshow(mask)\n",
    "        plt.title(organ)\n",
    "        plt.axis('off')\n",
    "\n",
    "        min_value = mask.min().item()\n",
    "        max_value = mask.max().item()\n",
    "        print(organ, min_value, max_value)\n",
    "elif isinstance(item.masks, torch.Tensor) and item.masks.ndim == 2:\n",
    "    plt.subplot(n_rows, n_cols, 2)\n",
    "    plt.imshow(item.masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_copy = image.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(arr):\n",
    "    print(arr.type(), arr.min(), arr.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(image_copy)\n",
    "stats(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run ../iu_xray.py\n",
    "%run ../common/constants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_dataset = IUXRayDataset('train')\n",
    "val_dataset = IUXRayDataset('val')\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Labels distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_labels_distribution(dataset):\n",
    "    amounts_by_disease = sum(\n",
    "        (dataset.labels_by_report[r['filename']] for r in dataset.reports),\n",
    "        torch.zeros(len(CHEXPERT_DISEASES)),\n",
    "    ).tolist()\n",
    "    max_amount = max(amounts_by_disease)\n",
    "    amounts_by_disease = list(zip(CHEXPERT_DISEASES, amounts_by_disease))\n",
    "    amounts_by_disease = sorted(amounts_by_disease, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    n_samples = len(dataset)\n",
    "    plt.title(f'{dataset.dataset_type} (n={n_samples:,})', fontsize=20)\n",
    "    plt.bar(*zip(*amounts_by_disease))\n",
    "    plt.xticks(rotation=60, fontsize=15, ha='right')\n",
    "    plt.ylabel('Amount of images', fontsize=18)\n",
    "    plt.ylim(0, max_amount * 1.15)\n",
    "    y_padding = int(max_amount * 0.03)\n",
    "    \n",
    "    for index, (disease, amount) in enumerate(amounts_by_disease):\n",
    "        amount = int(amount)\n",
    "        perc = amount / n_samples * 100\n",
    "        plt.text(index, amount + y_padding, f'{amount:,}\\n{perc:.0f}%', ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_labels_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_labels_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Report lengths distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_n_words_distribution(dataset):\n",
    "    lengths = [len(r['tokens_idxs']) for r in dataset.reports]\n",
    "    plt.title(f'Report-lengths ({dataset.dataset_type}, total={len(dataset):,})')\n",
    "    plt.ylabel('Amount of images')\n",
    "    plt.xlabel('Number of words')\n",
    "    _ = plt.hist(lengths, bins=25, range=(0, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_n_words_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_n_words_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Frontal vs lateral distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_view_position_distribution(dataset):\n",
    "    def _reduce_pos(position):\n",
    "        return position.replace('-left', '').replace('-right', '')\n",
    "    positions = Counter([_reduce_pos(r['position']) for r in dataset.reports])\n",
    "    \n",
    "    plt.title(f'Frontal vs lateral ({dataset.dataset_type})', fontsize=20)\n",
    "    plt.ylabel('Amount of images', fontsize=15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    \n",
    "    positions = sorted(positions.items(), key=lambda x: x[1], reverse=True)\n",
    "    keys, values = zip(*positions)\n",
    "    plt.bar(keys, values, width=0.2)\n",
    "    \n",
    "    plt.ylim(0, max(values) * 1.2)\n",
    "    y_padding = max(values) * 0.03\n",
    "    n_samples = len(dataset)\n",
    "    for index, value in enumerate(values):\n",
    "        perc = value / n_samples * 100\n",
    "        text = f'{value:,}\\n{perc:.2f}%'\n",
    "        plt.text(index, value + y_padding, text, ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_rows = 1\n",
    "n_cols = 2\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 1)\n",
    "plot_view_position_distribution(train_dataset)\n",
    "\n",
    "plt.subplot(n_rows, n_cols, 2)\n",
    "plot_view_position_distribution(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect different vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../vocab/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_full = load_vocab('iu_xray')\n",
    "vocab_1 = load_vocab('iu_xray', 1)\n",
    "vocab_10 = load_vocab('iu_xray', 10)\n",
    "len(vocab_full), len(vocab_1), len(vocab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(vocab_10).issubset(vocab_1)\n",
    "assert set(vocab_1).issubset(vocab_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_vocab_1 = set(vocab_full) - set(vocab_1)\n",
    "out_of_vocab_10 = set(vocab_1) - set(vocab_10)\n",
    "len(out_of_vocab_1), len(out_of_vocab_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_vocab_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check no-findings vs labels==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_path = os.path.join(REPORTS_DIR, 'reports_with_chexpert_labels.csv')\n",
    "mirqi_path = os.path.join(REPORTS_DIR, 'reports_with_mirqi_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chexpert_df = pd.read_csv(chexpert_path, index_col=0)\n",
    "chexpert_df.replace(-1, 1, inplace=True)\n",
    "chexpert_df.replace(-2, 0, inplace=True)\n",
    "chexpert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirqi_df = pd.read_csv(mirqi_path, index_col=0)\n",
    "mirqi_df.drop(columns=['attributes-gen', 'MIRQI-r', 'MIRQI-p', 'MIRQI-f'], inplace=True)\n",
    "mirqi_df.rename(columns={'attributes-gt': 'attributes'}, inplace=True)\n",
    "mirqi_df.replace(-1, 1, inplace=True)\n",
    "mirqi_df.replace(-2, 0, inplace=True)\n",
    "mirqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = set(['filename', 'Reports', 'attributes'])\n",
    "MIRQI_LABELS = [c for c in mirqi_df.columns if c not in base_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chexpert_df), len(mirqi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = chexpert_df.merge(mirqi_df, on='filename', suffixes=['_chx', '_mirqi'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_by_condition = defaultdict(set)\n",
    "\n",
    "for index, row in chexpert_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    report = row['Reports']\n",
    "    labels = row[CHEXPERT_LABELS]\n",
    "\n",
    "    tup = (index, filename, report)\n",
    "\n",
    "    no_findings = labels['No Finding']\n",
    "    \n",
    "    if no_findings == 1:\n",
    "        reports_by_condition['no-findings-1'].add(tup)\n",
    "        if any(l != 0 for l in labels[1:-1]):\n",
    "            # Exclude no-findings and support-devices\n",
    "            reports_by_condition['inconsistent'].add(tup)\n",
    "    else:\n",
    "        if not any(l != 0 for l in labels[1:-1]):\n",
    "            reports_by_condition['no-findings-absent'].add(tup)\n",
    "    \n",
    "    if all(l != 1 for l in labels):\n",
    "        reports_by_condition['no-1s'].add(tup)\n",
    "    \n",
    "[(k, len(v)) for k, v in reports_by_condition.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-absent'])\n",
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirqi_df.loc[mirqi_df['filename'] == '256.xml'][MIRQI_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-1s'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(reports_by_condition['no-findings-1'])\n",
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
